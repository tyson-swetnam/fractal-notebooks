{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Fractal patterns in Nature: Self-affinity vs Self-similarity","text":""},{"location":"#authors","title":"Authors","text":"<p>Tyson Lee Swetnam   Institute for Computation and Data-enabled Insight, University of Arizona</p> <p>Jon D Pelletier  Department of Geosciences, University of Arizona</p> <p>Brian J. Enquist  Department of Ecology and Evolutionary Biology, University of Arizona</p>"},{"location":"#abstract","title":"Abstract","text":"<p>Much of the scientific literature describes the fractal-like hierarchical branching networks of vascular organisms as 'self-similar'. Here we examine papers where fractal-like self-similarity is incorrectly described. We also link why the hierarchical branching networks in vascular organisms are 'self-affine' rather than self-similar by linking metabolic scaling theory to these structural traits. Last, we propose a mechanistic theory of fractal dimensions for single cell through multicellular life forms forms. </p> <p>In our supplemental materials, we provide empirical explanations for the fractal-like structures of single cell colonies and autotrophs including primitive algae, vascular organisms including lichens and bryophytes, and higher order terrestrial plants. </p> <p>We also describe how self-affinity arises in heterotrophs as related to metabolic and circulatory networks.</p>"},{"location":"#background","title":"Background","text":"<p>Self-similarity is an appropriate term for isometry, where objects scale identically in one or more dimensions, while self-affinity describes allometry, or differential scaling in one or more dimensions. </p> <p>The vascular networks of most higher organisms facilitate mass transport as capillary action (in autotrophs) or laminar or pulsatile flow (in heterotrophs) and laminar flow with turbulent motion giving way to diffusion at smaller scale (&lt;200nm). Diffusion is the most efficient mechanism for gas exchange at &lt;200nm, eliminating the need for vascularity.</p> <p>As an example of self-affine versus self-similar fractal dimensions, we calculated the mass dimension \\(d_m\\) by differential box counting in both synthetic fractal-like forms resembling plants and real vascular plants using x-ray and visible light photographs of the leaves, branches, and roots of individual organisms. We also calculated the mass dimension of forest-scale tree canopies from remote sensing. </p> <p>For leaves, branches, and roots, \\(d_m\\) was in good agreement with the predictions of Metabolic Scaling Theory (MST), where \\(d_m\\) is predicted to equal \\( \\frac{3}{2} \\). At the forest level, canopy height models show that \\(d_m\\) is related to a zeta function \\( \\zeta^{-s} \\), where fractal objects fill available space until they begin to self-thin in relation to their energetic equivalence with locally available free energy.</p> <p>Our results demonstrate:</p> <ol> <li> <p>Dimensional analysis with appropriate self-affine mass dimension shows that many reported fractal dimensions in ecology are either incorrect or inappropriately reported.</p> </li> <li> <p>A technique for testable predictions, including a mechanistic explanation for how individual branching networks grow and fill space and how communities of organisms emerge with fractal dimensions based on MST predictions.</p> </li> </ol> <p>These results may help reveal when communities of individuals have maximized their potential to cycle energy through an ecosystem or when they have been disturbed by exogenous forces.</p>"},{"location":"#1d-2d-3d-and-4d-fractal-like-patterns","title":"1D, 2D, 3D, and 4D fractal-like patterns","text":"<p>Fractals are intricate patterns that repeat themselves at different scales. They can exist in various dimensions. This introduction provides a brief overview of fractals in one-dimensional (1D), two-dimensional (2D), three-dimensional (3D), and four-dimensional (4D) spaces, along with examples of self-similar and self-affine fractals in each dimension.</p>"},{"location":"#1d-fractals","title":"1D Fractals","text":""},{"location":"#1f-noise-pink-noise","title":"1/f Noise (Pink Noise)","text":""},{"location":"#what-is-1f-noise","title":"What Is 1/f Noise?","text":"<p>1/f noise is a signal whose power spectral density (PSD) is inversely proportional to the frequency (f). This means that as the frequency decreases, the power increases, following the relationship:</p> \\[ \\text{PSD}(f) \\propto \\frac{1}{f^\\alpha} \\] <p>where \\(\\alpha\\) is approximately equal to 1 for true pink noise.</p>"},{"location":"#fractal-characteristics","title":"Fractal Characteristics","text":"<ul> <li> <p>Self-Similarity: The signal appears statistically similar across different time scales. Zooming in on a segment of the signal reveals patterns resembling the whole.</p> </li> <li> <p>Long-Range Dependence: Values in the signal are correlated over long time periods.</p> </li> <li> <p>Non-Integer Dimension: The signal has a fractal (non-integer) dimension, quantifying its complexity.</p> </li> </ul>"},{"location":"#examples-in-sound","title":"Examples in Sound","text":"<ul> <li> <p>Ambient Noise: Pink noise is perceived as balanced and soothing because it distributes equal power per octave. It's used in sound masking, tinnitus treatments, and sleep aids.</p> </li> <li> <p>Music and Speech: Elements of music dynamics and speech patterns often exhibit 1/f characteristics, contributing to their natural and pleasing qualities.</p> </li> </ul>"},{"location":"#examples-in-electrical-signals","title":"Examples in Electrical Signals","text":"<ul> <li> <p>Electronic Components: Resistors, semiconductors, and other electronic devices exhibit 1/f noise, also known as flicker noise. This can affect the performance of circuits, especially at low frequencies.</p> </li> <li> <p>Neural Activity: Electrical impulses in the brain, measured via electroencephalography (EEG), show 1/f spectral properties, indicating fractal-like neural dynamics.</p> </li> </ul>"},{"location":"#fractional-brownian-motion-fbm","title":"Fractional Brownian Motion (fBm)","text":""},{"location":"#what-is-fractional-brownian-motion","title":"What Is Fractional Brownian Motion?","text":"<p>Fractional Brownian motion is a generalization of standard Brownian motion that includes memory and persistence. It is characterized by the Hurst exponent (H), which determines the degree of self-similarity and long-range dependence.</p>"},{"location":"#fractal-characteristics_1","title":"Fractal Characteristics","text":"<ul> <li> <p>Self-Affinity: The statistical properties are preserved under anisotropic scaling of time and amplitude.</p> </li> <li> <p>Hurst Exponent: A value of \\( H &gt; 0.5 \\) indicates persistence, while \\( H &lt; 0.5 \\) indicates anti-persistence.</p> </li> </ul>"},{"location":"#applications","title":"Applications","text":"<ul> <li> <p>Heart Rate Variability: The intervals between heartbeats can display fractal patterns modeled by fBm. Healthy heart rhythms often exhibit fractal characteristics.</p> </li> <li> <p>Financial Markets: Stock prices and market indices can be modeled using fBm to account for long-range dependencies and volatility clustering.</p> </li> <li> <p>Telecommunications: Network traffic often shows self-similar patterns over time, impacting network design and performance.</p> </li> </ul>"},{"location":"#why-are-signals-fractal","title":"Why Are Signals Fractal?","text":"<p>Fractal signals like 1/f noise and fractional Brownian motion are considered fractal because they exhibit patterns that are consistent across different scales of observation. This property is known as statistical self-similarity.</p> <ul> <li> <p>Scaling Behavior: The signals maintain their statistical properties under scaling transformations.</p> </li> <li> <p>Complexity: The fractal dimension quantifies the complexity and irregularity of the signal, which is greater than that of a simple, smooth signal.</p> </li> </ul>"},{"location":"#visualization","title":"Visualization","text":"<p>Imagine recording the sound of ocean waves:</p> <ul> <li> <p>Long Observation: Over several minutes, you hear the rise and fall of waves.</p> </li> <li> <p>Short Observation: Zooming into a few seconds, the smaller ripples mimic the larger wave patterns.</p> </li> <li> <p>Signal Analysis: Plotting the amplitude over time reveals a waveform with self-similar patterns at different time scales.</p> </li> </ul>"},{"location":"#practical-implications","title":"Practical Implications","text":"<ul> <li> <p>Engineering: Understanding 1/f noise is crucial for designing low-noise electronic circuits and improving signal processing techniques.</p> </li> <li> <p>Medicine: Fractal analysis of physiological signals like heart rate and neural activity can aid in diagnosing health conditions.</p> </li> <li> <p>Music Production: Pink noise is used to test and calibrate audio equipment due to its balanced frequency distribution.</p> </li> </ul>"},{"location":"#2d-fractals","title":"2D Fractals","text":""},{"location":"#fractional-brownian-surfaces-fbs","title":"Fractional Brownian Surfaces (fBs)","text":""},{"location":"#what-are-fractional-brownian-surfaces","title":"What Are Fractional Brownian Surfaces?","text":"<p>Fractional Brownian surfaces are two-dimensional generalizations of fractional Brownian motion, representing surfaces whose elevations vary in a statistically self-similar way across different spatial scales. They are used to model natural terrains and textures that exhibit fractal characteristics.</p>"},{"location":"#fractal-characteristics_2","title":"Fractal Characteristics","text":"<ul> <li>Self-Affinity: The surface's statistical properties are preserved under anisotropic scaling, where spatial dimensions (x and y) and the elevation (z) are scaled by different factors.</li> <li>Hurst Exponent (H): Determines the roughness or smoothness of the surface. A higher H results in a smoother surface, while a lower H leads to a rougher one.</li> <li>Fractal Dimension (D): Given by \\( D = 3 - H \\), it quantifies the complexity of the surface. A higher fractal dimension indicates a more complex surface.</li> </ul>"},{"location":"#examples-in-natural-images","title":"Examples in Natural Images","text":"<ul> <li>Terrain and Landscapes: Elevation maps of mountains and valleys often display fractal properties, where smaller hills resemble larger mountain structures.</li> <li>Cloud Formations: Satellite images of clouds show patterns that are statistically similar across different scales.</li> <li>Coastlines: The intricate patterns of coastlines can be modeled using fractional Brownian surfaces, capturing their fractal nature.</li> </ul>"},{"location":"#why-are-these-surfaces-fractal","title":"Why Are These Surfaces Fractal?","text":"<p>Fractional Brownian surfaces are considered fractal because they exhibit statistical self-affinity across scales:</p> <ul> <li>Scaling Behavior: If you zoom into a portion of the surface and appropriately rescale the axes, the surface's statistical properties remain consistent.</li> <li>Complexity: The surfaces have a non-integer fractal dimension, filling space more than a flat plane but less than a full volume.</li> </ul>"},{"location":"#visualization_1","title":"Visualization","text":"<p>Imagine creating a digital elevation model for a landscape:</p> <ol> <li>Initial Generation: Start with a grid representing the surface.</li> <li>Applying fBs: Use algorithms that introduce fractional Brownian motion to assign elevation values, controlling roughness with the Hurst exponent.</li> <li>Resulting Surface: The generated surface displays hills and valleys with patterns that look similar, regardless of the scale at which you observe them.</li> </ol> <p></p> <p>An example of a fractional Brownian surface displaying self-affine fractal properties.</p>"},{"location":"#applications_1","title":"Applications","text":""},{"location":"#computer-graphics","title":"Computer Graphics","text":"<ul> <li>Terrain Generation: Used in video games and simulations to create realistic landscapes.</li> <li>Texture Synthesis: Generates natural-looking textures for objects and environments.</li> </ul>"},{"location":"#geographical-analysis","title":"Geographical Analysis","text":"<ul> <li>Satellite Imagery: Analyzing landforms and geological structures using fractal dimensions.</li> <li>Environmental Monitoring: Studying patterns of vegetation, deforestation, or urban development.</li> </ul>"},{"location":"#medical-imaging","title":"Medical Imaging","text":"<ul> <li>Tissue Analysis: Fractal analysis helps in characterizing complex structures in biological tissues, aiding in diagnostics.</li> <li>Bone Structure: Evaluating the fractal nature of bone trabeculae can assist in osteoporosis research.</li> </ul>"},{"location":"#fractal-analysis-techniques","title":"Fractal Analysis Techniques","text":""},{"location":"#box-counting-methods","title":"Box-Counting Methods","text":"<ul> <li> <p>Process: Overlay a grid of boxes over the image and count the number of boxes that contain part of the structure.</p> </li> <li> <p>Scaling: Repeat with different box sizes to see how the count changes.</p> </li> <li> <p>Fractal Dimension: Calculated based on how the number of occupied boxes scales with the box size.</p> </li> </ul>"},{"location":"#power-spectral-density-psd","title":"Power Spectral Density (PSD)","text":"<ul> <li> <p>Frequency Analysis: Transform the image into the frequency domain to analyze the distribution of spatial frequencies.</p> </li> <li> <p>Scaling Laws: The PSD often follows a power law, indicative of fractal behavior.</p> </li> </ul>"},{"location":"#practical-implications_1","title":"Practical Implications","text":""},{"location":"#engineering-and-design","title":"Engineering and Design","text":"<ul> <li> <p>Surface Roughness: Understanding the fractal nature of surfaces can improve material design and coatings.</p> </li> <li> <p>Antenna Design: Fractal-shaped antennas can operate efficiently over multiple frequency bands.</p> </li> </ul>"},{"location":"#environmental-science","title":"Environmental Science","text":"<ul> <li> <p>Erosion Patterns: Modeling soil erosion and river networks using fractal geometry.</p> </li> <li> <p>Climate Modeling: Analyzing cloud patterns and atmospheric turbulence.</p> </li> </ul>"},{"location":"#art-and-aesthetics","title":"Art and Aesthetics","text":"<ul> <li> <p>Fractal Art: Creating visually appealing images using fractal algorithms.</p> </li> <li> <p>Texture Mapping: Enhancing visual realism in digital art and animations.</p> </li> </ul>"},{"location":"#understanding-self-similarity-and-self-affinity-in-2d-fractals","title":"Understanding Self-Similarity and Self-Affinity in 2D Fractals","text":"<ul> <li> <p>Self-Similar Fractals: Patterns repeat exactly at different scales. Example: Sierpinski Carpet.</p> </li> <li> <p>Self-Affine Fractals: Scaling factors differ across axes. Natural terrains are self-affine because the vertical scale (elevation) and horizontal scales (latitude and longitude) scale differently.</p> </li> </ul>"},{"location":"#example-analyzing-satellite-images","title":"Example: Analyzing Satellite Images","text":""},{"location":"#steps","title":"Steps","text":"<ol> <li>Data Acquisition: Obtain high-resolution satellite images of a geographical area.</li> <li>Preprocessing: Convert images to grayscale and normalize.</li> <li>Fractal Analysis: Apply box-counting or PSD methods to calculate the fractal dimension.</li> <li>Interpretation: Use the fractal dimension to infer characteristics like terrain roughness or vegetation density.</li> </ol>"},{"location":"#insights","title":"Insights","text":"<ul> <li> <p>Urban vs. Natural Areas: Urban regions may have different fractal dimensions compared to natural landscapes due to human-made structures.</p> </li> <li> <p>Environmental Changes: Changes in fractal dimension over time can indicate deforestation, desertification, or urban expansion.</p> </li> </ul>"},{"location":"#3d-fractals","title":"3D Fractals","text":""},{"location":"#4d-fractals","title":"4D Fractals","text":""},{"location":"#applications_2","title":"Applications","text":"<p>We have created interactive example applications written in Python which simulate and generate fractal like structures that can run as stand-alone applications in your web browser.</p> <p>These applications allow you to calculate fractal dimensions of binary and scalar imagery, to interact with fractal like structures, and to upload and analyze your own data.</p>"},{"location":"#jupyter-notebooks","title":"Jupyter Notebooks","text":"<p>We provide a set of example Jupyter Notebooks demonstrating dimensionality of fractal-like behavior in nature.</p> <p>For all of our equations and figures, we provide example notebooks which use publicly available data and open source code .</p>"},{"location":"applications/","title":"Setup","text":""},{"location":"applications/#requirements","title":"Requirements","text":"<p>To run the example applications,  you will need to install a Python virtual environment or use a Python package manager. We recommend using <code>pip</code> or <code>conda</code> environments with <code>mamba</code> solvers.</p> <pre><code>cd apps\npip install requirements.txt\n</code></pre> <ol> <li>Creating a <code>conda</code> environment</li> </ol> <pre><code>cd notebooks\nmamba env create -f streamlit-plotly.yaml\n</code></pre> <ol> <li> <p>Activate the Conda Environment:</p> <pre><code>mamba activate fractal-env\n</code></pre> </li> <li> <p>Install Jupyter and Create a Jupyter Kernel:</p> <pre><code>mamba install -c conda-forge jupyterlab ipykernel\npython -m ipykernel install --name fractal-env --display-name \"Fractal Env\"\n</code></pre> </li> </ol> <p>These steps will create a Conda environment, activate it, and set up a Jupyter kernel named \"Fractal Env\" that you can use in Jupyter notebooks.</p>"},{"location":"conclusion/","title":"Conclusions","text":"<p>The main points of this paper are to establish:</p> <ol> <li> <p>Natural fractals are mostly self-affine and require special descriptors: Many fractals found in nature, particularly in biological systems, are self-affine rather than self-similar. This distinction is crucial for accurately measuring and understanding their scaling properties.</p> </li> <li> <p>The spectral \\( 1/f^\\beta \\) noises and fractal dimensions of organisms can be described as self-affine behavior: Fractal geometry in living systems, particularly in hierarchical branching networks like vascular systems, is driven by self-affine scaling, where different dimensions grow at different rates. This anisotropic scaling provides a more accurate description of these biological networks.</p> </li> <li> <p>The mechanism of all these processes is the maximization of entropy through mass transfer and enzyme kinetics: The fundamental processes behind these self-affine fractal patterns include fractional Brownian motion (fBm), Fickian diffusion, and convective mass transfer mechanisms, all of which work to maximize entropy production. These processes reflect the optimization of energy and resource distribution in biological systems.</p> </li> </ol> <p>We also reaffirm the predictions of Metabolic Scaling Theory (MST) that the geometry of organisms is fractal, rather than Euclidean. Although Mandelbrot (1982) suggested that self-affinity lacked a basic, universally valid reduction to principles, we argue that the fundamental mechanisms driving self-affine fractals in biological systems are well-explained by mass transfer processes and enzyme kinetics.</p> <p>In ecology, the Zipf-Mandelbrot law has been used to describe relative abundance distributions (RAD) and species abundance distributions (SAD). Ecologists should be aware of the differences between self-similar and self-affine fractals and apply the appropriate methods for deriving affine-fractal dimensions. Additionally, fractal lacunarity can serve as a useful measure for quantifying the phase state of ecosystems, especially when analyzing forest disturbance history.</p> <p>Further research into the fractal geometry of organisms and ecosystems may be necessary to fully understand whether entropy production is the driving force behind self-affine fractal dimensions. The unification of thermodynamic theories, metabolic scaling, and evolutionary principles could provide a broader understanding of fractal behavior in biological systems.</p>"},{"location":"dims/","title":"Dimensionality of Fractals","text":""},{"location":"dims/#1d-2d-3d-and-4d-fractal-like-patterns","title":"1D, 2D, 3D, and 4D fractal-like patterns","text":"<p>Fractals are intricate patterns that repeat themselves at different scales. They can exist in various dimensions. This introduction provides a brief overview of fractals in one-dimensional (1D), two-dimensional (2D), three-dimensional (3D), and four-dimensional (4D) spaces, along with examples of self-similar and self-affine fractals in each dimension.</p>"},{"location":"dims/#1d-fractals","title":"1D Fractals","text":""},{"location":"dims/#1f-noise-pink-noise","title":"1/f Noise (Pink Noise)","text":""},{"location":"dims/#what-is-1f-noise","title":"What Is 1/f Noise?","text":"<p>1/f noise is a signal whose power spectral density (PSD) is inversely proportional to the frequency (f). This means that as the frequency decreases, the power increases, following the relationship:</p> \\[ \\text{PSD}(f) \\propto \\frac{1}{f^\\alpha} \\] <p>where \\(\\alpha\\) is approximately equal to 1 for true pink noise.</p>"},{"location":"dims/#fractal-characteristics","title":"Fractal Characteristics","text":"<ul> <li> <p>Self-Similarity: The signal appears statistically similar across different time scales. Zooming in on a segment of the signal reveals patterns resembling the whole.</p> </li> <li> <p>Long-Range Dependence: Values in the signal are correlated over long time periods.</p> </li> <li> <p>Non-Integer Dimension: The signal has a fractal (non-integer) dimension, quantifying its complexity.</p> </li> </ul>"},{"location":"dims/#examples-in-sound","title":"Examples in Sound","text":"<ul> <li> <p>Ambient Noise: Pink noise is perceived as balanced and soothing because it distributes equal power per octave. It's used in sound masking, tinnitus treatments, and sleep aids.</p> </li> <li> <p>Music and Speech: Elements of music dynamics and speech patterns often exhibit 1/f characteristics, contributing to their natural and pleasing qualities.</p> </li> </ul>"},{"location":"dims/#examples-in-electrical-signals","title":"Examples in Electrical Signals","text":"<ul> <li> <p>Electronic Components: Resistors, semiconductors, and other electronic devices exhibit 1/f noise, also known as flicker noise. This can affect the performance of circuits, especially at low frequencies.</p> </li> <li> <p>Neural Activity: Electrical impulses in the brain, measured via electroencephalography (EEG), show 1/f spectral properties, indicating fractal-like neural dynamics.</p> </li> </ul>"},{"location":"dims/#fractional-brownian-motion-fbm","title":"Fractional Brownian Motion (fBm)","text":""},{"location":"dims/#what-is-fractional-brownian-motion","title":"What Is Fractional Brownian Motion?","text":"<p>Fractional Brownian motion is a generalization of standard Brownian motion that includes memory and persistence. It is characterized by the Hurst exponent (H), which determines the degree of self-similarity and long-range dependence.</p>"},{"location":"dims/#fractal-characteristics_1","title":"Fractal Characteristics","text":"<ul> <li> <p>Self-Affinity: The statistical properties are preserved under anisotropic scaling of time and amplitude.</p> </li> <li> <p>Hurst Exponent: A value of \\( H &gt; 0.5 \\) indicates persistence, while \\( H &lt; 0.5 \\) indicates anti-persistence.</p> </li> </ul>"},{"location":"dims/#applications","title":"Applications","text":"<ul> <li> <p>Heart Rate Variability: The intervals between heartbeats can display fractal patterns modeled by fBm. Healthy heart rhythms often exhibit fractal characteristics.</p> </li> <li> <p>Financial Markets: Stock prices and market indices can be modeled using fBm to account for long-range dependencies and volatility clustering.</p> </li> <li> <p>Telecommunications: Network traffic often shows self-similar patterns over time, impacting network design and performance.</p> </li> </ul>"},{"location":"dims/#why-are-signals-fractal","title":"Why Are Signals Fractal?","text":"<p>Fractal signals like 1/f noise and fractional Brownian motion are considered fractal because they exhibit patterns that are consistent across different scales of observation. This property is known as statistical self-similarity.</p> <ul> <li> <p>Scaling Behavior: The signals maintain their statistical properties under scaling transformations.</p> </li> <li> <p>Complexity: The fractal dimension quantifies the complexity and irregularity of the signal, which is greater than that of a simple, smooth signal.</p> </li> </ul>"},{"location":"dims/#visualization","title":"Visualization","text":"<p>Imagine recording the sound of ocean waves:</p> <ul> <li> <p>Long Observation: Over several minutes, you hear the rise and fall of waves.</p> </li> <li> <p>Short Observation: Zooming into a few seconds, the smaller ripples mimic the larger wave patterns.</p> </li> <li> <p>Signal Analysis: Plotting the amplitude over time reveals a waveform with self-similar patterns at different time scales.</p> </li> </ul>"},{"location":"dims/#practical-implications","title":"Practical Implications","text":"<ul> <li> <p>Engineering: Understanding 1/f noise is crucial for designing low-noise electronic circuits and improving signal processing techniques.</p> </li> <li> <p>Medicine: Fractal analysis of physiological signals like heart rate and neural activity can aid in diagnosing health conditions.</p> </li> <li> <p>Music Production: Pink noise is used to test and calibrate audio equipment due to its balanced frequency distribution.</p> </li> </ul>"},{"location":"dims/#2d-fractals","title":"2D Fractals","text":"<p>Certainly! An example of a two-dimensional fractal similar to the one-dimensional fractal signals is the concept of fractal textures found in natural images, such as satellite photos of landscapes, cloud formations, or even medical images. One specific mathematical model that captures this is the fractional Brownian surface (fBs), which extends the idea of fractional Brownian motion into two dimensions.</p>"},{"location":"dims/#fractional-brownian-surfaces-fbs","title":"Fractional Brownian Surfaces (fBs)","text":""},{"location":"dims/#what-are-fractional-brownian-surfaces","title":"What Are Fractional Brownian Surfaces?","text":"<p>Fractional Brownian surfaces are two-dimensional generalizations of fractional Brownian motion, representing surfaces whose elevations vary in a statistically self-similar way across different spatial scales. They are used to model natural terrains and textures that exhibit fractal characteristics.</p>"},{"location":"dims/#fractal-characteristics_2","title":"Fractal Characteristics","text":"<ul> <li>Self-Affinity: The surface's statistical properties are preserved under anisotropic scaling, where spatial dimensions (x and y) and the elevation (z) are scaled by different factors.</li> <li>Hurst Exponent (H): Determines the roughness or smoothness of the surface. A higher H results in a smoother surface, while a lower H leads to a rougher one.</li> <li>Fractal Dimension (D): Given by \\( D = 3 - H \\), it quantifies the complexity of the surface. A higher fractal dimension indicates a more complex surface.</li> </ul>"},{"location":"dims/#examples-in-natural-images","title":"Examples in Natural Images","text":"<ul> <li>Terrain and Landscapes: Elevation maps of mountains and valleys often display fractal properties, where smaller hills resemble larger mountain structures.</li> <li>Cloud Formations: Satellite images of clouds show patterns that are statistically similar across different scales.</li> <li>Coastlines: The intricate patterns of coastlines can be modeled using fractional Brownian surfaces, capturing their fractal nature.</li> </ul>"},{"location":"dims/#why-are-these-surfaces-fractal","title":"Why Are These Surfaces Fractal?","text":"<p>Fractional Brownian surfaces are considered fractal because they exhibit statistical self-affinity across scales:</p> <ul> <li>Scaling Behavior: If you zoom into a portion of the surface and appropriately rescale the axes, the surface's statistical properties remain consistent.</li> <li>Complexity: The surfaces have a non-integer fractal dimension, filling space more than a flat plane but less than a full volume.</li> </ul>"},{"location":"dims/#visualization_1","title":"Visualization","text":"<p>Imagine creating a digital elevation model for a landscape:</p> <ol> <li>Initial Generation: Start with a grid representing the surface.</li> <li>Applying fBs: Use algorithms that introduce fractional Brownian motion to assign elevation values, controlling roughness with the Hurst exponent.</li> <li>Resulting Surface: The generated surface displays hills and valleys with patterns that look similar, regardless of the scale at which you observe them.</li> </ol> <p></p> <p>An example of a fractional Brownian surface displaying self-affine fractal properties.</p>"},{"location":"dims/#applications_1","title":"Applications","text":""},{"location":"dims/#computer-graphics","title":"Computer Graphics","text":"<ul> <li>Terrain Generation: Used in video games and simulations to create realistic landscapes.</li> <li>Texture Synthesis: Generates natural-looking textures for objects and environments.</li> </ul>"},{"location":"dims/#geographical-analysis","title":"Geographical Analysis","text":"<ul> <li>Satellite Imagery: Analyzing landforms and geological structures using fractal dimensions.</li> <li>Environmental Monitoring: Studying patterns of vegetation, deforestation, or urban development.</li> </ul>"},{"location":"dims/#medical-imaging","title":"Medical Imaging","text":"<ul> <li>Tissue Analysis: Fractal analysis helps in characterizing complex structures in biological tissues, aiding in diagnostics.</li> <li>Bone Structure: Evaluating the fractal nature of bone trabeculae can assist in osteoporosis research.</li> </ul>"},{"location":"dims/#fractal-analysis-techniques","title":"Fractal Analysis Techniques","text":""},{"location":"dims/#box-counting-methods","title":"Box-Counting Methods","text":"<ul> <li> <p>Process: Overlay a grid of boxes over the image and count the number of boxes that contain part of the structure.</p> </li> <li> <p>Scaling: Repeat with different box sizes to see how the count changes.</p> </li> <li> <p>Fractal Dimension: Calculated based on how the number of occupied boxes scales with the box size.</p> </li> </ul>"},{"location":"dims/#power-spectral-density-psd","title":"Power Spectral Density (PSD)","text":"<ul> <li> <p>Frequency Analysis: Transform the image into the frequency domain to analyze the distribution of spatial frequencies.</p> </li> <li> <p>Scaling Laws: The PSD often follows a power law, indicative of fractal behavior.</p> </li> </ul>"},{"location":"dims/#practical-implications_1","title":"Practical Implications","text":""},{"location":"dims/#engineering-and-design","title":"Engineering and Design","text":"<ul> <li> <p>Surface Roughness: Understanding the fractal nature of surfaces can improve material design and coatings.</p> </li> <li> <p>Antenna Design: Fractal-shaped antennas can operate efficiently over multiple frequency bands.</p> </li> </ul>"},{"location":"dims/#environmental-science","title":"Environmental Science","text":"<ul> <li> <p>Erosion Patterns: Modeling soil erosion and river networks using fractal geometry.</p> </li> <li> <p>Climate Modeling: Analyzing cloud patterns and atmospheric turbulence.</p> </li> </ul>"},{"location":"dims/#art-and-aesthetics","title":"Art and Aesthetics","text":"<ul> <li> <p>Fractal Art: Creating visually appealing images using fractal algorithms.</p> </li> <li> <p>Texture Mapping: Enhancing visual realism in digital art and animations.</p> </li> </ul>"},{"location":"dims/#understanding-self-similarity-and-self-affinity-in-2d-fractals","title":"Understanding Self-Similarity and Self-Affinity in 2D Fractals","text":"<ul> <li> <p>Self-Similar Fractals: Patterns repeat exactly at different scales. Example: Sierpinski Carpet.</p> </li> <li> <p>Self-Affine Fractals: Scaling factors differ across axes. Natural terrains are self-affine because the vertical scale (elevation) and horizontal scales (latitude and longitude) scale differently.</p> </li> </ul>"},{"location":"dims/#example-analyzing-satellite-images","title":"Example: Analyzing Satellite Images","text":""},{"location":"dims/#steps","title":"Steps","text":"<ol> <li>Data Acquisition: Obtain high-resolution satellite images of a geographical area.</li> <li>Preprocessing: Convert images to grayscale and normalize.</li> <li>Fractal Analysis: Apply box-counting or PSD methods to calculate the fractal dimension.</li> <li>Interpretation: Use the fractal dimension to infer characteristics like terrain roughness or vegetation density.</li> </ol>"},{"location":"dims/#insights","title":"Insights","text":"<ul> <li> <p>Urban vs. Natural Areas: Urban regions may have different fractal dimensions compared to natural landscapes due to human-made structures.</p> </li> <li> <p>Environmental Changes: Changes in fractal dimension over time can indicate deforestation, desertification, or urban expansion.</p> </li> </ul>"},{"location":"dims/#3d-fractals","title":"3D Fractals","text":""},{"location":"dims/#4d-fractals","title":"4D Fractals","text":""},{"location":"discussion/","title":"Discussion","text":"<p>The failure of ecologists to use the term \"self-affine\" to describe fractal behavior appears to be limited to a few authors publishing in plant and forest ecology. Microbial ecologists (XXX) and marine ecologists (Seuront XXXX) seem to have a better understanding of self-affinity and its consequences.</p>"},{"location":"discussion/#closing-in-on-self-affinity-from-the-metabolic-scaling-theory","title":"Closing in on Self-Affinity from the Metabolic Scaling Theory","text":"<p>The misuse of the term \"self-similar\" for describing self-affine processes in ecology has gone largely unreported. Interestingly, some authors appear to be approaching the issue from different perspectives. Both Bentley et al. (2013) and Smith et al. (2014) report deviations from symmetry in branching, better predicting metabolism, hydraulics, and light interception in plants. Yet, neither explicitly refers to this behavior as \"self-affine,\" although their results are equivalent to how a self-affine object operates. For instance, Bentley et al. (2013) observed differences in scaling exponents at different-sized branching nodes within individual trees. Similarly, Smith et al. (2014) showed that path fractions (the ratio of minimum to maximum twig-to-trunk path lengths) varied from symmetric (self-similar) to highly asymmetric (self-affine).</p>"},{"location":"discussion/#demonstrations-of-self-affine-fractals","title":"Demonstrations of Self-Affine Fractals","text":"<p>Demonstrations of self-affine fractals resembling trees and plants, such as Barnsley's Fern (XX), have further solidified the concept of self-affinity in branching networks. The study of lacunarity, as proposed by Plotnick et al. (1996), supports the notion of self-affinity in hierarchical networks. Plotnick et al. found that tree seedlings exhibited clumping behavior around parent trees instead of a binomial random pattern, which aligns with the predictions of lacunarity in self-affine fractals.</p>"},{"location":"discussion/#a-fractal-theory-of-ecology","title":"A Fractal Theory of Ecology","text":"<p>Seely and Macklem (2012) proposed two null hypotheses regarding fractal variability in nature:</p> <ol> <li>Complex dissipative systems, such as the circulatory systems within animals and capillary networks in plants, emerge as self-optimized systems that dissipate energy in ways that maximize entropy production.</li> <li>The degree of variability in the system is proportional to the ratio of its maximum work output to its resting work output, reflecting the system\u2019s adaptability to change.</li> </ol> <p>These hypotheses relate closely to other discussions in ecology concerning fractals and the thermodynamics of metabolism in organisms (e.g., MST). MST also theorizes that hierarchical branching networks are optimized to maximize the delivery of substrates to active sites where metabolism takes place. The optimization of fractal networks allows organisms to balance metabolic demand with mass and energy flow, ultimately leading to predictable fractal dimensions.</p> <p>In contrast to Rubner\u2019s (1883) \"surface rule,\" which suggests that an organism\u2019s body scales its metabolism proportionally to its surface area with a \u2154 exponent, Kleiber (1932) showed that the surface rule was invalid. Instead, organisms scale their metabolism to body mass with a \\(3/4\\) exponent, as observed across 23 orders of magnitude in body size. This \\(3/4\\) exponent reflects the fractal nature of the metabolic scaling law proposed by WBE, which remains robust when applied to vascular organisms.</p>"},{"location":"discussion/#fractal-dimensions-of-non-vascular-organisms","title":"Fractal Dimensions of Non-Vascular Organisms","text":"<p>Colonies of single-celled organisms, such as bacteria, exhibit diffusion-limited aggregation (DLA), a self-similar fractal pattern. When substrate levels are not limiting, these colonies grow as uniform advancing fronts, following a fractal model described by the Eden Model and the Kardar-Parisi-Zhang (KPZ) equation. The body forms of primitive non-vascular land plants, such as liverworts, hornworts, and mosses, exhibit similar DLA fractal patterns. Without hierarchical branching supply networks, these organisms are self-limited in their ability to deliver substrates over long distances, relying instead on diffusion.</p> <p>Aquatic organisms without vascular structures, such as sponges and xenophyophores, have evolved hyperbolic geometries to maximize substrate delivery. These organisms bypass the need for hierarchical networks by leveraging turbulent mixing in aquatic environments, which allows them to compete effectively despite lacking vascularity. The fractal dimension of such organisms often aligns with the fractal geometry of turbulence (Kolmogorov turbulence, \\( \\beta = -\\frac{5}{3} \\)).</p>"},{"location":"discussion/#extended-applications-explaining-why-vascular-life-forms-dominate","title":"Extended Applications: Explaining Why Vascular Life Forms Dominate","text":"<p>The dominance of vascular organisms in terrestrial ecosystems can be explained by their ability to utilize turbulent and laminar fluid flows within their internal networks, enhancing substrate transport. The hypothesis proposed by Seely and Macklem (2012) that vascularity maximizes entropy production seems self-evident when comparing vascular and non-vascular organisms. Vascular organisms increase their rate of metabolism by facilitating and controlling convective forces, moving substrates to points where diffusion and enzyme kinetics take over.</p> <p>While the evolution of fractal forms is influenced by natural selection, the maximization of entropy production appears to be a fundamental mechanism underlying the self-affine fractal dimensions observed in organisms. Organisms with lower entropy production are typically constrained by external factors, such as gravity and resource availability, leading to a diversity of body forms that optimize resource utilization under specific environmental conditions.</p> <p>In 1985, Sernetz et al. suggested considering the organism as a \"bioreactor\"\u2014a volume-area hybrid where fractal surfaces maximize exchange through turbulent and diffusive motions. This view aligns with MST and supports the idea that fractal geometry in organisms reflects an optimization of mass transfer mechanisms. Although Mandelbrot (1982) suggested that self-affinity lacked a universally valid reduction to basic principles, the fundamental processes of fractional Brownian motion, Fickian diffusion, and convective motion by pulsatile or capillary action provide sufficient explanations for the emergence of self-affine fractal geometry in life forms.</p>"},{"location":"discussion/#toward-a-unified-theory","title":"Toward a Unified Theory","text":"<p>In ecology, the Zipf-Mandelbrot law has been used to describe relative abundance distributions (RAD) and species abundance distributions (SAD). Ecologists considering fractal analyses should be aware of the distinctions between self-similar and self-affine fractals, ensuring the appropriate methods are used for deriving affine fractal dimensions. The techniques used in this study, such as differential box counting and lacunarity analysis, are well-suited for spatial fractal dimensions in grayscale images, but other techniques (e.g., power spectrum analysis, detrended fluctuation analysis, rescaled range analysis) may offer further insights into fractal behavior in ecosystems.</p> <p>Further exploration of the fractal geometry of organisms may help to resolve questions about the role of entropy production in determining fractal dimensions. The authors believe that a unification of thermodynamics, information theory, the reduction law of metabolism, and Darwinian evolution could provide a comprehensive framework for understanding the fractal nature of life.</p>"},{"location":"glossary/","title":"Glossary of Self-Affine Fractal Properties","text":"<p>This glossary covers essential terms and equations related to self-affine fractal patterns in nature, including concepts like fractal dimensions, Hausdorff dimensions, and famous fractal patterns.</p>"},{"location":"glossary/#allometry","title":"Allometry","text":"<p>Definition: Allometry refers to the study of how the size of one part of an organism changes in relation to the size of the entire organism, or another part of the organism, as it grows. It often explores the relationship between the shape, structure, and function of living organisms as they scale up or down in size.</p>"},{"location":"glossary/#allometric","title":"Allometric","text":"<p>Definition: The term allometric is used to describe the relationship between different biological variables that change disproportionately relative to each other. For example, allometric scaling often refers to the way that physiological or morphological traits, such as metabolic rate or limb length, grow at different rates compared to the overall size of the organism.</p>"},{"location":"glossary/#isometry","title":"Isometry","text":"<p>Definition: Isometry refers to a type of scaling where all parts of an object or organism grow at the same rate, maintaining the same proportions as size increases or decreases. In other words, the shape and relative proportions remain constant as the size changes.</p>"},{"location":"glossary/#isometric","title":"Isometric","text":"<p>Definition: The term isometric describes a relationship where growth or scaling occurs equally in all dimensions, so the overall shape and proportions of the organism or object stay the same as its size changes. For example, if an organism grows isometrically, its limbs, body, and head would increase in size at the same rate, keeping the same shape throughout growth.</p>"},{"location":"glossary/#self-affinity","title":"Self-Affinity","text":"<p>Definition: Self-affinity refers to a property of fractals where the fractal appears similar to a part of itself when scaled by different factors along different axes. Unlike self-similar fractals, which are scaled uniformly, self-affine fractals require anisotropic scaling.</p> <p>Mathematical Representation:</p> <p>A self-affine transformation scales coordinates differently:</p> \\[ x' = \\lambda_x x, \\quad y' = \\lambda_y y, \\quad z' = \\lambda_z z \\] <p>where \\(\\lambda_x\\), \\(\\lambda_y\\), and \\(\\lambda_z\\) are scaling factors along the \\(x\\), \\(y\\), and \\(z\\) axes, respectively.</p>"},{"location":"glossary/#fractal","title":"Fractal","text":"<p>Definition: A fractal is a complex geometric shape exhibiting self-similarity at various scales. Fractals are characterized by fractional dimensions and are often generated by recursive or iterative processes.</p>"},{"location":"glossary/#fractal-dimension","title":"Fractal Dimension","text":"<p>Definition: The fractal dimension quantifies the complexity of a fractal by describing how detail in a pattern changes with the scale at which it is measured.</p> <p>Common Fractal Dimensions:</p> <ul> <li>Hausdorff Dimension</li> <li>Box-Counting Dimension</li> </ul>"},{"location":"glossary/#hausdorff-dimension","title":"Hausdorff Dimension","text":"<p>Definition: The Hausdorff dimension is a measure of a fractal's dimensionality that generalizes the notion of the dimension of a real vector space. It is defined using the concept of Hausdorff measure.</p> <p>Mathematical Representation:</p> <p>For a set \\(S\\), the Hausdorff dimension \\(D_H\\) is:</p> \\[ D_H = \\inf \\left\\{ d \\geq 0 \\mid H^d(S) = 0 \\right\\} \\] <p>where \\(H^d(S)\\) is the \\(d\\)-dimensional Hausdorff measure of \\(S\\).</p>"},{"location":"glossary/#box-counting-dimension","title":"Box-Counting Dimension","text":"<p>Definition: The box-counting dimension is an approximate method for calculating the fractal dimension by covering the fractal with boxes of size \\(\\varepsilon\\) and counting how the number of boxes \\(N(\\varepsilon)\\) changes as \\(\\varepsilon\\) decreases.</p> <p>Mathematical Representation:</p> \\[ D_B = \\lim_{\\varepsilon \\to 0} \\frac{\\log N(\\varepsilon)}{\\log (1/\\varepsilon)} \\]"},{"location":"glossary/#differential-box-counting","title":"Differential Box-Counting","text":"<p>Definition: Differential box-counting is an extension of the box-counting method used for estimating the fractal dimension of grayscale images. It accounts for intensity variations by partitioning the intensity axis.</p>"},{"location":"glossary/#riemann-zeta-function","title":"Riemann Zeta Function","text":"<p>Definition: The Riemann zeta function \\(\\zeta(s)\\) is a complex function important in number theory and mathematical analysis.</p> <p>Mathematical Representation:</p> \\[ \\zeta(s) = \\sum_{n=1}^\\infty \\frac{1}{n^s} \\] <p>for \\(\\Re(s) &gt; 1\\), and by analytic continuation elsewhere.</p>"},{"location":"glossary/#barnsley-fern","title":"Barnsley Fern","text":"<p>Definition: The Barnsley Fern is a fractal resembling a natural fern, generated using an Iterated Function System (IFS) with affine transformations.</p> <p>Iterated Function System Equations:</p> <p>The Barnsley Fern uses four affine transformations:</p> <ol> <li>Stem:</li> </ol> <p>[    f_1:    \\begin{cases}    x_{n+1} = 0 \\    y_{n+1} = 0.16 y_n    \\end{cases}    ]</p> <ol> <li>Successively smaller leaflets:</li> </ol> <p>[    f_2:    \\begin{cases}    x_{n+1} = 0.85 x_n + 0.04 y_n \\    y_{n+1} = -0.04 x_n + 0.85 y_n + 1.6    \\end{cases}    ]</p> <ol> <li>Largest left-hand leaflet:</li> </ol> <p>[    f_3:    \\begin{cases}    x_{n+1} = 0.2 x_n - 0.26 y_n \\    y_{n+1} = 0.23 x_n + 0.22 y_n + 1.6    \\end{cases}    ]</p> <ol> <li>Largest right-hand leaflet:</li> </ol> <p>[    f_4:    \\begin{cases}    x_{n+1} = -0.15 x_n + 0.28 y_n \\    y_{n+1} = 0.26 x_n + 0.24 y_n + 0.44    \\end{cases}    ]</p> <p>Each transformation is chosen with a specific probability.</p>"},{"location":"glossary/#famous-fractal-patterns","title":"Famous Fractal Patterns","text":""},{"location":"glossary/#mandelbrot-set","title":"Mandelbrot Set","text":"<p>Definition: The Mandelbrot set is a set of complex numbers \\(c\\) for which the sequence \\(z_{n+1} = z_n^2 + c\\) does not diverge when iterated from \\(z_0 = 0\\).</p>"},{"location":"glossary/#julia-set","title":"Julia Set","text":"<p>Definition: Julia sets are fractals generated by iterating the function \\(z_{n+1} = z_n^2 + c\\), where \\(c\\) is a complex parameter.</p>"},{"location":"glossary/#koch-curve","title":"Koch Curve","text":"<p>Definition: The Koch curve is a fractal constructed by recursively altering a straight line segment into a snowflake-like pattern.</p>"},{"location":"glossary/#sierpinski-triangle","title":"Sierpi\u0144ski Triangle","text":"<p>Definition: The Sierpi\u0144ski triangle is a fractal formed by recursively removing equilateral triangles from a larger equilateral triangle.</p>"},{"location":"glossary/#cantor-set","title":"Cantor Set","text":"<p>Definition: The Cantor set is created by repeatedly removing the middle third of a line segment, resulting in a fractal with zero measure but uncountably infinite points.</p>"},{"location":"glossary/#self-similarity","title":"Self-Similarity","text":"<p>Definition: Self-similarity is a property where a shape looks similar to a part of itself at different scales. In fractals, this means the pattern repeats itself at every scale.</p>"},{"location":"glossary/#scaling-laws","title":"Scaling Laws","text":"<p>Definition: Scaling laws describe how certain properties of a system change with size. In fractals, these laws relate the change in detail with the change in scale.</p>"},{"location":"glossary/#iterated-function-systems-ifs","title":"Iterated Function Systems (IFS)","text":"<p>Definition: An IFS is a method of constructing fractals using a set of contraction mappings on a complete metric space.</p>"},{"location":"glossary/#multi-fractals","title":"Multi-Fractals","text":"<p>Definition: Multi-fractals are generalizations of fractals that have multiple scaling rules, leading to complex patterns with varying fractal dimensions.</p>"},{"location":"glossary/#lacunarity","title":"Lacunarity","text":"<p>Definition: Lacunarity measures the texture or gaps within a fractal pattern. It quantifies how patterns fill space.</p>"},{"location":"glossary/#attractor","title":"Attractor","text":"<p>Definition: An attractor is a set of numerical values toward which a system tends to evolve. In fractals, strange attractors are associated with chaotic systems.</p>"},{"location":"glossary/#l-systems","title":"L-Systems","text":"<p>Definition: L-systems, or Lindenmayer systems, are a mathematical formalism for simulating plant growth and fractal patterns using string rewriting.</p>"},{"location":"glossary/#percolation-theory","title":"Percolation Theory","text":"<p>Definition: Percolation theory studies the movement and filtering of fluids through porous materials. It is related to fractals in modeling random media.</p>"},{"location":"glossary/#random-walk","title":"Random Walk","text":"<p>Definition: A random walk is a mathematical object describing a path consisting of random steps. In fractals, it models diffusion processes.</p>"},{"location":"glossary/#brownian-motion","title":"Brownian Motion","text":"<p>Definition: Brownian motion is the random movement of particles suspended in a fluid, a fractal process with a Hausdorff dimension of 2.</p>"},{"location":"glossary/#renormalization-group","title":"Renormalization Group","text":"<p>Definition: The renormalization group is a mathematical tool used to study systems with scale invariance, crucial in understanding phase transitions and fractals.</p>"},{"location":"glossary/#equations-summary","title":"Equations Summary","text":""},{"location":"glossary/#box-counting-dimension_1","title":"Box-Counting Dimension:","text":"\\[ D_B = \\lim_{\\varepsilon \\to 0} \\frac{\\log N(\\varepsilon)}{\\log (1/\\varepsilon)} \\]"},{"location":"glossary/#hausdorff-dimension_1","title":"Hausdorff Dimension:","text":"\\[ D_H = \\inf \\left\\{ d \\geq 0 \\mid H^d(S) = 0 \\right\\} \\]"},{"location":"glossary/#riemann-zeta-function_1","title":"Riemann Zeta Function:","text":"\\[ \\zeta(s) = \\sum_{n=1}^\\infty \\frac{1}{n^s} \\]"},{"location":"glossary/#self-affine-transformation","title":"Self-Affine Transformation:","text":"\\[ x' = \\lambda_x x, \\quad y' = \\lambda_y y, \\quad z' = \\lambda_z z \\]"},{"location":"glossary/#frequently-used-mathematical-equations","title":"Frequently Used Mathematical Equations","text":""},{"location":"glossary/#scaling-relation","title":"Scaling Relation","text":"<p>For self-affine fractals, the scaling relation between measurement scale \\(\\varepsilon\\) and the measured quantity \\(N(\\varepsilon)\\):</p> \\[ N(\\varepsilon) \\propto \\varepsilon^{-D} \\] <p>where \\(D\\) is the fractal dimension.</p>"},{"location":"glossary/#power-law-distribution","title":"Power Law Distribution","text":"<p>Fractal systems often exhibit power-law distributions:</p> \\[ P(x) \\propto x^{-\\alpha} \\] <p>where \\(P(x)\\) is the probability of occurrence of an event \\(x\\), and \\(\\alpha\\) is a positive constant.</p>"},{"location":"glossary/#conclusion","title":"Conclusion","text":"<p>This glossary provides foundational concepts and mathematical tools essential for understanding self-affine fractal patterns in nature. It covers key terms, definitions, famous fractal examples, and important equations that describe the properties and behaviors of fractals.</p>"},{"location":"installation/","title":"Creating a Python Environment","text":"<p>Download <code>pytorch-gpu.yaml</code></p>"},{"location":"installation/#install-mini-conda-and-mamba","title":"Install Mini-conda and Mamba","text":""},{"location":"installation/#mac","title":"Mac","text":"<ol> <li>Download the Miniconda installer for macOS from the official website.</li> <li>Open a terminal and run the following command to install Miniconda:     <pre><code>bash Miniconda3-latest-MacOSX-x86_64.sh\n</code></pre></li> <li>Follow the prompts to complete the installation.</li> <li>Install Mamba by running:     <pre><code>conda install mamba -n base -c conda-forge\n</code></pre></li> </ol>"},{"location":"installation/#windows","title":"Windows","text":"<ol> <li>Download the Miniconda installer for Windows from the official website.</li> <li>Run the installer and follow the prompts to complete the installation.</li> <li>Open the Anaconda Prompt from the Start Menu.</li> <li>Install Mamba by running:     <pre><code>conda install mamba -n base -c conda-forge\n</code></pre></li> </ol>"},{"location":"installation/#ubuntu-linux","title":"Ubuntu Linux","text":"<ol> <li>Download the Miniconda installer for Linux from the official website.</li> <li>Open a terminal and run the following command to install Miniconda:     <pre><code>bash Miniconda3-latest-Linux-x86_64.sh\n</code></pre></li> <li>Follow the prompts to complete the installation.</li> <li>Install Mamba by running:     <pre><code>conda install mamba -n base -c conda-forge\n</code></pre></li> </ol>"},{"location":"installation/#using-conda-mamba","title":"Using Conda (Mamba)","text":"<pre><code>git clone https://github.com/tyson-swetnam/fractal-notebooks\ncd notebooks\nmamba env create -f pytorch-gpu.yaml\n## Using Conda  (Mamba)\n\n```bash\ngit clone https://github.com/tyson-swetnam/fractal-notebooks\ncd notebooks\nmamba env create -f pytorch-gpu.yaml\n</code></pre>"},{"location":"installation/#ensuring-cuda-is-installed","title":"Ensuring CUDA is Installed","text":"<p>To leverage GPU acceleration with PyTorch, you need to ensure that CUDA is installed on your machine. Follow the steps below for your operating system:</p>"},{"location":"installation/#mac_1","title":"Mac","text":"<p>CUDA is not natively supported on macOS. You will need to use a Linux or Windows machine for CUDA support.</p>"},{"location":"installation/#windows_1","title":"Windows","text":"<ol> <li>Visit the NVIDIA CUDA Toolkit website.</li> <li>Select your operating system, architecture, and version.</li> <li>Download and run the installer.</li> <li>Follow the prompts to complete the installation.</li> <li>Verify the installation by running the following command in the Command Prompt:     <pre><code>nvcc --version\n</code></pre></li> </ol>"},{"location":"installation/#ubuntu-linux_1","title":"Ubuntu Linux","text":"<ol> <li>Visit the NVIDIA CUDA Toolkit website.</li> <li>Select your operating system, architecture, and version.</li> <li>Follow the instructions provided for your specific configuration.</li> <li>After installation, verify the installation by running:     <pre><code>nvcc --version\n</code></pre></li> </ol>"},{"location":"installation/#verifying-cuda-installation-in-python","title":"Verifying CUDA Installation in Python","text":"<p>After installing CUDA, you can verify that PyTorch can access the GPU by running the following Python code:</p> <pre><code>import torch\nprint(torch.cuda.is_available())\n</code></pre>"},{"location":"introduction/","title":"Introduction","text":"<p>\"Allometry\" is the study of organismal size and physiological rates of change in relation to body parts (Huxley 1932, 1950). The term \"allometric\" translates from Latin as \"different measure,\" while \"isometric\" means \"equal measure\" (Huxley and Tessier 1936). Allometric scaling refers to the way that physiological or morphological traits, such as metabolism or limb size, change at different rates compared to overall size of an organism. Isometric scaling maintains the same ratio of lengths, making the object appear identical at different scales.</p> <p>In 1975, Benoit Mandelbrot introduced the word 'fractal' to describe self-similar and irregular patterns found in nature (Mandelbrot 1977). In 1985 Mandelbrot published his book on self-affine fractals and fractal dimensions (Mandelbrot 1985). Mandelbrot later published on multifractals, 1/f noises, and Gaussian self-affinity in nature (Mandelbrot (2002, 2013))</p> <p></p> <p>Plate 1: Gaston Julia created so-called Julia sets using interative functions over 100 years ago. code written in Python.</p> <p></p> <p>Plate 2: The so-called Mandelbrot Set, named in honor of Benoit Mandelbrot. code written in Python. </p> <p>Mandelbrot was careful to point out that natural phenomena, including hierarchical branching networks in organisms, are \"fractal-like\" over a limited range, unlike true fractals, which repeat infinitely. In a review of the most widely cited research on fractals in biology, we found that vascular organisms and forests are almost exclusively referred to as being \"self-similar,\" and, critically, they were measured using self-similar fractal dimension techniques (Table 1).</p> <p>For a phenomenon to be self-similar, it must have the same appearance at all scales. This is clearly not the case for organisms, as allometric theory describes changes in appearance as they grow and age (Huxley 1932, Kleiber 1932). This misuse of terminology appears to have started as an oversight by authors incorporating fractals into thir research and affecting how ecologists think about scaling processes in relation to fractal dimension.</p> <p>In most cases, the misuse of \"self-similar\" has had limited impact on the field. For example, predictions from Metabolic Scaling Theory (MST) (West et al. 1999a, West et al. 1999b, Brown et al. 2002) remain unaffected since allometric equations are complementary to self-affinity. Acknowledging self-affinity may reconcile inconsistencies between MST and observed asymmetry in branching architectures (Bentley et al. 2013, Smith et al. 2014).</p>"},{"location":"introduction/#differentiating-between-self-similarity-and-self-affinity","title":"Differentiating Between Self-Similarity and Self-Affinity","text":"<p>Reported fractal dimensions of trees and forests using self-similar dimensional analysis are likely to be incorrect based on these facts. Specifically, papers that report the length dimension [Hausdorff-Besicovitch] or box-counting dimension [Minkowski-Bouligand] of hierarchical branching phenomena (leaves, branches, forests) (Table 1) are more problematic.</p> <p></p> <p>Plate 3: The Pythagoras Tree (Bosman 1942). Note: the fractal uses self-similar squares with a \\(45^\\circ\\) angle, and branches asymetrically in the positive y-axis. code written in Python.</p> <p>Mandelbrot (1985) explained how evaluating fractals using self-similar techniques yields inaccurate results for measuring self-affine fractals because self-affine processes change their dimension between local and global scales. Since vascular plants have self-affine geometries, measuring them with self-similar fractal dimensions is likely to produce spurious values, as demonstrated in this study.</p> <p></p> <p>Plate 3: A Pythagoras tree with a \\(30^\\circ\\) angle that also includes a length and width variable. Note: the fractal uses a self-affine dimension, where branch length and width decrease at a different rate. code written in Python.</p> <p>The basic fractal concept requires an object to exhibit a self-similar signal or shape, which can be measured as:</p> \\[ N \\propto \\frac{1}{\\varepsilon^{\\beta}} \\equiv \\varepsilon^{-\\beta} \\] <p>Equation 1</p> <p>where \\(N\\) is the number of scalars \\( \\varepsilon \\) required to measure the whole object, and \\( \\beta \\) is a scaling exponent. Mandelbrot (1983, 1985) showed that all \\( 1/f^{\\beta} \\) \"noises\" are self-affine, and \\( \\beta \\) can be transformatively related to a fractal dimension \\( \\alpha \\) via the Hurst exponent \\( H \\), such that \\( \\beta = 2\\alpha - H \\). Examples of \\( 1/f^{\\beta} \\) noises include white noise (\\( 1/f^0 \\)) and Brownian noise (\\( 1/f^2 \\)).</p> <p>A fractal object's topological dimension is given by \\( \\beta = \\frac{\\log N}{\\log \\frac{1}{\\varepsilon}} \\). A Euclidean object has a dimension \\( \\beta \\) equal to an integer (Mandelbrot 1983). For example, if \\( \\beta = 2 \\), the object is a square (\\( \\varepsilon^2 \\)), or a disk where \\( \\varepsilon \\) equals \\( \\pi \\times \\text{radius} \\), and the object's mass \\( m \\) is equivalent to:</p> \\[ m(\\varepsilon) \\propto \\varepsilon^2 \\] <p>When a portion of the object is removed, its new surface or mass is reduced by the factor \\( \\delta^{\\beta} \\), written as:</p> \\[ m(\\delta \\varepsilon) = \\delta^{\\beta} m(\\varepsilon) \\] <p>Equation 2</p>"},{"location":"introduction/#table-1-reported-fractal-dimensions-and-techniques-measuring-fractal-behavior-in-plants-or-forests","title":"Table 1: Reported fractal dimensions and techniques measuring fractal behavior in plants or forests","text":"Author(s) by Date Self-similarity Self-affinity Allometric Review (meta-analysis) Characteristic Measured Fractal Dimension(s) DOI/URL Rubner 1883 \u2713 Ueber den Einfluss der K\u00f6rpergr\u00f6\u00dfe auf Stoffwechsel DOI:  Kleiber 1932 \u2713 Body size and metabolism DOI:  Hemmingsen 1960 \u2713 Energy metabolism as related to body size and respiratory surface, and its evolution DOI:XX Ultsch 1974 \u2713 Metabolism and Skeleton size DOI:10.2307/2424317 Taylor et al. 1981 Maximum aerobic capacity DOI:10.1016/0034-5687(81)90075-X Mandelbrot 1982 \u2713 \u2713 Multiple Multiple DOI:10.7560/703544-005 Bradbury and Reichelt 1983 \u2713 \u2713 Dimensional analyses Box-counting, Information Dimension Sernetz et al. 1985 \u2713 \u2713 \u2713 Multiple Length DOI:10.1016/S0022-5193(85)80218-6 Morse et al. 1985 \u2713 Canopy Length DOI:10.1038/314731a0 Mandelbrot 1986 \u2713 \u2713 Multiple Multiple DOI:10.1016/B978-0-444-86995-1.50004-4 Prothero 1986 DOI:10.1016/0300-9629(86)90569-4 Frontier 1987 \u2713 \u2713 \u2713 Multiple Length DOI:10.1007/978-3-642-70880-0_9 Barnsley 1988 DOI:10.1007/978-1-4612-3784-6_1 Tatsumi et al. 1989 Roots Box Count URL Loehle 1990 DOI:10.1007/BF00153802 Obert et al. 1990 \u2713 Microbial Colony Box Count Mass DOI:10.1128/jb.172.3.1180-1185.1990 Sugihara and May 1990 \u2713 \u2713 \u2713 Multiple Multiple DOI:10.1016/0169-5347(90)90235-6 Zeide 1991 \u2713 Canopy Length DOI:0378-1127(91)90230-S Zeide and Gresham 1991 \u2713 Canopy Length DOI:10.1139/x91-169 Zeide and Pfeifer 1991 \u2713 Canopy Length DOI:10.1093/forestscience/37.5.1253 Fitter and Strickland 1992 Roots Length DOI:10.1111/j.1469-8137.1992.tb01110.x Milne 1992 \u2713 \u2713 \u2713 Multiple Length DOI:10.1086/285312 Milne et al. 1992 DOI:10.1016/0040-5809(92)90033-P Plotnick et al. 1993 Lacunarity Lorimer et al. 1994 \u2713 \u2713 \u2713 Multiple Length DOI:10.2737/NC-GTR-170 Sol\u00e9 and Manrubia 1995 \u2713 Canopy Box Count DOI:10.1006/jtbi.1995.0040 Tatsumi et al. 1995 DOI:10.1626/jcs.64.50 Plotnick 1995 DOI:10.2110/scn.95.36.0001 Calder 1996 Size and life history DOI: Loehle and Li 1996 \u2713 \u2713 Information DOI:10.1016/0304-3800(94)00177-4 Halley 1996 \u2713 1/f noises Power Spectral DOI:10.1016/0169-5347(96)81067-6 Plotnick et al. 1996 Canopy Gliding Box (lacunarity) DOI:10.2307/2265712 Weishampel et al. 1998 \u2713 Canopy Lacunarity DOI:10.1016/S0303-2647(97)00092-8 Zeide 1998 \u2713 Canopy Length DOI:10.1139/x98-139 West et al. 1998 DOI:xx Banavar, Maritan, &amp; Rinaldo 1999 Transportation networks DOI: West 1999 \u2713 \u2713 Branching Box Count DOI:10.1126/science.284.5420.1677 West et al. 1999 \u2713 \u2713 Branching DOI:10.1126/science.276.5309.122 Brown et al. 2000 \u2713 \u2713 \u2713 Multiple DOI:10.1073/pnas.97.11.6242 Li 2000 \u2713 \u2713 Patch Information, Box Count DOI:10.1006/jtbi.2000.2070 Dale 2000 Lacunarity DOI:10.1023/A:1008176601940 Zhu &amp; Bunn 2001 Cell oxygen sensing DOI:  Darveau et al. 2002 X Metabolism DOI:10.1038/417166a Hochachka et al. 2003 X X Body mass effects on metabolism DOI:10.1016/S1095-6433(02)00364-1 Enquist et al. 2002 \u2713 Canopy, Roots DOI:10.1038/nature01269 Fitter 2002 DOI:xx Halley et al. 2004 \u2713 DOI:10.1098/rspa.2004.1384 Drake and Weishampel 2000 \u2713 Canopy Multifractals DOI:10.1007/s004420050009 Eamus et al. 2002 Roots -- DOI:10.1071/FP02118 Alados et al. 2003 \u2713 Patch Information DOI:10.1016/S0304-3800(02)00268-1 Zhang et al. 2007 Canopy Length DOI:10.1016/j.ecolmodel.2006.08.002 Enquist et al. 2010 \u2713 Canopy, Roots -- DOI:10.1098/rspb.2010.1080 West et al. 2010 DOI:10.1038/s41586-019-0976-6 Savage et al. 2010 DOI:10.1073/pnas.1012194108 Seuront 2011 \u2713 \u2713 \u2713 \u2713 Multiple DOI:10.1016/j.physa.2010.09.025 Brummer et al. 2017 DOI:10.1371/journal.pcbi.1005394 Husain et al. 2022a DOI:10.3390/fractalfract6020089 Husain et al. 2022b DOI:10.3390/fractalfract6070379 Loke &amp; Chisholm 2022 Box Counting Fischer &amp; Jucker 2023 \u2713 \u2713 Box Counting DOI:10.1111/1365-2745.14244 Ain et al. 2024 \u2713 \u2713 Maryenko &amp; Stepanenko 2024 \u2713 \u2713 box-counting, contour-scaling Brain tissue Authors Year \u2713 \u2713 \u2713 \u2713 DOI: ---"},{"location":"methods/","title":"Methods","text":"<p>Today, there are numerous numerical and analytical tools for evaluating fractal dimensions. Fractal dimension can be evaluated in binary (e.g., presence vs. absence) or continuous values (e.g., grayscale). An important implication of evaluating organisms, specifically their hierarchical branching networks, is that their distribution of mass is expected to scale anisotropically across their various branching orders.</p>"},{"location":"methods/#metabolic-scaling-theory","title":"Metabolic Scaling Theory","text":"<p>Metabolic Scaling Theory (MST) makes quantitative predictions about the fractal dimension of hierarchical branching networks in both three-dimensional and two-dimensional space. MST was primarily formulated by the authors West, Brown, and Enquist (hereafter WBE) (West 1999; West et al. 1999, 2009; Enquist et al. 1998, 1999, 2009; Brown and West 2000; Brown et al. 2004). West et al. (1999) provide the theoretical framework from which MST is based. Numerous papers have followed, supporting MST\u2019s theoretical strengths and refuting its weaknesses when applied to real-world phenomena. Despite its weaknesses, the theory continues to be modified and improved upon, gaining momentum as a useful null model for predicting natural phenomena.</p> <p>Relative to the fractal dimensions of vascular plants, MST incorporates different power-law functions with various scaling exponents to predict branching geometry, growth rates, and size. The MST authors do not use the adjective \"self-affine\" to describe the fractal-like behavior; instead, they state the systems are self-similar (Table 1), which we argue is syntactically incorrect. This misuse of terminology does not affect the robustness of MST\u2019s predictions and, in some cases, should help resolve questions about observed asymmetry (Smith et al. 2014).</p> <p>Allometric relationships are typically written as a power-law:</p> \\[ f(\\varepsilon) = C \\varepsilon^{\\alpha} \\] <p>Equation 9</p> <p>where \\(C\\) is the prefactor or normalization coefficient, \\( \\varepsilon \\) is a measure of size (such as the radii of a meristem, the length of a conduit, or the surface area of a leaf), and \\( \\alpha \\) is the dynamic exponent (West et al. 1999, 2009; Brown et al. 2004). For example, the relationship of basal metabolic rate \\( B \\) to body mass \\( M \\) can be given as:</p> \\[ B \\propto M^{3/4} \\] <p>WBE show that for a resource distribution network such as a tree, with continuous branching from the trunk to the petioles or root terminals, the primary size measures (e.g., radius \\(r\\) or path length \\(l\\)) change in regular ways between the \\(k\\) to \\(k+1\\) branching levels, often referred to as bifurcations (e.g., bifurcation for two daughter branches, trifurcation for three branches). For the general case, the bifurcation rate, also called the branching ratio of \\(r\\) and \\(l\\), can be written as:</p> \\[ \\xi = \\frac{r_{k+1}}{r_k} = n^{-\\frac{1}{2}}  \\quad \\text{and} \\quad  \\gamma = \\frac{l_{k+1}}{l_k} = n^{-\\frac{1}{3}} \\] <p>Equation 10</p> <p>where \\( \\xi \\) is the bifurcation rate, \\( \\gamma \\) is the ratio of branch lengths respective to any \\(n\\) number of daughter branches, and \\(k\\) refers to the branching order. The invariance leads to \\( \\gamma = n^{-1/3} \\) and \\( \\xi = n^{-1/2} \\), and these scaling parameters are equivalent to a Lindenmayer system (L-system), which is itself a space-filling Peano curve (Peano 1890) that uses a formal grammar.</p> <p>The volume \\( V_B \\) of a branching network in space can be described as:</p> \\[ V_B = \\pi \\sum_{k=0}^{N} n_k r_k^2 l_k \\approx \\gamma \\xi^2 V_N \\left( 1 - n^{-4/3} \\right) V_N \\] <p>Equation 11</p> <p>where \\( n_k \\) is an arbitrary branching level, \\( V_N \\) is the total volume space occupied, and \\( l_N \\) is the length, while the branching ratios are given in Equation 10 (West et al. 2009). </p> <p>Distinguishing the filled volume in which a branching network occupies is equivalent to:</p> \\[ v_n \\propto l_n^3 \\] <p>In Euclidean space, this can be approximated by a sphere:</p> \\[ v_n = \\frac{4}{3} \\pi l_n^{2/3} \\] <p>Equation 12</p> <p>This gives the total volume filled by the network as:</p> \\[ V_{\\text{net}} = n_k v_k \\propto n_k l_k^3 \\] <p>Equation 13</p> <p>where the occupied volume \\( V_{\\text{net}} \\) is preserved throughout and can be approximated at any arbitrary branching level \\(k\\) as \\(V_{\\text{net}} \\propto n_k l_k^3\\).</p> <p>To derive the mass \\( M_k \\) of an individual by its branch volume \\(V_B\\), a non-fractal quantity is expressed as:</p> \\[ V_B = v_i L^3 \\] <p>Equation 14</p> <p>where \\(v_i\\) is the volume in units of length \\(L^3\\). If we display a three-dimensional object in two dimensions, looking perpendicular to the principal axis of the network, the area \\(A \\approx V_{\\text{net}}^{2/3}\\) from Equation 7 can be expressed as:</p> \\[ A \\propto n^{2/3} l_N^{2} \\] <p>Equation 15</p> <p>Measuring such an object with boxes \\( \\varepsilon^2 \\) of area becomes:</p> \\[ A \\propto V_B^{1/2} l_N^{3/2} r_N \\propto L^{3/2} l_N^{3/2} r_N \\] <p>Equation 16</p> <p>The number of boxes required to measure the object is:</p> \\[ N(\\varepsilon) \\propto \\frac{A}{\\varepsilon^2} \\propto L^{3/2} l_N^{3/2} (\\varepsilon r_N) \\] <p>Equation 17</p> <p>As \\( \\varepsilon \\to 0 \\), \\( \\dim \\to 2 \\), and for the smallest observed branch size, \\( \\varepsilon \\), it becomes:</p> \\[ N(\\varepsilon) \\propto \\varepsilon^{3/2} \\] <p>revealing the fractal dimension of branching network volume to be \\( d = \\frac{3}{2} \\) (West et al., unpublished).</p>"},{"location":"results/","title":"Results","text":"<p>Images of different computer-generated Lindenmayer systems (i.e., fractal trees) were analyzed using the open-source image analysis software FracLac. First, the fractal dimension was calculated using regular box-counting, and then with the differential box-count technique. The box-count analysis estimated the objects to have fractal dimensions between \\( 1.81 \\pm 0.056 &lt; D_B &lt; 1.90 \\pm 0.66 \\); however, the differential box-count mass dimension was found to be lower on average, with \\( D_M = 1.60 \\pm 0.10 \\) (Table 1).</p> <p>In Tables 1-X and Figures X-X, the observed mass dimensions of x-ray leaves, branches, and roots are statistically indistinguishable from the MST and fractional Brownian motion (fBm) predictions of \\( \\alpha = 3/2 \\).</p> <p>From Equation 18, a differential mass dimension for such an image is expected to equal \\( 4/3 \\) rather than \\( 3/2 \\) (see Supplementary Information).</p>"},{"location":"results/#table-1-fractal-mass-dimension-d_m-pm-mu-textse-and-coefficient-of-variation-cv","title":"Table 1: Fractal mass dimension \\( d_m \\pm \\mu \\text{SE} \\) and coefficient of variation (CV)","text":"\\[ \\text{CV} = \\frac{\\sigma}{\\mu} \\] <p>where \\( \\sigma \\) is the standard deviation over the mean number of pixels per box. The associated lacunarity \\( \\Lambda \\) and CV are also reported.</p> Fractal Type Pixels \\( d_m \\pm \\mu \\text{SE} \\) \\( \\mu r^2 \\) \\( d_m (\\frac{\\sigma}{\\mu}) \\) \\( \\Lambda \\) \\( \\Lambda (\\frac{\\sigma}{\\mu}) \\) Peano Curve 1 (square) 756,030 1.846 \u00b1 0.100 0.9966 0.0111 0.0133 0.2128 Peano Curve 2 (rounded) 1,440,000 1.803 \u00b1 0.109 0.9959 0.0161 0.0713 0.1348 H-fractal 3,932,289 1.760 \u00b1 0.124 0.9945 0.0102 0.1142 0.0746 Pythagoras Tree 1 5,000,000 1.607 \u00b1 0.106 0.9953 0.0030 0.7003 0.0871 Pythagoras Tree 2 393,216 1.655 \u00b1 0.075 0.9976 0.0108 0.2267 0.0899 Barnsley\u2019s Fern 180,000 1.576 \u00b1 0.073 0.9973 0.0116 0.3787 0.0680 Fibonacci Tree 348,140 1.470 \u00b1 0.074 0.9969 0.0118 0.8680 0.0657"},{"location":"results/#table-2-observed-local-mass-fractal-dimension-of-five-different-types-of-leaves","title":"Table 2: Observed local mass fractal dimension of five different types of leaves","text":"<p>The results were obtained using the FracLac Differential Box Count for a power series with an exponentially increasing box size factor of 0.1.</p> Image Pixels \\( d_M = \\ln(\\mu_\\varepsilon) / \\ln \\varepsilon \\) \\( \\mu r^2 \\) \\( \\mu \\text{SE} \\) \\( CV (\\frac{\\sigma}{\\mu}) \\) Coleus 144,316 1.5384 0.9938 0.1008 0.0038 Fig 315,495 1.4844 0.9918 0.1123 0.0026 Nasturtium 1,115,114 1.5525 0.9969 0.0880 0.0010 Ginkgo 1,086,596 1.5135 0.9978 0.0705 0.0020 Fern 581,196 1.5083 0.9968 0.1268 0.0064"},{"location":"results/#table-3-observed-local-mass-fractal-dimension-of-three-branching-networks","title":"Table 3: Observed local mass fractal dimension of three branching networks","text":"<p>Results were obtained using FracLac Differential Box Count for a power series with an exponentially increasing box size factor of 0.1.</p> Image Pixels \\( d_M = \\ln(\\mu_\\varepsilon) / \\ln \\varepsilon \\) \\( \\mu r^2 \\) \\( \\mu \\text{SE} \\) \\( CV (\\frac{\\sigma}{\\mu}) \\) Single branch 255,285 1.4946 0.9953 0.0850 0.0024 Maple branches 473,450 1.4775 0.9944 0.0920 0.0057 Maple root 617,312 1.4549 0.9970 0.0668 0.0016"},{"location":"results/#table-4-aerial-lidar-canopy-height-models-chm-over-various-forest-types","title":"Table 4: Aerial LiDAR Canopy Height Models (CHM) over various forest types","text":"<p>Results were obtained using FracLac Differential Box Count for a power series with an exponentially increasing box size factor of 0.1. The predicted mass fractal dimension is \\( \\frac{3}{2} \\) or 1.5.</p> Image Pixels Mass Dimension \\( d_M \\) \\( \\mu r^2 \\) \\( \\mu \\text{SE} \\) \\( CV (\\frac{\\sigma}{\\mu}) \\) Lowland Rainforest 361,201 1.3313 0.9860 0.1969 0.0128 Pine/Hardwood (South Carolina) 362,403 1.5223 0.9898 0.1919 0.0135 Sierra Madre Oaks (Arizona) 362,404 1.4973 0.9886 0.1988 0.0116 Western Ponderosa Pine (New Mexico) 361,802 1.4566 0.9847 0.2252 0.0144 Southwest Mixed Conifer (New Mexico) 361,802 1.5319 0.9869 0.2190 0.0177 Southwest Spruce-Fir (New Mexico) 361,802 1.5355 0.9862 0.2255 0.0139"},{"location":"notebooks/dbc/","title":"Differential Box Counting","text":"In\u00a0[2]: Copied! <pre>import numpy as np\nimport cv2\nfrom numba import cuda\nimport math\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport ipywidgets as widgets\nfrom IPython.display import display\n</pre> import numpy as np import cv2 from numba import cuda import math import matplotlib.pyplot as plt %matplotlib inline  import ipywidgets as widgets from IPython.display import display  <pre>\n---------------------------------------------------------------------------\nModuleNotFoundError                       Traceback (most recent call last)\nCell In[2], line 2\n      1 import numpy as np\n----&gt; 2 import cv2\n      3 from numba import cuda\n      4 import math\n\nModuleNotFoundError: No module named 'cv2'</pre> In\u00a0[3]: Copied! <pre>import os\n# Prompt the user for the file path\nfile_path = input(\"Please enter the file path (.png, .jpg, .jpeg, .tif, .txt, .csv): \")\n\n# Check if the file exists\nif not os.path.isfile(file_path):\n    print(\"File not found. Please check the path and try again.\")\nelse:\n    # Determine the file extension\n    _, file_extension = os.path.splitext(file_path)\n    file_extension = file_extension.lower()\n</pre> import os # Prompt the user for the file path file_path = input(\"Please enter the file path (.png, .jpg, .jpeg, .tif, .txt, .csv): \")  # Check if the file exists if not os.path.isfile(file_path):     print(\"File not found. Please check the path and try again.\") else:     # Determine the file extension     _, file_extension = os.path.splitext(file_path)     file_extension = file_extension.lower()  <pre>File not found. Please check the path and try again.\n</pre> In\u00a0[3]: Copied! <pre>def load_image_file(file_path):\n    import cv2\n    # Load the image in unchanged mode to preserve bit depth\n    img = cv2.imread(file_path, cv2.IMREAD_UNCHANGED)\n    if img is None:\n        raise ValueError(\"The file is not a valid image or is corrupted.\")\n    else:\n        # Convert to grayscale if it's a color image\n        if len(img.shape) == 3:\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n\n        # Check data type and normalize accordingly\n        if img.dtype == np.uint16:\n            print(\"16-bit image detected.\")\n            max_intensity = 65535\n        elif img.dtype == np.uint8:\n            print(\"8-bit image detected.\")\n            max_intensity = 255\n        else:\n            print(f\"{img.dtype} image detected.\")\n            max_intensity = img.max()\n        \n        # Normalize the image to the range [0, max_intensity]\n        img = cv2.normalize(img, None, 0, max_intensity, cv2.NORM_MINMAX).astype(img.dtype)\n        \n        return img, max_intensity\n</pre> def load_image_file(file_path):     import cv2     # Load the image in unchanged mode to preserve bit depth     img = cv2.imread(file_path, cv2.IMREAD_UNCHANGED)     if img is None:         raise ValueError(\"The file is not a valid image or is corrupted.\")     else:         # Convert to grayscale if it's a color image         if len(img.shape) == 3:             img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)          # Check data type and normalize accordingly         if img.dtype == np.uint16:             print(\"16-bit image detected.\")             max_intensity = 65535         elif img.dtype == np.uint8:             print(\"8-bit image detected.\")             max_intensity = 255         else:             print(f\"{img.dtype} image detected.\")             max_intensity = img.max()                  # Normalize the image to the range [0, max_intensity]         img = cv2.normalize(img, None, 0, max_intensity, cv2.NORM_MINMAX).astype(img.dtype)                  return img, max_intensity  In\u00a0[4]: Copied! <pre>def load_large_float_file(file_path):\n    import numpy as np\n\n    # Determine the delimiter based on the file extension\n    delimiter = ',' if file_path.endswith('.csv') else None  # None means any whitespace\n\n    # Get the file size\n    file_size = os.path.getsize(file_path)\n    print(f\"File size: {file_size / (1024 ** 3):.2f} GB\")\n\n    # Read the first line to check for header and estimate columns\n    with open(file_path, 'r') as f:\n        first_line = f.readline()\n        # Try to parse the first line as floats\n        try:\n            first_values = [float(val) for val in first_line.strip().split(delimiter)]\n            header = False\n            num_cols = len(first_values)\n            print(\"No header detected.\")\n        except ValueError:\n            # First line is not numeric, assume it's a header\n            header = True\n            print(\"Header detected. Skipping the header line.\")\n            # Read the next line to get number of columns\n            second_line = f.readline()\n            first_values = [float(val) for val in second_line.strip().split(delimiter)]\n            num_cols = len(first_values)\n        # Close the file to reset the pointer\n        f.close()\n\n    # Read the data into a list of arrays\n    data_list = []\n    chunk_size = 10 ** 6  # Adjust based on available memory\n    total_rows = 0\n    max_value = -np.inf\n    min_value = np.inf\n\n    print(\"Reading the data in chunks...\")\n    with open(file_path, 'r') as f:\n        if header:\n            next(f)  # Skip the header line\n        for i, line in enumerate(f):\n            values = line.strip().split(delimiter)\n            try:\n                values = [float(val) for val in values]\n            except ValueError:\n                print(f\"Non-numeric data found on line {i+2 if header else i+1}. Skipping this line.\")\n                continue  # Skip lines with non-numeric data\n            data_list.append(values)\n            if len(data_list) &gt;= chunk_size:\n                chunk_array = np.array(data_list, dtype=np.float32)\n                max_value = max(max_value, np.nanmax(chunk_array))\n                min_value = min(min_value, np.nanmin(chunk_array))\n                total_rows += chunk_array.shape[0]\n                data_list = []  # Reset the list for the next chunk\n\n        # Handle the last chunk\n        if data_list:\n            chunk_array = np.array(data_list, dtype=np.float32)\n            max_value = max(max_value, np.nanmax(chunk_array))\n            min_value = min(min_value, np.nanmin(chunk_array))\n            total_rows += chunk_array.shape[0]\n\n    print(f\"Total rows: {total_rows}, Columns per row: {num_cols}\")\n    print(f\"Data range: min={min_value}, max={max_value}\")\n\n    # Concatenate all chunks to form the full array\n    # Note: For very large datasets, consider processing without concatenation\n    img = np.array(data_list, dtype=np.float32)\n    max_intensity = max_value\n\n    return img, max_intensity\n</pre> def load_large_float_file(file_path):     import numpy as np      # Determine the delimiter based on the file extension     delimiter = ',' if file_path.endswith('.csv') else None  # None means any whitespace      # Get the file size     file_size = os.path.getsize(file_path)     print(f\"File size: {file_size / (1024 ** 3):.2f} GB\")      # Read the first line to check for header and estimate columns     with open(file_path, 'r') as f:         first_line = f.readline()         # Try to parse the first line as floats         try:             first_values = [float(val) for val in first_line.strip().split(delimiter)]             header = False             num_cols = len(first_values)             print(\"No header detected.\")         except ValueError:             # First line is not numeric, assume it's a header             header = True             print(\"Header detected. Skipping the header line.\")             # Read the next line to get number of columns             second_line = f.readline()             first_values = [float(val) for val in second_line.strip().split(delimiter)]             num_cols = len(first_values)         # Close the file to reset the pointer         f.close()      # Read the data into a list of arrays     data_list = []     chunk_size = 10 ** 6  # Adjust based on available memory     total_rows = 0     max_value = -np.inf     min_value = np.inf      print(\"Reading the data in chunks...\")     with open(file_path, 'r') as f:         if header:             next(f)  # Skip the header line         for i, line in enumerate(f):             values = line.strip().split(delimiter)             try:                 values = [float(val) for val in values]             except ValueError:                 print(f\"Non-numeric data found on line {i+2 if header else i+1}. Skipping this line.\")                 continue  # Skip lines with non-numeric data             data_list.append(values)             if len(data_list) &gt;= chunk_size:                 chunk_array = np.array(data_list, dtype=np.float32)                 max_value = max(max_value, np.nanmax(chunk_array))                 min_value = min(min_value, np.nanmin(chunk_array))                 total_rows += chunk_array.shape[0]                 data_list = []  # Reset the list for the next chunk          # Handle the last chunk         if data_list:             chunk_array = np.array(data_list, dtype=np.float32)             max_value = max(max_value, np.nanmax(chunk_array))             min_value = min(min_value, np.nanmin(chunk_array))             total_rows += chunk_array.shape[0]      print(f\"Total rows: {total_rows}, Columns per row: {num_cols}\")     print(f\"Data range: min={min_value}, max={max_value}\")      # Concatenate all chunks to form the full array     # Note: For very large datasets, consider processing without concatenation     img = np.array(data_list, dtype=np.float32)     max_intensity = max_value      return img, max_intensity   In\u00a0[5]: Copied! <pre>from numba import cuda\n\n# CUDA kernel for computing N(s) for a given scale s\n@cuda.jit\ndef compute_ns(img, s, Ns, max_intensity):\n    y, x = cuda.grid(2)\n    rows, cols = img.shape\n    nx = (cols + s - 1) // s  # Number of boxes along x\n    ny = (rows + s - 1) // s  # Number of boxes along y\n\n    if x &lt; nx and y &lt; ny:\n        z_min = max_intensity\n        z_max = 0\n        for i in range(s):\n            for j in range(s):\n                xi = x * s + i\n                yj = y * s + j\n                if xi &lt; cols and yj &lt; rows:\n                    val = img[yj, xi]\n                    if val &lt; z_min:\n                        z_min = val\n                    if val &gt; z_max:\n                        z_max = val\n        n = math.ceil((z_max - z_min) / s) + 1\n        Ns[y, x] = n\n</pre> from numba import cuda  # CUDA kernel for computing N(s) for a given scale s @cuda.jit def compute_ns(img, s, Ns, max_intensity):     y, x = cuda.grid(2)     rows, cols = img.shape     nx = (cols + s - 1) // s  # Number of boxes along x     ny = (rows + s - 1) // s  # Number of boxes along y      if x &lt; nx and y &lt; ny:         z_min = max_intensity         z_max = 0         for i in range(s):             for j in range(s):                 xi = x * s + i                 yj = y * s + j                 if xi &lt; cols and yj &lt; rows:                     val = img[yj, xi]                     if val &lt; z_min:                         z_min = val                     if val &gt; z_max:                         z_max = val         n = math.ceil((z_max - z_min) / s) + 1         Ns[y, x] = n  In\u00a0[6]: Copied! <pre># Import necessary libraries\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Enable interactive plotting\n%matplotlib widget\n\n# Prompt the user for the file path\nfile_path = input(\"Please enter the file path (.png, .jpg, .jpeg, .tif, .txt, .csv): \")\n\n# Check if the file exists\nif not os.path.isfile(file_path):\n    print(\"File not found. Please check the path and try again.\")\nelse:\n    # Determine the file extension\n    _, file_extension = os.path.splitext(file_path)\n    file_extension = file_extension.lower()\n    \n    # Function to load image files\n    def load_image_file(file_path):\n        import cv2\n        # Load the image in unchanged mode to preserve bit depth\n        img = cv2.imread(file_path, cv2.IMREAD_UNCHANGED)\n        if img is None:\n            raise ValueError(\"The file is not a valid image or is corrupted.\")\n        else:\n            # Convert to grayscale if it's a color image\n            if len(img.shape) == 3:\n                img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    \n            # Check data type and normalize accordingly\n            if img.dtype == np.uint16:\n                print(\"16-bit image detected.\")\n                max_intensity = 65535\n            elif img.dtype == np.uint8:\n                print(\"8-bit image detected.\")\n                max_intensity = 255\n            else:\n                print(f\"{img.dtype} image detected.\")\n                max_intensity = img.max()\n            \n            # Normalize the image to the range [0, max_intensity]\n            img = cv2.normalize(img, None, 0, max_intensity, cv2.NORM_MINMAX).astype(img.dtype)\n            \n            return img, max_intensity\n    \n    # Function to load large float files with header handling\n    def load_large_float_file(file_path):\n        import numpy as np\n\n        # Determine the delimiter based on the file extension\n        delimiter = ',' if file_path.endswith('.csv') else None  # None means any whitespace\n\n        # Get the file size\n        file_size = os.path.getsize(file_path)\n        print(f\"File size: {file_size / (1024 ** 3):.2f} GB\")\n\n        # Read the first line to check for header and estimate columns\n        with open(file_path, 'r') as f:\n            first_line = f.readline()\n            # Try to parse the first line as floats\n            try:\n                first_values = [float(val) for val in first_line.strip().split(delimiter)]\n                header = False\n                num_cols = len(first_values)\n                print(\"No header detected.\")\n            except ValueError:\n                # First line is not numeric, assume it's a header\n                header = True\n                print(\"Header detected. Skipping the header line.\")\n                # Read the next line to get number of columns\n                second_line = f.readline()\n                first_values = [float(val) for val in second_line.strip().split(delimiter)]\n                num_cols = len(first_values)\n            # Close the file to reset the pointer\n            f.close()\n\n        # Read the data into a list of arrays\n        data_list = []\n        chunk_size = 10 ** 6  # Adjust based on available memory\n        total_rows = 0\n        max_value = -np.inf\n        min_value = np.inf\n\n        print(\"Reading the data in chunks...\")\n        with open(file_path, 'r') as f:\n            if header:\n                next(f)  # Skip the header line\n            for i, line in enumerate(f):\n                values = line.strip().split(delimiter)\n                try:\n                    values = [float(val) for val in values]\n                except ValueError:\n                    print(f\"Non-numeric data found on line {i+2 if header else i+1}. Skipping this line.\")\n                    continue  # Skip lines with non-numeric data\n                data_list.append(values)\n                if len(data_list) &gt;= chunk_size:\n                    chunk_array = np.array(data_list, dtype=np.float32)\n                    max_value = max(max_value, np.nanmax(chunk_array))\n                    min_value = min(min_value, np.nanmin(chunk_array))\n                    total_rows += chunk_array.shape[0]\n                    data_list = []  # Reset the list for the next chunk\n\n            # Handle the last chunk\n            if data_list:\n                chunk_array = np.array(data_list, dtype=np.float32)\n                max_value = max(max_value, np.nanmax(chunk_array))\n                min_value = min(min_value, np.nanmin(chunk_array))\n                total_rows += chunk_array.shape[0]\n\n        print(f\"Total rows: {total_rows}, Columns per row: {num_cols}\")\n        print(f\"Data range: min={min_value}, max={max_value}\")\n\n        # Concatenate all chunks to form the full array\n        img = np.array(data_list, dtype=np.float32)\n        max_intensity = max_value\n\n        return img, max_intensity\n    \n    # Main code block\n    try:\n        if file_extension in ['.png', '.jpg', '.jpeg', '.tif']:\n            img, max_intensity = load_image_file(file_path)\n        elif file_extension in ['.txt', '.csv']:\n            img, max_intensity = load_large_float_file(file_path)\n        else:\n            raise ValueError(\"Unsupported file type.\")\n        \n        image_name = os.path.basename(file_path)\n        print(f\"Loaded File: {image_name}\")\n        \n        # Create an interactive figure\n        fig, ax = plt.subplots()\n        im = ax.imshow(img, cmap='gray', origin='upper')\n        ax.set_title('Loaded Data')\n        ax.axis('on')  # Show axes to display coordinates\n        \n        # Enable zooming and panning\n        fig.canvas.toolbar_visible = True\n        fig.canvas.header_visible = False\n        fig.canvas.footer_visible = False\n\n        # Function to handle clicks\n        def onclick(event):\n            if event.inaxes == ax:\n                x = int(event.xdata + 0.5)\n                y = int(event.ydata + 0.5)\n                if x &gt;= 0 and x &lt; img.shape[1] and y &gt;= 0 and y &lt; img.shape[0]:\n                    pixel_value = img[y, x]\n                    print(f\"Clicked at x={x}, y={y}, value={pixel_value}\")\n                else:\n                    print(\"Clicked outside image bounds\")\n        \n        # Connect the click event handler\n        cid = fig.canvas.mpl_connect('button_press_event', onclick)\n        plt.show()\n    except Exception as e:\n        print(f\"Error: {e}\")\n</pre> # Import necessary libraries import os import numpy as np import matplotlib.pyplot as plt  # Enable interactive plotting %matplotlib widget  # Prompt the user for the file path file_path = input(\"Please enter the file path (.png, .jpg, .jpeg, .tif, .txt, .csv): \")  # Check if the file exists if not os.path.isfile(file_path):     print(\"File not found. Please check the path and try again.\") else:     # Determine the file extension     _, file_extension = os.path.splitext(file_path)     file_extension = file_extension.lower()          # Function to load image files     def load_image_file(file_path):         import cv2         # Load the image in unchanged mode to preserve bit depth         img = cv2.imread(file_path, cv2.IMREAD_UNCHANGED)         if img is None:             raise ValueError(\"The file is not a valid image or is corrupted.\")         else:             # Convert to grayscale if it's a color image             if len(img.shape) == 3:                 img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)                  # Check data type and normalize accordingly             if img.dtype == np.uint16:                 print(\"16-bit image detected.\")                 max_intensity = 65535             elif img.dtype == np.uint8:                 print(\"8-bit image detected.\")                 max_intensity = 255             else:                 print(f\"{img.dtype} image detected.\")                 max_intensity = img.max()                          # Normalize the image to the range [0, max_intensity]             img = cv2.normalize(img, None, 0, max_intensity, cv2.NORM_MINMAX).astype(img.dtype)                          return img, max_intensity          # Function to load large float files with header handling     def load_large_float_file(file_path):         import numpy as np          # Determine the delimiter based on the file extension         delimiter = ',' if file_path.endswith('.csv') else None  # None means any whitespace          # Get the file size         file_size = os.path.getsize(file_path)         print(f\"File size: {file_size / (1024 ** 3):.2f} GB\")          # Read the first line to check for header and estimate columns         with open(file_path, 'r') as f:             first_line = f.readline()             # Try to parse the first line as floats             try:                 first_values = [float(val) for val in first_line.strip().split(delimiter)]                 header = False                 num_cols = len(first_values)                 print(\"No header detected.\")             except ValueError:                 # First line is not numeric, assume it's a header                 header = True                 print(\"Header detected. Skipping the header line.\")                 # Read the next line to get number of columns                 second_line = f.readline()                 first_values = [float(val) for val in second_line.strip().split(delimiter)]                 num_cols = len(first_values)             # Close the file to reset the pointer             f.close()          # Read the data into a list of arrays         data_list = []         chunk_size = 10 ** 6  # Adjust based on available memory         total_rows = 0         max_value = -np.inf         min_value = np.inf          print(\"Reading the data in chunks...\")         with open(file_path, 'r') as f:             if header:                 next(f)  # Skip the header line             for i, line in enumerate(f):                 values = line.strip().split(delimiter)                 try:                     values = [float(val) for val in values]                 except ValueError:                     print(f\"Non-numeric data found on line {i+2 if header else i+1}. Skipping this line.\")                     continue  # Skip lines with non-numeric data                 data_list.append(values)                 if len(data_list) &gt;= chunk_size:                     chunk_array = np.array(data_list, dtype=np.float32)                     max_value = max(max_value, np.nanmax(chunk_array))                     min_value = min(min_value, np.nanmin(chunk_array))                     total_rows += chunk_array.shape[0]                     data_list = []  # Reset the list for the next chunk              # Handle the last chunk             if data_list:                 chunk_array = np.array(data_list, dtype=np.float32)                 max_value = max(max_value, np.nanmax(chunk_array))                 min_value = min(min_value, np.nanmin(chunk_array))                 total_rows += chunk_array.shape[0]          print(f\"Total rows: {total_rows}, Columns per row: {num_cols}\")         print(f\"Data range: min={min_value}, max={max_value}\")          # Concatenate all chunks to form the full array         img = np.array(data_list, dtype=np.float32)         max_intensity = max_value          return img, max_intensity          # Main code block     try:         if file_extension in ['.png', '.jpg', '.jpeg', '.tif']:             img, max_intensity = load_image_file(file_path)         elif file_extension in ['.txt', '.csv']:             img, max_intensity = load_large_float_file(file_path)         else:             raise ValueError(\"Unsupported file type.\")                  image_name = os.path.basename(file_path)         print(f\"Loaded File: {image_name}\")                  # Create an interactive figure         fig, ax = plt.subplots()         im = ax.imshow(img, cmap='gray', origin='upper')         ax.set_title('Loaded Data')         ax.axis('on')  # Show axes to display coordinates                  # Enable zooming and panning         fig.canvas.toolbar_visible = True         fig.canvas.header_visible = False         fig.canvas.footer_visible = False          # Function to handle clicks         def onclick(event):             if event.inaxes == ax:                 x = int(event.xdata + 0.5)                 y = int(event.ydata + 0.5)                 if x &gt;= 0 and x &lt; img.shape[1] and y &gt;= 0 and y &lt; img.shape[0]:                     pixel_value = img[y, x]                     print(f\"Clicked at x={x}, y={y}, value={pixel_value}\")                 else:                     print(\"Clicked outside image bounds\")                  # Connect the click event handler         cid = fig.canvas.mpl_connect('button_press_event', onclick)         plt.show()     except Exception as e:         print(f\"Error: {e}\")  <pre>\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nFile /opt/conda/envs/pytorch-gpu/lib/python3.10/site-packages/matplotlib/backends/registry.py:413, in BackendRegistry.resolve_gui_or_backend(self, gui_or_backend)\n    412 try:\n--&gt; 413     return self.resolve_backend(gui_or_backend)\n    414 except Exception:  # KeyError ?\n\nFile /opt/conda/envs/pytorch-gpu/lib/python3.10/site-packages/matplotlib/backends/registry.py:375, in BackendRegistry.resolve_backend(self, backend)\n    374 if gui is None:\n--&gt; 375     raise RuntimeError(f\"'{backend}' is not a recognised backend name\")\n    377 return backend, gui if gui != \"headless\" else None\n\nRuntimeError: 'widget' is not a recognised backend name\n\nDuring handling of the above exception, another exception occurred:\n\nRuntimeError                              Traceback (most recent call last)\nCell In[6], line 7\n      4 import matplotlib.pyplot as plt\n      6 # Enable interactive plotting\n----&gt; 7 get_ipython().run_line_magic('matplotlib', 'widget')\n      9 # Prompt the user for the file path\n     10 file_path = input(\"Please enter the file path (.png, .jpg, .jpeg, .tif, .txt, .csv): \")\n\nFile /opt/conda/envs/pytorch-gpu/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2480, in InteractiveShell.run_line_magic(self, magic_name, line, _stack_depth)\n   2478     kwargs['local_ns'] = self.get_local_scope(stack_depth)\n   2479 with self.builtin_trap:\n-&gt; 2480     result = fn(*args, **kwargs)\n   2482 # The code below prevents the output from being displayed\n   2483 # when using magics with decorator @output_can_be_silenced\n   2484 # when the last Python token in the expression is a ';'.\n   2485 if getattr(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, False):\n\nFile /opt/conda/envs/pytorch-gpu/lib/python3.10/site-packages/IPython/core/magics/pylab.py:103, in PylabMagics.matplotlib(self, line)\n     98     print(\n     99         \"Available matplotlib backends: %s\"\n    100         % _list_matplotlib_backends_and_gui_loops()\n    101     )\n    102 else:\n--&gt; 103     gui, backend = self.shell.enable_matplotlib(args.gui)\n    104     self._show_matplotlib_backend(args.gui, backend)\n\nFile /opt/conda/envs/pytorch-gpu/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3665, in InteractiveShell.enable_matplotlib(self, gui)\n   3662     import matplotlib_inline.backend_inline\n   3664 from IPython.core import pylabtools as pt\n-&gt; 3665 gui, backend = pt.find_gui_and_backend(gui, self.pylab_gui_select)\n   3667 if gui != None:\n   3668     # If we have our first gui selection, store it\n   3669     if self.pylab_gui_select is None:\n\nFile /opt/conda/envs/pytorch-gpu/lib/python3.10/site-packages/IPython/core/pylabtools.py:349, in find_gui_and_backend(gui, gui_select)\n    347 else:\n    348     gui = _convert_gui_to_matplotlib(gui)\n--&gt; 349     backend, gui = backend_registry.resolve_gui_or_backend(gui)\n    351 gui = _convert_gui_from_matplotlib(gui)\n    352 return gui, backend\n\nFile /opt/conda/envs/pytorch-gpu/lib/python3.10/site-packages/matplotlib/backends/registry.py:415, in BackendRegistry.resolve_gui_or_backend(self, gui_or_backend)\n    413     return self.resolve_backend(gui_or_backend)\n    414 except Exception:  # KeyError ?\n--&gt; 415     raise RuntimeError(\n    416         f\"'{gui_or_backend} is not a recognised GUI loop or backend name\")\n\nRuntimeError: 'widget is not a recognised GUI loop or backend name</pre> In\u00a0[12]: Copied! <pre>try:\n    if file_extension in ['.png', '.jpg', '.jpeg', '.tif']:\n        img, max_intensity = load_image_file(file_path)\n    elif file_extension in ['.txt', '.csv']:\n        img, max_intensity = load_large_float_file(file_path)\n    else:\n        raise ValueError(\"Unsupported file type.\")\n    \n    image_name = os.path.basename(file_path)\n    print(f\"Loaded File: {image_name}\")\n    plt.imshow(img, cmap='gray')\n    plt.title('Loaded Data')\n    plt.axis('on')\n    plt.show()\nexcept Exception as e:\n    print(f\"Error: {e}\")\n</pre> try:     if file_extension in ['.png', '.jpg', '.jpeg', '.tif']:         img, max_intensity = load_image_file(file_path)     elif file_extension in ['.txt', '.csv']:         img, max_intensity = load_large_float_file(file_path)     else:         raise ValueError(\"Unsupported file type.\")          image_name = os.path.basename(file_path)     print(f\"Loaded File: {image_name}\")     plt.imshow(img, cmap='gray')     plt.title('Loaded Data')     plt.axis('on')     plt.show() except Exception as e:     print(f\"Error: {e}\")  <pre>8-bit image detected.\nLoaded File: blonder_aspen.tif\n</pre> In\u00a0[13]: Copied! <pre>from numba import cuda\n\n# CUDA kernel for computing N(s) for a given scale s\n@cuda.jit\ndef compute_ns(img, s, Ns, max_intensity):\n    y, x = cuda.grid(2)\n    rows, cols = img.shape\n    nx = (cols + s - 1) // s  # Number of boxes along x\n    ny = (rows + s - 1) // s  # Number of boxes along y\n\n    if x &lt; nx and y &lt; ny:\n        z_min = max_intensity\n        z_max = 0.0\n        for i in range(s):\n            for j in range(s):\n                xi = x * s + i\n                yj = y * s + j\n                if xi &lt; cols and yj &lt; rows:\n                    val = img[yj, xi]\n                    if val &lt; z_min:\n                        z_min = val\n                    if val &gt; z_max:\n                        z_max = val\n        n = math.ceil((z_max - z_min) / s) + 1\n        Ns[y, x] = n\n</pre> from numba import cuda  # CUDA kernel for computing N(s) for a given scale s @cuda.jit def compute_ns(img, s, Ns, max_intensity):     y, x = cuda.grid(2)     rows, cols = img.shape     nx = (cols + s - 1) // s  # Number of boxes along x     ny = (rows + s - 1) // s  # Number of boxes along y      if x &lt; nx and y &lt; ny:         z_min = max_intensity         z_max = 0.0         for i in range(s):             for j in range(s):                 xi = x * s + i                 yj = y * s + j                 if xi &lt; cols and yj &lt; rows:                     val = img[yj, xi]                     if val &lt; z_min:                         z_min = val                     if val &gt; z_max:                         z_max = val         n = math.ceil((z_max - z_min) / s) + 1         Ns[y, x] = n  In\u00a0[14]: Copied! <pre>def compute_fractal_dimension(img, scales, max_intensity):\n    Ns_list = []\n    inv_scales = []\n    for s in scales:\n        nx = (img.shape[1] + s - 1) // s\n        ny = (img.shape[0] + s - 1) // s\n        Ns = np.zeros((ny, nx), dtype=np.int32)\n        \n        # Prepare the image and Ns arrays for CUDA\n        img_device = cuda.to_device(img)\n        Ns_device = cuda.to_device(Ns)\n        \n        # CUDA grid and block dimensions\n        threadsperblock = (16, 16)\n        blockspergrid_x = (nx + threadsperblock[1] - 1) // threadsperblock[1]\n        blockspergrid_y = (ny + threadsperblock[0] - 1) // threadsperblock[0]\n        blockspergrid = (blockspergrid_y, blockspergrid_x)\n        \n        # Launch CUDA kernel\n        compute_ns[blockspergrid, threadsperblock](img_device, s, Ns_device, max_intensity)\n        cuda.synchronize()\n        \n        # Copy the result back to host\n        Ns = Ns_device.copy_to_host()\n        \n        N = Ns.sum()\n        Ns_list.append(N)\n        inv_scales.append(1/s)\n        \n        print(f\"Scale: {s}, N(s): {N}\")\n        \n    # Linear fit to estimate the fractal dimension\n    log_Ns = np.log(Ns_list)\n    log_inv_scales = np.log(inv_scales)\n    coeffs = np.polyfit(log_inv_scales, log_Ns, 1)\n    fractal_dimension = coeffs[0]\n    return fractal_dimension, log_inv_scales, log_Ns\n</pre> def compute_fractal_dimension(img, scales, max_intensity):     Ns_list = []     inv_scales = []     for s in scales:         nx = (img.shape[1] + s - 1) // s         ny = (img.shape[0] + s - 1) // s         Ns = np.zeros((ny, nx), dtype=np.int32)                  # Prepare the image and Ns arrays for CUDA         img_device = cuda.to_device(img)         Ns_device = cuda.to_device(Ns)                  # CUDA grid and block dimensions         threadsperblock = (16, 16)         blockspergrid_x = (nx + threadsperblock[1] - 1) // threadsperblock[1]         blockspergrid_y = (ny + threadsperblock[0] - 1) // threadsperblock[0]         blockspergrid = (blockspergrid_y, blockspergrid_x)                  # Launch CUDA kernel         compute_ns[blockspergrid, threadsperblock](img_device, s, Ns_device, max_intensity)         cuda.synchronize()                  # Copy the result back to host         Ns = Ns_device.copy_to_host()                  N = Ns.sum()         Ns_list.append(N)         inv_scales.append(1/s)                  print(f\"Scale: {s}, N(s): {N}\")              # Linear fit to estimate the fractal dimension     log_Ns = np.log(Ns_list)     log_inv_scales = np.log(inv_scales)     coeffs = np.polyfit(log_inv_scales, log_Ns, 1)     fractal_dimension = coeffs[0]     return fractal_dimension, log_inv_scales, log_Ns   In\u00a0[15]: Copied! <pre>if 'img' in globals():\n    # Define scales (adjust based on image size)\n    min_scale = 2\n    max_scale = min(img.shape) // 4  # Maximum scale to consider\n    num_scales = 5  # Number of scales to evaluate\n    scales = [int(min_scale * (2 ** i)) for i in range(num_scales) if min_scale * (2 ** i) &lt;= max_scale]\n    \n    if not scales:\n        scales = [2, 4]  # Fallback scales if image is too small\n    \n    print(f\"Scales to be used: {scales}\")\n    \n    fractal_dimension, log_inv_scales, log_Ns = compute_fractal_dimension(img, scales, max_intensity)\n    print(f\"\\nEstimated Fractal Dimension: {fractal_dimension:.4f}\")\nelse:\n    print(\"Image not loaded. Please provide a valid image path.\")\n</pre> if 'img' in globals():     # Define scales (adjust based on image size)     min_scale = 2     max_scale = min(img.shape) // 4  # Maximum scale to consider     num_scales = 5  # Number of scales to evaluate     scales = [int(min_scale * (2 ** i)) for i in range(num_scales) if min_scale * (2 ** i) &lt;= max_scale]          if not scales:         scales = [2, 4]  # Fallback scales if image is too small          print(f\"Scales to be used: {scales}\")          fractal_dimension, log_inv_scales, log_Ns = compute_fractal_dimension(img, scales, max_intensity)     print(f\"\\nEstimated Fractal Dimension: {fractal_dimension:.4f}\") else:     print(\"Image not loaded. Please provide a valid image path.\")   <pre>Scales to be used: [2, 4, 8, 16, 32]\nScale: 2, N(s): 150730395\nScale: 4, N(s): 43765109\nScale: 8, N(s): 9008751\nScale: 16, N(s): 1666865\nScale: 32, N(s): 282917\n\nEstimated Fractal Dimension: 2.2829\n</pre> In\u00a0[16]: Copied! <pre>if 'img' in globals():\n    # Plotting the log-log plot\n    plt.figure(figsize=(16, 12))\n    plt.plot(log_inv_scales, log_Ns, 'o-', label='Data')\n    # Plot the fitted line\n    coeffs = np.polyfit(log_inv_scales, log_Ns, 1)\n    plt.plot(log_inv_scales, np.polyval(coeffs, log_inv_scales), 'r--', label=f'Fit: D = {coeffs[0]:.4f}')\n    plt.xlabel('log(1/s)', fontsize=24)\n    plt.ylabel('log(N(s))', fontsize=24)\n    plt.title('Fractal Dimension Estimation', fontsize=36)\n    plt.legend(fontsize=24)\n    plt.grid(True)\n    plt.show()\nelse:\n    print(\"Image not loaded. Please provide a valid image path.\")\n</pre> if 'img' in globals():     # Plotting the log-log plot     plt.figure(figsize=(16, 12))     plt.plot(log_inv_scales, log_Ns, 'o-', label='Data')     # Plot the fitted line     coeffs = np.polyfit(log_inv_scales, log_Ns, 1)     plt.plot(log_inv_scales, np.polyval(coeffs, log_inv_scales), 'r--', label=f'Fit: D = {coeffs[0]:.4f}')     plt.xlabel('log(1/s)', fontsize=24)     plt.ylabel('log(N(s))', fontsize=24)     plt.title('Fractal Dimension Estimation', fontsize=36)     plt.legend(fontsize=24)     plt.grid(True)     plt.show() else:     print(\"Image not loaded. Please provide a valid image path.\")   In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"notebooks/dla/","title":"Dla","text":"<p>In this notebook, we will generate different types of self-affine fractal patterns using Python. Specifically, we will create Diffusion Limited Aggregation (DLA) models that resemble a lichen, a saprophyte, and a bryophyte.</p> <p>Note: While GPU acceleration can significantly speed up computations, implementing DLA on a GPU is challenging due to the inherently serial and random nature of the algorithm. Therefore, we will use Numba's Just-In-Time (JIT) compilation to optimize our code for better performance.</p> In\u00a0[2]: Copied! <pre>!which python\n</pre> !which python <pre>/Users/tswetnam/github/fractal-notebooks/.venv/bin/python\n</pre> In\u00a0[10]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom numba import njit, prange\n</pre> import numpy as np import matplotlib.pyplot as plt from numba import njit, prange  In\u00a0[11]: Copied! <pre># Grid size\ngrid_size = 1000\n\n# Number of particles\nnum_particles = 200000\n\n# Maximum steps per particle\nmax_steps = 1000000\n\n# Initialize the grid\ngrid = np.zeros((grid_size, grid_size), dtype=np.float64)\n\n# Set the seed particle at the center\ncenter = grid_size // 2\ngrid[center, center] = 1\n</pre> # Grid size grid_size = 1000  # Number of particles num_particles = 200000  # Maximum steps per particle max_steps = 1000000  # Initialize the grid grid = np.zeros((grid_size, grid_size), dtype=np.float64)  # Set the seed particle at the center center = grid_size // 2 grid[center, center] = 1  In\u00a0[12]: Copied! <pre>@njit(parallel=True)\ndef dla_simulation(grid, num_particles, max_steps):\n    grid_size = grid.shape[0]\n    center = grid_size // 2\n\n    for n in prange(num_particles):\n        # Start the particle at a random position on the boundary\n        angle = 2 * np.pi * np.random.rand()\n        x = int(center + (grid_size // 2 - 1) * np.cos(angle))\n        y = int(center + (grid_size // 2 - 1) * np.sin(angle))\n\n        for _ in range(max_steps):\n            # Random movement\n            direction = np.random.randint(4)\n            if direction == 0 and x &gt; 0:\n                x -= 1  # Left\n            elif direction == 1 and x &lt; grid_size - 1:\n                x += 1  # Right\n            elif direction == 2 and y &gt; 0:\n                y -= 1  # Up\n            elif direction == 3 and y &lt; grid_size - 1:\n                y += 1  # Down\n\n            # Check if the particle is adjacent to the cluster\n            if (grid[(x - 1) % grid_size, y] == 1 or\n                grid[(x + 1) % grid_size, y] == 1 or\n                grid[x, (y - 1) % grid_size] == 1 or\n                grid[x, (y + 1) % grid_size] == 1):\n                grid[x, y] = 1\n                break\n            # If the particle moves out of bounds, reposition it\n            if x &lt;= 0 or x &gt;= grid_size - 1 or y &lt;= 0 or y &gt;= grid_size - 1:\n                break\n</pre> @njit(parallel=True) def dla_simulation(grid, num_particles, max_steps):     grid_size = grid.shape[0]     center = grid_size // 2      for n in prange(num_particles):         # Start the particle at a random position on the boundary         angle = 2 * np.pi * np.random.rand()         x = int(center + (grid_size // 2 - 1) * np.cos(angle))         y = int(center + (grid_size // 2 - 1) * np.sin(angle))          for _ in range(max_steps):             # Random movement             direction = np.random.randint(4)             if direction == 0 and x &gt; 0:                 x -= 1  # Left             elif direction == 1 and x &lt; grid_size - 1:                 x += 1  # Right             elif direction == 2 and y &gt; 0:                 y -= 1  # Up             elif direction == 3 and y &lt; grid_size - 1:                 y += 1  # Down              # Check if the particle is adjacent to the cluster             if (grid[(x - 1) % grid_size, y] == 1 or                 grid[(x + 1) % grid_size, y] == 1 or                 grid[x, (y - 1) % grid_size] == 1 or                 grid[x, (y + 1) % grid_size] == 1):                 grid[x, y] = 1                 break             # If the particle moves out of bounds, reposition it             if x &lt;= 0 or x &gt;= grid_size - 1 or y &lt;= 0 or y &gt;= grid_size - 1:                 break  In\u00a0[\u00a0]: Copied! <pre># Run the DLA simulation\ndla_simulation(grid, num_particles, max_steps)\n</pre> # Run the DLA simulation dla_simulation(grid, num_particles, max_steps)  In\u00a0[\u00a0]: Copied! <pre>plt.figure(figsize=(16, 16))\nplt.imshow(grid, cmap='Reds')\nplt.axis('off')\nplt.title('DLA Simulation Resembling a Lichen')\nplt.show()\n</pre> plt.figure(figsize=(16, 16)) plt.imshow(grid, cmap='Reds') plt.axis('off') plt.title('DLA Simulation Resembling a Lichen') plt.show()  In\u00a0[\u00a0]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nimport ipywidgets as widgets\nfrom ipywidgets import interact\nfrom numba import njit\n\n# DLA Simulation Function\n@njit\ndef dla_simulation(grid_size, num_particles, max_steps):\n    grid = np.zeros((grid_size, grid_size), dtype=np.float64)\n    center = grid_size // 2\n    grid[center, center] = 1\n\n    for _ in range(num_particles):\n        angle = 2 * np.pi * np.random.rand()\n        x = int(center + (grid_size // 2 - 1) * np.cos(angle))\n        y = int(center + (grid_size // 2 - 1) * np.sin(angle))\n\n        for _ in range(max_steps):\n            direction = np.random.randint(4)\n            if direction == 0 and x &gt; 0:\n                x -= 1\n            elif direction == 1 and x &lt; grid_size - 1:\n                x += 1\n            elif direction == 2 and y &gt; 0:\n                y -= 1\n            elif direction == 3 and y &lt; grid_size - 1:\n                y += 1\n\n            if (grid[(x - 1) % grid_size, y] == 1 or\n                grid[(x + 1) % grid_size, y] == 1 or\n                grid[x, (y - 1) % grid_size] == 1 or\n                grid[x, (y + 1) % grid_size] == 1):\n                grid[x, y] = 1\n                break\n\n    return grid\n\n# Plotting Function\ndef plot_dla(grid_size, num_particles, max_steps):\n    grid = dla_simulation(grid_size, num_particles, max_steps)\n    plt.figure(figsize=(16, 16))\n    plt.imshow(grid, cmap='Reds')\n    plt.axis('off')\n    plt.title(f'DLA Simulation\\nGrid Size: {grid_size}, Particles: {num_particles}, Max Steps: {max_steps}')\n    plt.show()\n\n# Sliders for interactive inputs\ngrid_size_slider = widgets.IntSlider(min=100, max=800, step=50, value=500, description='Grid Size')\nnum_particles_slider = widgets.IntSlider(min=1000, max=100000, step=5000, value=50000, description='Particles')\nmax_steps_slider = widgets.IntSlider(min=1000, max=2000000, step=1000, value=10000, description='Max Steps')\n\n# Interactive widget display\ninteract(plot_dla, \n         grid_size=grid_size_slider, \n         num_particles=num_particles_slider, \n         max_steps=max_steps_slider)\n</pre> import numpy as np import matplotlib.pyplot as plt import ipywidgets as widgets from ipywidgets import interact from numba import njit  # DLA Simulation Function @njit def dla_simulation(grid_size, num_particles, max_steps):     grid = np.zeros((grid_size, grid_size), dtype=np.float64)     center = grid_size // 2     grid[center, center] = 1      for _ in range(num_particles):         angle = 2 * np.pi * np.random.rand()         x = int(center + (grid_size // 2 - 1) * np.cos(angle))         y = int(center + (grid_size // 2 - 1) * np.sin(angle))          for _ in range(max_steps):             direction = np.random.randint(4)             if direction == 0 and x &gt; 0:                 x -= 1             elif direction == 1 and x &lt; grid_size - 1:                 x += 1             elif direction == 2 and y &gt; 0:                 y -= 1             elif direction == 3 and y &lt; grid_size - 1:                 y += 1              if (grid[(x - 1) % grid_size, y] == 1 or                 grid[(x + 1) % grid_size, y] == 1 or                 grid[x, (y - 1) % grid_size] == 1 or                 grid[x, (y + 1) % grid_size] == 1):                 grid[x, y] = 1                 break      return grid  # Plotting Function def plot_dla(grid_size, num_particles, max_steps):     grid = dla_simulation(grid_size, num_particles, max_steps)     plt.figure(figsize=(16, 16))     plt.imshow(grid, cmap='Reds')     plt.axis('off')     plt.title(f'DLA Simulation\\nGrid Size: {grid_size}, Particles: {num_particles}, Max Steps: {max_steps}')     plt.show()  # Sliders for interactive inputs grid_size_slider = widgets.IntSlider(min=100, max=800, step=50, value=500, description='Grid Size') num_particles_slider = widgets.IntSlider(min=1000, max=100000, step=5000, value=50000, description='Particles') max_steps_slider = widgets.IntSlider(min=1000, max=2000000, step=1000, value=10000, description='Max Steps')  # Interactive widget display interact(plot_dla,           grid_size=grid_size_slider,           num_particles=num_particles_slider,           max_steps=max_steps_slider)  In\u00a0[\u00a0]: Copied! <pre>import numpy as np\nimport plotly.graph_objects as go\nimport ipywidgets as widgets\nfrom ipywidgets import interact\nfrom numba import njit\n\n# DLA Simulation Function\n@njit\ndef dla_simulation(grid_size, num_particles, max_steps):\n    grid = np.zeros((grid_size, grid_size), dtype=np.float64)\n    center = grid_size // 2\n    grid[center, center] = 1\n\n    for _ in range(num_particles):\n        angle = 2 * np.pi * np.random.rand()\n        x = int(center + (grid_size // 2 - 1) * np.cos(angle))\n        y = int(center + (grid_size // 2 - 1) * np.sin(angle))\n\n        for _ in range(max_steps):\n            direction = np.random.randint(4)\n            if direction == 0 and x &gt; 0:\n                x -= 1\n            elif direction == 1 and x &lt; grid_size - 1:\n                x += 1\n            elif direction == 2 and y &gt; 0:\n                y -= 1\n            elif direction == 3 and y &lt; grid_size - 1:\n                y += 1\n\n            if (grid[(x - 1) % grid_size, y] == 1 or\n                grid[(x + 1) % grid_size, y] == 1 or\n                grid[x, (y - 1) % grid_size] == 1 or\n                grid[x, (y + 1) % grid_size] == 1):\n                grid[x, y] = 1\n                break\n\n    return grid\n\n# Plotting Function using Plotly\ndef plot_dla(grid_size, num_particles, max_steps):\n    grid = dla_simulation(grid_size, num_particles, max_steps)\n    \n    fig = go.Figure(data=go.Heatmap(\n        z=grid, \n        colorscale='Greys',\n        showscale=False\n    ))\n\n    fig.update_layout(\n        title=f'DLA Simulation\\nGrid Size: {grid_size}, Particles: {num_particles}, Max Steps: {max_steps}',\n        width=800,\n        height=800,\n        xaxis=dict(showgrid=False, zeroline=False, visible=False),\n        yaxis=dict(showgrid=False, zeroline=False, visible=False),\n    )\n\n    fig.show()\n\n# Sliders for interactive inputs\ngrid_size_slider = widgets.IntSlider(min=100, max=800, step=50, value=500, description='Grid Size')\nnum_particles_slider = widgets.IntSlider(min=1000, max=1000000, step=5000, value=50000, description='Particles')\nmax_steps_slider = widgets.IntSlider(min=1000, max=1000000, step=1000, value=10000, description='Max Steps')\n\n# Interactive widget display\ninteract(plot_dla, \n         grid_size=grid_size_slider, \n         num_particles=num_particles_slider, \n         max_steps=max_steps_slider)\n</pre> import numpy as np import plotly.graph_objects as go import ipywidgets as widgets from ipywidgets import interact from numba import njit  # DLA Simulation Function @njit def dla_simulation(grid_size, num_particles, max_steps):     grid = np.zeros((grid_size, grid_size), dtype=np.float64)     center = grid_size // 2     grid[center, center] = 1      for _ in range(num_particles):         angle = 2 * np.pi * np.random.rand()         x = int(center + (grid_size // 2 - 1) * np.cos(angle))         y = int(center + (grid_size // 2 - 1) * np.sin(angle))          for _ in range(max_steps):             direction = np.random.randint(4)             if direction == 0 and x &gt; 0:                 x -= 1             elif direction == 1 and x &lt; grid_size - 1:                 x += 1             elif direction == 2 and y &gt; 0:                 y -= 1             elif direction == 3 and y &lt; grid_size - 1:                 y += 1              if (grid[(x - 1) % grid_size, y] == 1 or                 grid[(x + 1) % grid_size, y] == 1 or                 grid[x, (y - 1) % grid_size] == 1 or                 grid[x, (y + 1) % grid_size] == 1):                 grid[x, y] = 1                 break      return grid  # Plotting Function using Plotly def plot_dla(grid_size, num_particles, max_steps):     grid = dla_simulation(grid_size, num_particles, max_steps)          fig = go.Figure(data=go.Heatmap(         z=grid,          colorscale='Greys',         showscale=False     ))      fig.update_layout(         title=f'DLA Simulation\\nGrid Size: {grid_size}, Particles: {num_particles}, Max Steps: {max_steps}',         width=800,         height=800,         xaxis=dict(showgrid=False, zeroline=False, visible=False),         yaxis=dict(showgrid=False, zeroline=False, visible=False),     )      fig.show()  # Sliders for interactive inputs grid_size_slider = widgets.IntSlider(min=100, max=800, step=50, value=500, description='Grid Size') num_particles_slider = widgets.IntSlider(min=1000, max=1000000, step=5000, value=50000, description='Particles') max_steps_slider = widgets.IntSlider(min=1000, max=1000000, step=1000, value=10000, description='Max Steps')  # Interactive widget display interact(plot_dla,           grid_size=grid_size_slider,           num_particles=num_particles_slider,           max_steps=max_steps_slider)  In\u00a0[\u00a0]: Copied! <pre>@njit(parallel=True)\ndef dla_simulation_saprophyte(grid, num_particles, max_steps):\n    grid_size = grid.shape[0]\n\n    for n in prange(num_particles):\n        # Start the particle at a random position at the bottom\n        x = np.random.randint(0, grid_size)\n        y = grid_size - 1\n\n        for _ in range(max_steps):\n            # Introduce upward bias\n            prob = np.random.rand()\n            if prob &lt; 0.7 and y &gt; 0:\n                y -= 1  # Up\n            elif prob &lt; 0.85 and x &gt; 0:\n                x -= 1  # Left\n            elif prob &lt; 1.0 and x &lt; grid_size - 1:\n                x += 1  # Right\n\n            # Check if the particle is adjacent to the cluster\n            if (grid[x, (y - 1) % grid_size] == 1 or\n                grid[(x - 1) % grid_size, y] == 1 or\n                grid[(x + 1) % grid_size, y] == 1):\n                grid[x, y] = 1\n                break\n            # Break if out of bounds\n            if y &lt;= 0:\n                break\n</pre> @njit(parallel=True) def dla_simulation_saprophyte(grid, num_particles, max_steps):     grid_size = grid.shape[0]      for n in prange(num_particles):         # Start the particle at a random position at the bottom         x = np.random.randint(0, grid_size)         y = grid_size - 1          for _ in range(max_steps):             # Introduce upward bias             prob = np.random.rand()             if prob &lt; 0.7 and y &gt; 0:                 y -= 1  # Up             elif prob &lt; 0.85 and x &gt; 0:                 x -= 1  # Left             elif prob &lt; 1.0 and x &lt; grid_size - 1:                 x += 1  # Right              # Check if the particle is adjacent to the cluster             if (grid[x, (y - 1) % grid_size] == 1 or                 grid[(x - 1) % grid_size, y] == 1 or                 grid[(x + 1) % grid_size, y] == 1):                 grid[x, y] = 1                 break             # Break if out of bounds             if y &lt;= 0:                 break  In\u00a0[\u00a0]: Copied! <pre># Initialize the grid\ngrid_saprophyte = np.zeros((grid_size, grid_size), dtype=np.uint8)\n\n# Set the seed particles at the bottom row\ngrid_saprophyte[:, grid_size - 1] = 1\n\n# Run the DLA simulation with upward bias\ndla_simulation_saprophyte(grid_saprophyte, num_particles, max_steps)\n</pre> # Initialize the grid grid_saprophyte = np.zeros((grid_size, grid_size), dtype=np.uint8)  # Set the seed particles at the bottom row grid_saprophyte[:, grid_size - 1] = 1  # Run the DLA simulation with upward bias dla_simulation_saprophyte(grid_saprophyte, num_particles, max_steps)  In\u00a0[\u00a0]: Copied! <pre>plt.figure(figsize=(8, 8))\nplt.imshow(grid_saprophyte.T, cmap='Greens')\nplt.axis('off')\nplt.title('DLA Simulation Resembling a Saprophyte')\nplt.show()\n</pre> plt.figure(figsize=(8, 8)) plt.imshow(grid_saprophyte.T, cmap='Greens') plt.axis('off') plt.title('DLA Simulation Resembling a Saprophyte') plt.show()  In\u00a0[\u00a0]: Copied! <pre>@njit(parallel=True)\ndef dla_simulation_bryophyte(grid, num_particles, max_steps):\n    grid_size = grid.shape[0]\n    center = grid_size // 2\n\n    for n in prange(num_particles):\n        # Start the particle near the bottom center\n        x = np.random.randint(center - 50, center + 50)\n        y = grid_size - 1\n\n        for _ in range(max_steps):\n            # Introduce upward and lateral bias\n            prob = np.random.rand()\n            if prob &lt; 0.6 and y &gt; 0:\n                y -= 1  # Up\n            elif prob &lt; 0.8 and x &gt; 0:\n                x -= 1  # Left\n            elif prob &lt; 1.0 and x &lt; grid_size - 1:\n                x += 1  # Right\n\n            # Check if the particle is adjacent to the cluster\n            if (grid[x, (y - 1) % grid_size] == 1 or\n                grid[(x - 1) % grid_size, y] == 1 or\n                grid[(x + 1) % grid_size, y] == 1):\n                # Introduce lower sticking probability to encourage branching\n                if np.random.rand() &lt; 0.5:\n                    grid[x, y] = 1\n                    break\n            # Break if out of bounds\n            if y &lt;= 0:\n                break\n</pre> @njit(parallel=True) def dla_simulation_bryophyte(grid, num_particles, max_steps):     grid_size = grid.shape[0]     center = grid_size // 2      for n in prange(num_particles):         # Start the particle near the bottom center         x = np.random.randint(center - 50, center + 50)         y = grid_size - 1          for _ in range(max_steps):             # Introduce upward and lateral bias             prob = np.random.rand()             if prob &lt; 0.6 and y &gt; 0:                 y -= 1  # Up             elif prob &lt; 0.8 and x &gt; 0:                 x -= 1  # Left             elif prob &lt; 1.0 and x &lt; grid_size - 1:                 x += 1  # Right              # Check if the particle is adjacent to the cluster             if (grid[x, (y - 1) % grid_size] == 1 or                 grid[(x - 1) % grid_size, y] == 1 or                 grid[(x + 1) % grid_size, y] == 1):                 # Introduce lower sticking probability to encourage branching                 if np.random.rand() &lt; 0.5:                     grid[x, y] = 1                     break             # Break if out of bounds             if y &lt;= 0:                 break  In\u00a0[\u00a0]: Copied! <pre># Initialize the grid\ngrid_bryophyte = np.zeros((grid_size, grid_size), dtype=np.uint8)\n\n# Set the seed particles at the bottom center\ngrid_bryophyte[center - 5:center + 5, grid_size - 1] = 1\n\n# Run the DLA simulation for bryophyte\ndla_simulation_bryophyte(grid_bryophyte, num_particles, max_steps)\n</pre> # Initialize the grid grid_bryophyte = np.zeros((grid_size, grid_size), dtype=np.uint8)  # Set the seed particles at the bottom center grid_bryophyte[center - 5:center + 5, grid_size - 1] = 1  # Run the DLA simulation for bryophyte dla_simulation_bryophyte(grid_bryophyte, num_particles, max_steps)  In\u00a0[\u00a0]: Copied! <pre>plt.figure(figsize=(16, 16))\nplt.imshow(grid_bryophyte.T, cmap='Blues')\nplt.axis('off')\nplt.title('DLA Simulation Resembling a Bryophyte')\nplt.show()\n</pre> plt.figure(figsize=(16, 16)) plt.imshow(grid_bryophyte.T, cmap='Blues') plt.axis('off') plt.title('DLA Simulation Resembling a Bryophyte') plt.show()  In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"notebooks/dla/#setup","title":"Setup\u00b6","text":"<p>Install missing packages</p> <pre><code>{bash}\n\nmamba install -c conda-forge -y cudatoolkit  gcc_linux-64=9.5.0 ipywidgets jupyter_contrib_nbextensions nodejs numba numpy plotly pycuda pythreejs  py-opencv\n\njupyter labextension install jupyter-threejs\n\n</code></pre>"},{"location":"notebooks/dla/#diffusion-limited-aggregates","title":"Diffusion limited aggregates\u00b6","text":""},{"location":"notebooks/dla/#dla-resembling-a-lichen","title":"DLA resembling a lichen\u00b6","text":""},{"location":"notebooks/dla/#dla-model-resembling-a-saprophyte","title":"DLA Model Resembling a Saprophyte\u00b6","text":""},{"location":"notebooks/dla/#dla-model-resembling-a-bryophyte","title":"DLA Model Resembling a Bryophyte\u00b6","text":""},{"location":"notebooks/ferns/","title":"Barnsleys Ferns","text":"In\u00a0[1]: Copied! <pre>from numba import jit\n</pre> from numba import jit In\u00a0[8]: Copied! <pre>def barnsley_fern(n_points, color):\n    # Initialize arrays to hold x and y values\n    x = np.zeros(n_points)\n    y = np.zeros(n_points)\n    \n    for i in range(1, n_points):\n        r = np.random.random()\n        if r &lt; 0.01:\n            # Transformation 1\n            x[i] = 0\n            y[i] = 0.16 * y[i-1]\n        elif r &lt; 0.86:\n            # Transformation 2\n            x[i] = 0.85 * x[i-1] + 0.04 * y[i-1]\n            y[i] = -0.04 * x[i-1] + 0.85 * y[i-1] + 1.6\n        elif r &lt; 0.93:\n            # Transformation 3\n            x[i] = 0.20 * x[i-1] - 0.26 * y[i-1]\n            y[i] = 0.23 * x[i-1] + 0.22 * y[i-1] + 1.6\n        else:\n            # Transformation 4\n            x[i] = -0.15 * x[i-1] + 0.28 * y[i-1]\n            y[i] = 0.26 * x[i-1] + 0.24 * y[i-1] + 0.44\n    \n    # Plotting the points\n    plt.figure(figsize=(6, 10))\n    plt.scatter(x, y, s=0.2, color=color)\n    plt.axis('off')\n    plt.show()\n</pre> def barnsley_fern(n_points, color):     # Initialize arrays to hold x and y values     x = np.zeros(n_points)     y = np.zeros(n_points)          for i in range(1, n_points):         r = np.random.random()         if r &lt; 0.01:             # Transformation 1             x[i] = 0             y[i] = 0.16 * y[i-1]         elif r &lt; 0.86:             # Transformation 2             x[i] = 0.85 * x[i-1] + 0.04 * y[i-1]             y[i] = -0.04 * x[i-1] + 0.85 * y[i-1] + 1.6         elif r &lt; 0.93:             # Transformation 3             x[i] = 0.20 * x[i-1] - 0.26 * y[i-1]             y[i] = 0.23 * x[i-1] + 0.22 * y[i-1] + 1.6         else:             # Transformation 4             x[i] = -0.15 * x[i-1] + 0.28 * y[i-1]             y[i] = 0.26 * x[i-1] + 0.24 * y[i-1] + 0.44          # Plotting the points     plt.figure(figsize=(6, 10))     plt.scatter(x, y, s=0.2, color=color)     plt.axis('off')     plt.show()  In\u00a0[9]: Copied! <pre>interact(\n    barnsley_fern,\n    n_points=widgets.IntSlider(min=1000, max=100000, step=1000, value=50000, description='Iterations'),\n    color=widgets.ColorPicker(value='green', description='Color')\n)\n</pre> interact(     barnsley_fern,     n_points=widgets.IntSlider(min=1000, max=100000, step=1000, value=50000, description='Iterations'),     color=widgets.ColorPicker(value='green', description='Color') )  <pre>interactive(children=(IntSlider(value=50000, description='Iterations', max=100000, min=1000, step=1000), Color\u2026</pre> Out[9]: <pre>&lt;function __main__.barnsley_fern(n_points, color)&gt;</pre> In\u00a0[2]: Copied! <pre>from numba import jit\n\n@jit(nopython=True)\ndef generate_fern(n_points):\n    x = np.zeros(n_points)\n    y = np.zeros(n_points)\n    \n    for i in range(1, n_points):\n        r = np.random.random()\n        if r &lt; 0.01:\n            x[i] = 0\n            y[i] = 0.16 * y[i-1]\n        elif r &lt; 0.86:\n            x[i] = 0.85 * x[i-1] + 0.04 * y[i-1]\n            y[i] = -0.04 * x[i-1] + 0.85 * y[i-1] + 1.6\n        elif r &lt; 0.93:\n            x[i] = 0.20 * x[i-1] - 0.26 * y[i-1]\n            y[i] = 0.23 * x[i-1] + 0.22 * y[i-1] + 1.6\n        else:\n            x[i] = -0.15 * x[i-1] + 0.28 * y[i-1]\n            y[i] = 0.26 * x[i-1] + 0.24 * y[i-1] + 0.44\n    return x, y\n</pre> from numba import jit  @jit(nopython=True) def generate_fern(n_points):     x = np.zeros(n_points)     y = np.zeros(n_points)          for i in range(1, n_points):         r = np.random.random()         if r &lt; 0.01:             x[i] = 0             y[i] = 0.16 * y[i-1]         elif r &lt; 0.86:             x[i] = 0.85 * x[i-1] + 0.04 * y[i-1]             y[i] = -0.04 * x[i-1] + 0.85 * y[i-1] + 1.6         elif r &lt; 0.93:             x[i] = 0.20 * x[i-1] - 0.26 * y[i-1]             y[i] = 0.23 * x[i-1] + 0.22 * y[i-1] + 1.6         else:             x[i] = -0.15 * x[i-1] + 0.28 * y[i-1]             y[i] = 0.26 * x[i-1] + 0.24 * y[i-1] + 0.44     return x, y  In\u00a0[3]: Copied! <pre>def barnsley_fern(n_points, color):\n    x, y = generate_fern(n_points)\n    plt.figure(figsize=(6, 10))\n    plt.scatter(x, y, s=0.2, color=color)\n    plt.axis('off')\n    plt.show()\n</pre> def barnsley_fern(n_points, color):     x, y = generate_fern(n_points)     plt.figure(figsize=(6, 10))     plt.scatter(x, y, s=0.2, color=color)     plt.axis('off')     plt.show()  In\u00a0[4]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom ipywidgets import interact, widgets\nfrom numba import jit\n\n@jit(nopython=True)\ndef generate_fern(n_points):\n    x = np.zeros(n_points)\n    y = np.zeros(n_points)\n    \n    for i in range(1, n_points):\n        r = np.random.random()\n        if r &lt; 0.01:\n            # Transformation 1\n            x[i] = 0\n            y[i] = 0.16 * y[i-1]\n        elif r &lt; 0.86:\n            # Transformation 2\n            x[i] = 0.85 * x[i-1] + 0.04 * y[i-1]\n            y[i] = -0.04 * x[i-1] + 0.85 * y[i-1] + 1.6\n        elif r &lt; 0.93:\n            # Transformation 3\n            x[i] = 0.20 * x[i-1] - 0.26 * y[i-1]\n            y[i] = 0.23 * x[i-1] + 0.22 * y[i-1] + 1.6\n        else:\n            # Transformation 4\n            x[i] = -0.15 * x[i-1] + 0.28 * y[i-1]\n            y[i] = 0.26 * x[i-1] + 0.24 * y[i-1] + 0.44\n    return x, y\n\ndef barnsley_fern(n_points, color):\n    x, y = generate_fern(n_points)\n    plt.figure(figsize=(6, 10))\n    plt.scatter(x, y, s=0.2, color=color)\n    plt.axis('off')\n    plt.show()\n\ninteract(\n    barnsley_fern,\n    n_points=widgets.IntSlider(min=1000, max=100000, step=1000, value=50000, description='Iterations'),\n    color=widgets.ColorPicker(value='green', description='Color')\n)\n</pre> import numpy as np import matplotlib.pyplot as plt from ipywidgets import interact, widgets from numba import jit  @jit(nopython=True) def generate_fern(n_points):     x = np.zeros(n_points)     y = np.zeros(n_points)          for i in range(1, n_points):         r = np.random.random()         if r &lt; 0.01:             # Transformation 1             x[i] = 0             y[i] = 0.16 * y[i-1]         elif r &lt; 0.86:             # Transformation 2             x[i] = 0.85 * x[i-1] + 0.04 * y[i-1]             y[i] = -0.04 * x[i-1] + 0.85 * y[i-1] + 1.6         elif r &lt; 0.93:             # Transformation 3             x[i] = 0.20 * x[i-1] - 0.26 * y[i-1]             y[i] = 0.23 * x[i-1] + 0.22 * y[i-1] + 1.6         else:             # Transformation 4             x[i] = -0.15 * x[i-1] + 0.28 * y[i-1]             y[i] = 0.26 * x[i-1] + 0.24 * y[i-1] + 0.44     return x, y  def barnsley_fern(n_points, color):     x, y = generate_fern(n_points)     plt.figure(figsize=(6, 10))     plt.scatter(x, y, s=0.2, color=color)     plt.axis('off')     plt.show()  interact(     barnsley_fern,     n_points=widgets.IntSlider(min=1000, max=100000, step=1000, value=50000, description='Iterations'),     color=widgets.ColorPicker(value='green', description='Color') )  <pre>interactive(children=(IntSlider(value=50000, description='Iterations', max=100000, min=1000, step=1000), Color\u2026</pre> Out[4]: <pre>&lt;function __main__.barnsley_fern(n_points, color)&gt;</pre> In\u00a0[5]: Copied! <pre>def generate_fern(n_points, t1_params, t2_params, t3_params, t4_params, probs):\n    x = np.zeros(n_points)\n    y = np.zeros(n_points)\n    \n    # Normalize probabilities\n    prob_cum = np.cumsum(probs)\n    prob_cum /= prob_cum[-1]\n    \n    for i in range(1, n_points):\n        r = np.random.random()\n        if r &lt; prob_cum[0]:\n            a, b, c, d, e, f = t1_params\n        elif r &lt; prob_cum[1]:\n            a, b, c, d, e, f = t2_params\n        elif r &lt; prob_cum[2]:\n            a, b, c, d, e, f = t3_params\n        else:\n            a, b, c, d, e, f = t4_params\n\n        x_i = x[i-1]\n        y_i = y[i-1]\n        x[i] = a * x_i + b * y_i + e\n        y[i] = c * x_i + d * y_i + f\n        \n    return x, y\n</pre> def generate_fern(n_points, t1_params, t2_params, t3_params, t4_params, probs):     x = np.zeros(n_points)     y = np.zeros(n_points)          # Normalize probabilities     prob_cum = np.cumsum(probs)     prob_cum /= prob_cum[-1]          for i in range(1, n_points):         r = np.random.random()         if r &lt; prob_cum[0]:             a, b, c, d, e, f = t1_params         elif r &lt; prob_cum[1]:             a, b, c, d, e, f = t2_params         elif r &lt; prob_cum[2]:             a, b, c, d, e, f = t3_params         else:             a, b, c, d, e, f = t4_params          x_i = x[i-1]         y_i = y[i-1]         x[i] = a * x_i + b * y_i + e         y[i] = c * x_i + d * y_i + f              return x, y  In\u00a0[6]: Copied! <pre>def barnsley_fern(n_points, width, color, \n                  t1_a, t1_b, t1_c, t1_d, t1_e, t1_f,\n                  t2_a, t2_b, t2_c, t2_d, t2_e, t2_f,\n                  t3_a, t3_b, t3_c, t3_d, t3_e, t3_f,\n                  t4_a, t4_b, t4_c, t4_d, t4_e, t4_f,\n                  p1, p2, p3, p4):\n    # Transformation parameters\n    t1_params = [t1_a, t1_b, t1_c, t1_d, t1_e, t1_f]\n    t2_params = [t2_a, t2_b, t2_c, t2_d, t2_e, t2_f]\n    t3_params = [t3_a, t3_b, t3_c, t3_d, t3_e, t3_f]\n    t4_params = [t4_a, t4_b, t4_c, t4_d, t4_e, t4_f]\n    probs = [p1, p2, p3, p4]\n    \n    x, y = generate_fern(n_points, t1_params, t2_params, t3_params, t4_params, probs)\n    plt.figure(figsize=(6, 10))\n    plt.scatter(x, y, s=width, color=color, marker='o')\n    plt.axis('off')\n    plt.show()\n</pre> def barnsley_fern(n_points, width, color,                    t1_a, t1_b, t1_c, t1_d, t1_e, t1_f,                   t2_a, t2_b, t2_c, t2_d, t2_e, t2_f,                   t3_a, t3_b, t3_c, t3_d, t3_e, t3_f,                   t4_a, t4_b, t4_c, t4_d, t4_e, t4_f,                   p1, p2, p3, p4):     # Transformation parameters     t1_params = [t1_a, t1_b, t1_c, t1_d, t1_e, t1_f]     t2_params = [t2_a, t2_b, t2_c, t2_d, t2_e, t2_f]     t3_params = [t3_a, t3_b, t3_c, t3_d, t3_e, t3_f]     t4_params = [t4_a, t4_b, t4_c, t4_d, t4_e, t4_f]     probs = [p1, p2, p3, p4]          x, y = generate_fern(n_points, t1_params, t2_params, t3_params, t4_params, probs)     plt.figure(figsize=(6, 10))     plt.scatter(x, y, s=width, color=color, marker='o')     plt.axis('off')     plt.show()  In\u00a0[7]: Copied! <pre>interact(\n    barnsley_fern,\n    n_points=widgets.IntSlider(min=1000, max=200000, step=1000, value=50000, description='Iterations'),\n    width=widgets.FloatSlider(min=0.1, max=2, step=0.1, value=0.2, description='Width'),\n    color=widgets.ColorPicker(value='green', description='Color'),\n    \n    # Transformation 1 parameters\n    t1_a=widgets.FloatText(value=0.0, description='T1 a'),\n    t1_b=widgets.FloatText(value=0.0, description='T1 b'),\n    t1_c=widgets.FloatText(value=0.0, description='T1 c'),\n    t1_d=widgets.FloatText(value=0.16, description='T1 d'),\n    t1_e=widgets.FloatText(value=0.0, description='T1 e'),\n    t1_f=widgets.FloatText(value=0.0, description='T1 f'),\n    \n    # Transformation 2 parameters\n    t2_a=widgets.FloatText(value=0.85, description='T2 a'),\n    t2_b=widgets.FloatText(value=0.04, description='T2 b'),\n    t2_c=widgets.FloatText(value=-0.04, description='T2 c'),\n    t2_d=widgets.FloatText(value=0.85, description='T2 d'),\n    t2_e=widgets.FloatText(value=0.0, description='T2 e'),\n    t2_f=widgets.FloatText(value=1.6, description='T2 f'),\n    \n    # Transformation 3 parameters\n    t3_a=widgets.FloatText(value=0.20, description='T3 a'),\n    t3_b=widgets.FloatText(value=-0.26, description='T3 b'),\n    t3_c=widgets.FloatText(value=0.23, description='T3 c'),\n    t3_d=widgets.FloatText(value=0.22, description='T3 d'),\n    t3_e=widgets.FloatText(value=0.0, description='T3 e'),\n    t3_f=widgets.FloatText(value=1.6, description='T3 f'),\n    \n    # Transformation 4 parameters\n    t4_a=widgets.FloatText(value=-0.15, description='T4 a'),\n    t4_b=widgets.FloatText(value=0.28, description='T4 b'),\n    t4_c=widgets.FloatText(value=0.26, description='T4 c'),\n    t4_d=widgets.FloatText(value=0.24, description='T4 d'),\n    t4_e=widgets.FloatText(value=0.0, description='T4 e'),\n    t4_f=widgets.FloatText(value=0.44, description='T4 f'),\n    \n    # Probabilities\n    p1=widgets.FloatSlider(min=0.0, max=1.0, step=0.01, value=0.01, description='P1'),\n    p2=widgets.FloatSlider(min=0.0, max=1.0, step=0.01, value=0.85, description='P2'),\n    p3=widgets.FloatSlider(min=0.0, max=1.0, step=0.01, value=0.07, description='P3'),\n    p4=widgets.FloatSlider(min=0.0, max=1.0, step=0.01, value=0.07, description='P4'),\n)\n</pre> interact(     barnsley_fern,     n_points=widgets.IntSlider(min=1000, max=200000, step=1000, value=50000, description='Iterations'),     width=widgets.FloatSlider(min=0.1, max=2, step=0.1, value=0.2, description='Width'),     color=widgets.ColorPicker(value='green', description='Color'),          # Transformation 1 parameters     t1_a=widgets.FloatText(value=0.0, description='T1 a'),     t1_b=widgets.FloatText(value=0.0, description='T1 b'),     t1_c=widgets.FloatText(value=0.0, description='T1 c'),     t1_d=widgets.FloatText(value=0.16, description='T1 d'),     t1_e=widgets.FloatText(value=0.0, description='T1 e'),     t1_f=widgets.FloatText(value=0.0, description='T1 f'),          # Transformation 2 parameters     t2_a=widgets.FloatText(value=0.85, description='T2 a'),     t2_b=widgets.FloatText(value=0.04, description='T2 b'),     t2_c=widgets.FloatText(value=-0.04, description='T2 c'),     t2_d=widgets.FloatText(value=0.85, description='T2 d'),     t2_e=widgets.FloatText(value=0.0, description='T2 e'),     t2_f=widgets.FloatText(value=1.6, description='T2 f'),          # Transformation 3 parameters     t3_a=widgets.FloatText(value=0.20, description='T3 a'),     t3_b=widgets.FloatText(value=-0.26, description='T3 b'),     t3_c=widgets.FloatText(value=0.23, description='T3 c'),     t3_d=widgets.FloatText(value=0.22, description='T3 d'),     t3_e=widgets.FloatText(value=0.0, description='T3 e'),     t3_f=widgets.FloatText(value=1.6, description='T3 f'),          # Transformation 4 parameters     t4_a=widgets.FloatText(value=-0.15, description='T4 a'),     t4_b=widgets.FloatText(value=0.28, description='T4 b'),     t4_c=widgets.FloatText(value=0.26, description='T4 c'),     t4_d=widgets.FloatText(value=0.24, description='T4 d'),     t4_e=widgets.FloatText(value=0.0, description='T4 e'),     t4_f=widgets.FloatText(value=0.44, description='T4 f'),          # Probabilities     p1=widgets.FloatSlider(min=0.0, max=1.0, step=0.01, value=0.01, description='P1'),     p2=widgets.FloatSlider(min=0.0, max=1.0, step=0.01, value=0.85, description='P2'),     p3=widgets.FloatSlider(min=0.0, max=1.0, step=0.01, value=0.07, description='P3'),     p4=widgets.FloatSlider(min=0.0, max=1.0, step=0.01, value=0.07, description='P4'), )  <pre>interactive(children=(IntSlider(value=50000, description='Iterations', max=200000, min=1000, step=1000), Float\u2026</pre> Out[7]: <pre>&lt;function __main__.barnsley_fern(n_points, width, color, t1_a, t1_b, t1_c, t1_d, t1_e, t1_f, t2_a, t2_b, t2_c, t2_d, t2_e, t2_f, t3_a, t3_b, t3_c, t3_d, t3_e, t3_f, t4_a, t4_b, t4_c, t4_d, t4_e, t4_f, p1, p2, p3, p4)&gt;</pre>"},{"location":"notebooks/ferns/#setup","title":"Setup\u00b6","text":"<p>Install missing packages</p> <pre>mamba install -c conda-forge plotly streamlit numba numpy matplotlib \n</pre>"},{"location":"notebooks/ferns/#barnsleys-ferns","title":"Barnsley's Ferns\u00b6","text":""},{"location":"notebooks/ferns/#explanation-of-parameters","title":"Explanation of Parameters\u00b6","text":""},{"location":"notebooks/ferns/#affine-transformation-parameters","title":"Affine Transformation Parameters\u00b6","text":"<p>Each transformation is defined by the parameters ( a, b, c, d, e, f ) in the affine transformation equations:</p> <p>[ \\begin{cases} x_{\\text{new}} = a \\cdot x_{\\text{old}} + b \\cdot y_{\\text{old}} + e \\\\ y_{\\text{new}} = c \\cdot x_{\\text{old}} + d \\cdot y_{\\text{old}} + f \\end{cases} ]</p> <ul> <li>Angles and Lengths: The parameters ( a, b, c, d ) control scaling (lengths) and rotation (angles) of each transformation.</li> <li>Translation: The parameters ( e, f ) shift the fern along the x and y axes.</li> <li>Transformation Probabilities (Bifurcation Rate): The probabilities ( P1, P2, P3, P4 ) determine how often each transformation is applied. Adjusting these changes the bifurcation patterns in the fern.</li> </ul>"},{"location":"notebooks/ferns/#width","title":"Width\u00b6","text":"<ul> <li>Point Size: Controls the size of the points in the scatter plot, effectively changing the \"width\" of the branches.</li> </ul>"},{"location":"notebooks/ferns/#how-to-use-the-interactive-widgets","title":"How to Use the Interactive Widgets\u00b6","text":"<ul> <li>Adjust Transformation Parameters: Use the text boxes to input different values for ( a, b, c, d, e, f ) for each transformation (T1 to T4). Small changes can significantly affect the fractal's shape.</li> <li>Modify Probabilities: Use the sliders for ( P1 ) to ( P4 ) to change the likelihood of each transformation being applied. Ensure that the sum of probabilities is greater than zero (they will be normalized automatically).</li> <li>Change Width and Color: Adjust the point size with the \"Width\" slider and select different colors using the color picker.</li> <li>Number of Iterations: Increase or decrease the \"Iterations\" slider to control the number of points generated. More iterations result in a more detailed fern but may take longer to compute.</li> </ul>"},{"location":"notebooks/ferns/#visualization-example","title":"Visualization Example\u00b6","text":"<p>Experiment with different parameters to see how they affect the Barnsley Fern. Here are some suggestions:</p> <ul> <li>Classic Fern: Use the default parameters provided.</li> <li>Wider Fern: Increase the scaling factors ( a ) and ( d ) in T2, T3, and T4.</li> <li>Different Angles: Modify ( b ) and ( c ) to introduce shearing and rotation.</li> <li>Alter Bifurcation Rate: Change the probabilities to see how the fern's branching structure changes.</li> </ul>"},{"location":"notebooks/fractal_generators/","title":"Self-affine Fractals","text":"In\u00a0[13]: Copied! <pre>!which python\n</pre> !which python <pre>/home/codespace/.python/current/bin/python\n</pre> In\u00a0[14]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom ipywidgets import interact, widgets\n</pre> import numpy as np import matplotlib.pyplot as plt from ipywidgets import interact, widgets In\u00a0[15]: Copied! <pre>def draw_tree(x1, y1, angle, depth, angle_change, length_factor, linewidth_factor):\n    if depth &gt; 0:\n        x2 = x1 + np.cos(angle) * depth * length_factor\n        y2 = y1 + np.sin(angle) * depth * length_factor\n        plt.plot([x1, x2], [y1, y2], color='green', linewidth=depth * linewidth_factor)\n        draw_tree(x2, y2, angle - angle_change, depth - 1, angle_change, length_factor, linewidth_factor)\n        draw_tree(x2, y2, angle + angle_change, depth - 1, angle_change, length_factor, linewidth_factor)\n</pre> def draw_tree(x1, y1, angle, depth, angle_change, length_factor, linewidth_factor):     if depth &gt; 0:         x2 = x1 + np.cos(angle) * depth * length_factor         y2 = y1 + np.sin(angle) * depth * length_factor         plt.plot([x1, x2], [y1, y2], color='green', linewidth=depth * linewidth_factor)         draw_tree(x2, y2, angle - angle_change, depth - 1, angle_change, length_factor, linewidth_factor)         draw_tree(x2, y2, angle + angle_change, depth - 1, angle_change, length_factor, linewidth_factor)  In\u00a0[16]: Copied! <pre>def plot_tree(depth, angle_deg, length_factor, linewidth_factor):\n    plt.figure(figsize=(8, 8))\n    plt.axis('off')\n    draw_tree(0, -100, np.pi/2, depth, np.deg2rad(angle_deg), length_factor, linewidth_factor)\n    plt.show()\n</pre> def plot_tree(depth, angle_deg, length_factor, linewidth_factor):     plt.figure(figsize=(8, 8))     plt.axis('off')     draw_tree(0, -100, np.pi/2, depth, np.deg2rad(angle_deg), length_factor, linewidth_factor)     plt.show()  In\u00a0[17]: Copied! <pre>interact(\n    plot_tree,\n    depth=widgets.IntSlider(min=1, max=15, step=1, value=9, description='Depth'),\n    angle_deg=widgets.FloatSlider(min=0, max=90, step=1, value=30, description='Branch Angle'),\n    length_factor=widgets.FloatSlider(min=5, max=20, step=0.5, value=10, description='Branch Length'),\n    linewidth_factor=widgets.FloatSlider(min=0.1, max=2, step=0.1, value=0.5, description='Branch Width')\n)\n</pre> interact(     plot_tree,     depth=widgets.IntSlider(min=1, max=15, step=1, value=9, description='Depth'),     angle_deg=widgets.FloatSlider(min=0, max=90, step=1, value=30, description='Branch Angle'),     length_factor=widgets.FloatSlider(min=5, max=20, step=0.5, value=10, description='Branch Length'),     linewidth_factor=widgets.FloatSlider(min=0.1, max=2, step=0.1, value=0.5, description='Branch Width') )  <pre>interactive(children=(IntSlider(value=9, description='Depth', max=15, min=1), FloatSlider(value=30.0, descript\u2026</pre> Out[17]: <pre>&lt;function __main__.plot_tree(depth, angle_deg, length_factor, linewidth_factor)&gt;</pre> In\u00a0[18]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom ipywidgets import interact, widgets\n\ndef draw_tree(x1, y1, angle, depth, angle_range_deg, length_factor, linewidth_factor, length_scale, width_scale, branching_factor, branching_scale, initial_depth):\n    if depth &gt; 0:\n        scale_exponent = initial_depth - depth\n        scaled_length = length_factor * (length_scale ** scale_exponent)\n        scaled_width = linewidth_factor * (width_scale ** scale_exponent)\n        \n        x2 = x1 + np.cos(angle) * scaled_length\n        y2 = y1 + np.sin(angle) * scaled_length\n        plt.plot([x1, x2], [y1, y2], color='green', linewidth=scaled_width)\n        \n        # Compute current branching factor\n        current_branching_factor = max(1, int(branching_factor * (branching_scale ** scale_exponent)))\n        \n        angle_range = np.deg2rad(angle_range_deg)\n        angles = np.linspace(angle - angle_range / 2, angle + angle_range / 2, current_branching_factor)\n        for branch_angle in angles:\n            draw_tree(x2, y2, branch_angle, depth - 1, angle_range_deg, length_factor, linewidth_factor, length_scale, width_scale, branching_factor, branching_scale, initial_depth)\n\ndef plot_tree(depth, angle_range_deg, length_factor, linewidth_factor, length_scale, width_scale, branching_factor, branching_scale):\n    plt.figure(figsize=(8, 8))\n    plt.axis('off')\n    draw_tree(0, -100, np.pi/2, depth, angle_range_deg, length_factor, linewidth_factor, length_scale, width_scale, branching_factor, branching_scale, depth)\n    plt.show()\n    \ninteract(\n    plot_tree,\n    depth=widgets.IntSlider(min=1, max=15, step=1, value=9, description='Depth'),\n    angle_range_deg=widgets.FloatSlider(min=0, max=180, step=1, value=60, description='Angle Range'),\n    length_factor=widgets.FloatSlider(min=1, max=100, step=1, value=10, description='Base Length'),\n    linewidth_factor=widgets.FloatSlider(min=0.1, max=10, step=0.1, value=1, description='Base Width'),\n    length_scale=widgets.FloatSlider(min=0.5, max=1.5, step=0.1, value=0.7, description='Length Scale'),\n    width_scale=widgets.FloatSlider(min=0.5, max=1.5, step=0.1, value=0.7, description='Width Scale'),\n    branching_factor=widgets.IntSlider(min=1, max=5, step=1, value=2, description='Branches'),\n    branching_scale=widgets.FloatSlider(min=0.5, max=2.0, step=0.1, value=1.0, description='Branching Scale')\n)\n</pre> import numpy as np import matplotlib.pyplot as plt from ipywidgets import interact, widgets  def draw_tree(x1, y1, angle, depth, angle_range_deg, length_factor, linewidth_factor, length_scale, width_scale, branching_factor, branching_scale, initial_depth):     if depth &gt; 0:         scale_exponent = initial_depth - depth         scaled_length = length_factor * (length_scale ** scale_exponent)         scaled_width = linewidth_factor * (width_scale ** scale_exponent)                  x2 = x1 + np.cos(angle) * scaled_length         y2 = y1 + np.sin(angle) * scaled_length         plt.plot([x1, x2], [y1, y2], color='green', linewidth=scaled_width)                  # Compute current branching factor         current_branching_factor = max(1, int(branching_factor * (branching_scale ** scale_exponent)))                  angle_range = np.deg2rad(angle_range_deg)         angles = np.linspace(angle - angle_range / 2, angle + angle_range / 2, current_branching_factor)         for branch_angle in angles:             draw_tree(x2, y2, branch_angle, depth - 1, angle_range_deg, length_factor, linewidth_factor, length_scale, width_scale, branching_factor, branching_scale, initial_depth)  def plot_tree(depth, angle_range_deg, length_factor, linewidth_factor, length_scale, width_scale, branching_factor, branching_scale):     plt.figure(figsize=(8, 8))     plt.axis('off')     draw_tree(0, -100, np.pi/2, depth, angle_range_deg, length_factor, linewidth_factor, length_scale, width_scale, branching_factor, branching_scale, depth)     plt.show()      interact(     plot_tree,     depth=widgets.IntSlider(min=1, max=15, step=1, value=9, description='Depth'),     angle_range_deg=widgets.FloatSlider(min=0, max=180, step=1, value=60, description='Angle Range'),     length_factor=widgets.FloatSlider(min=1, max=100, step=1, value=10, description='Base Length'),     linewidth_factor=widgets.FloatSlider(min=0.1, max=10, step=0.1, value=1, description='Base Width'),     length_scale=widgets.FloatSlider(min=0.5, max=1.5, step=0.1, value=0.7, description='Length Scale'),     width_scale=widgets.FloatSlider(min=0.5, max=1.5, step=0.1, value=0.7, description='Width Scale'),     branching_factor=widgets.IntSlider(min=1, max=5, step=1, value=2, description='Branches'),     branching_scale=widgets.FloatSlider(min=0.5, max=2.0, step=0.1, value=1.0, description='Branching Scale') )  <pre>interactive(children=(IntSlider(value=9, description='Depth', max=15, min=1), FloatSlider(value=60.0, descript\u2026</pre> Out[18]: <pre>&lt;function __main__.plot_tree(depth, angle_range_deg, length_factor, linewidth_factor, length_scale, width_scale, branching_factor, branching_scale)&gt;</pre> In\u00a0[1]: Copied! <pre>import numpy as np\nimport plotly.graph_objects as go\nfrom ipywidgets import interact, widgets\n\ndef cylinder_between_points(p0, p1, radius, n=8):\n    \"\"\"\n    Generate the mesh data for a cylinder between two points p0 and p1.\n    \"\"\"\n    # Vector from p0 to p1\n    v = np.array(p1) - np.array(p0)\n    # Length of the cylinder\n    length = np.linalg.norm(v)\n    if length == 0:\n        return None  # Avoid division by zero\n    # Unit vector in direction of cylinder axis\n    v = v / length\n\n    # Create arbitrary vectors orthogonal to v\n    not_v = np.array([1, 0, 0])\n    if (v == not_v).all():\n        not_v = np.array([0, 1, 0])\n    n1 = np.cross(v, not_v)\n    n1 /= np.linalg.norm(n1)\n    n2 = np.cross(v, n1)\n\n    # Generate circle points in the plane orthogonal to v\n    t = np.linspace(0, 2 * np.pi, n)\n    circle = np.array([np.cos(t), np.sin(t)])\n    circle_pts = radius * (np.outer(n1, circle[0]) + np.outer(n2, circle[1]))\n\n    # Points at base and top of cylinder\n    x_base = p0[0] + circle_pts[0]\n    y_base = p0[1] + circle_pts[1]\n    z_base = p0[2] + circle_pts[2]\n\n    x_top = x_base + v[0] * length\n    y_top = y_base + v[1] * length\n    z_top = z_base + v[2] * length\n\n    # Combine base and top points\n    x = np.concatenate([x_base, x_top])\n    y = np.concatenate([y_base, y_top])\n    z = np.concatenate([z_base, z_top])\n\n    # Define faces of the cylinder\n    faces = []\n    n_points = n\n    for i in range(n_points):\n        next_i = (i + 1) % n_points\n        # Side faces\n        faces.append([i, next_i, n_points + next_i])\n        faces.append([i, n_points + next_i, n_points + i])\n    return x, y, z, faces\n\ndef draw_tree_3d(x1, y1, z1, theta, phi, depth, angle_range_deg, length_factor,\n                 linewidth_factor, length_scale, width_scale, branching_factor,\n                 branching_scale, initial_depth, cylinders):\n    if depth &gt; 0:\n        scale_exponent = initial_depth - depth\n        scaled_length = length_factor * (length_scale ** scale_exponent)\n        scaled_width = linewidth_factor * (width_scale ** scale_exponent)\n\n        # Compute the direction vector\n        direction = np.array([\n            np.sin(theta) * np.cos(phi),\n            np.sin(theta) * np.sin(phi),\n            np.cos(theta)\n        ])\n\n        # Compute the new point\n        x2 = x1 + direction[0] * scaled_length\n        y2 = y1 + direction[1] * scaled_length\n        z2 = z1 + direction[2] * scaled_length\n\n        # Store the cylinder data\n        cylinder_data = cylinder_between_points(\n            [x1, y1, z1],\n            [x2, y2, z2],\n            scaled_width\n        )\n        if cylinder_data:\n            x_cyl, y_cyl, z_cyl, faces = cylinder_data\n            cylinders.append({\n                'x': x_cyl,\n                'y': y_cyl,\n                'z': z_cyl,\n                'faces': faces,\n                'color': 'green'\n            })\n\n        # Compute current branching factor\n        current_branching_factor = max(1, int(branching_factor * (branching_scale ** scale_exponent)))\n\n        # Generate new branches\n        angle_range_rad = np.deg2rad(angle_range_deg)\n\n        for _ in range(current_branching_factor):\n            # Random angles within the specified range\n            delta_theta = angle_range_rad * (np.random.rand() - 0.5)\n            delta_phi = angle_range_rad * (np.random.rand() - 0.5)\n            new_theta = theta + delta_theta\n            new_phi = phi + delta_phi\n            # Recursive call\n            draw_tree_3d(\n                x2, y2, z2, new_theta, new_phi, depth - 1, angle_range_deg,\n                length_factor, linewidth_factor, length_scale, width_scale,\n                branching_factor, branching_scale, initial_depth, cylinders\n            )\n\ndef plot_tree_3d(depth, angle_range_deg, length_factor, linewidth_factor,\n                 length_scale, width_scale, branching_factor, branching_scale):\n    cylinders = []\n    initial_theta = 0  # Initial angle from z-axis\n    initial_phi = 0    # Initial angle in x-y plane\n    initial_depth = depth\n    draw_tree_3d(\n        0, 0, 0, initial_theta, initial_phi, depth, angle_range_deg,\n        length_factor, linewidth_factor, length_scale, width_scale,\n        branching_factor, branching_scale, initial_depth, cylinders\n    )\n\n    # Prepare data for plotting\n    fig = go.Figure()\n    for cyl in cylinders:\n        fig.add_trace(go.Mesh3d(\n            x=cyl['x'],\n            y=cyl['y'],\n            z=cyl['z'],\n            color=cyl['color'],\n            opacity=1.0,\n            i=[face[0] for face in cyl['faces']],\n            j=[face[1] for face in cyl['faces']],\n            k=[face[2] for face in cyl['faces']],\n            flatshading=True,\n            showscale=False\n        ))\n\n    fig.update_layout(\n        scene=dict(\n            xaxis=dict(visible=False),\n            yaxis=dict(visible=False),\n            zaxis=dict(visible=False),\n            aspectmode='data'\n        ),\n        showlegend=False\n    )\n    fig.show()\n\ninteract(\n    plot_tree_3d,\n    depth=widgets.IntSlider(min=1, max=8, step=1, value=4, description='Depth'),\n    angle_range_deg=widgets.FloatSlider(min=0, max=180, step=1, value=30, description='Angle Range'),\n    length_factor=widgets.FloatSlider(min=1, max=10, step=1, value=5, description='Base Length'),\n    linewidth_factor=widgets.FloatSlider(min=0.1, max=2, step=0.1, value=0.5, description='Base Width'),\n    length_scale=widgets.FloatSlider(min=0.5, max=1.5, step=0.05, value=0.7, description='Length Scale'),\n    width_scale=widgets.FloatSlider(min=0.5, max=1.0, step=0.05, value=0.7, description='Width Scale'),\n    branching_factor=widgets.IntSlider(min=1, max=5, step=1, value=2, description='Branches'),\n    branching_scale=widgets.FloatSlider(min=0.5, max=1.0, step=0.1, value=1.0, description='Branching Scale')\n)\n</pre> import numpy as np import plotly.graph_objects as go from ipywidgets import interact, widgets  def cylinder_between_points(p0, p1, radius, n=8):     \"\"\"     Generate the mesh data for a cylinder between two points p0 and p1.     \"\"\"     # Vector from p0 to p1     v = np.array(p1) - np.array(p0)     # Length of the cylinder     length = np.linalg.norm(v)     if length == 0:         return None  # Avoid division by zero     # Unit vector in direction of cylinder axis     v = v / length      # Create arbitrary vectors orthogonal to v     not_v = np.array([1, 0, 0])     if (v == not_v).all():         not_v = np.array([0, 1, 0])     n1 = np.cross(v, not_v)     n1 /= np.linalg.norm(n1)     n2 = np.cross(v, n1)      # Generate circle points in the plane orthogonal to v     t = np.linspace(0, 2 * np.pi, n)     circle = np.array([np.cos(t), np.sin(t)])     circle_pts = radius * (np.outer(n1, circle[0]) + np.outer(n2, circle[1]))      # Points at base and top of cylinder     x_base = p0[0] + circle_pts[0]     y_base = p0[1] + circle_pts[1]     z_base = p0[2] + circle_pts[2]      x_top = x_base + v[0] * length     y_top = y_base + v[1] * length     z_top = z_base + v[2] * length      # Combine base and top points     x = np.concatenate([x_base, x_top])     y = np.concatenate([y_base, y_top])     z = np.concatenate([z_base, z_top])      # Define faces of the cylinder     faces = []     n_points = n     for i in range(n_points):         next_i = (i + 1) % n_points         # Side faces         faces.append([i, next_i, n_points + next_i])         faces.append([i, n_points + next_i, n_points + i])     return x, y, z, faces  def draw_tree_3d(x1, y1, z1, theta, phi, depth, angle_range_deg, length_factor,                  linewidth_factor, length_scale, width_scale, branching_factor,                  branching_scale, initial_depth, cylinders):     if depth &gt; 0:         scale_exponent = initial_depth - depth         scaled_length = length_factor * (length_scale ** scale_exponent)         scaled_width = linewidth_factor * (width_scale ** scale_exponent)          # Compute the direction vector         direction = np.array([             np.sin(theta) * np.cos(phi),             np.sin(theta) * np.sin(phi),             np.cos(theta)         ])          # Compute the new point         x2 = x1 + direction[0] * scaled_length         y2 = y1 + direction[1] * scaled_length         z2 = z1 + direction[2] * scaled_length          # Store the cylinder data         cylinder_data = cylinder_between_points(             [x1, y1, z1],             [x2, y2, z2],             scaled_width         )         if cylinder_data:             x_cyl, y_cyl, z_cyl, faces = cylinder_data             cylinders.append({                 'x': x_cyl,                 'y': y_cyl,                 'z': z_cyl,                 'faces': faces,                 'color': 'green'             })          # Compute current branching factor         current_branching_factor = max(1, int(branching_factor * (branching_scale ** scale_exponent)))          # Generate new branches         angle_range_rad = np.deg2rad(angle_range_deg)          for _ in range(current_branching_factor):             # Random angles within the specified range             delta_theta = angle_range_rad * (np.random.rand() - 0.5)             delta_phi = angle_range_rad * (np.random.rand() - 0.5)             new_theta = theta + delta_theta             new_phi = phi + delta_phi             # Recursive call             draw_tree_3d(                 x2, y2, z2, new_theta, new_phi, depth - 1, angle_range_deg,                 length_factor, linewidth_factor, length_scale, width_scale,                 branching_factor, branching_scale, initial_depth, cylinders             )  def plot_tree_3d(depth, angle_range_deg, length_factor, linewidth_factor,                  length_scale, width_scale, branching_factor, branching_scale):     cylinders = []     initial_theta = 0  # Initial angle from z-axis     initial_phi = 0    # Initial angle in x-y plane     initial_depth = depth     draw_tree_3d(         0, 0, 0, initial_theta, initial_phi, depth, angle_range_deg,         length_factor, linewidth_factor, length_scale, width_scale,         branching_factor, branching_scale, initial_depth, cylinders     )      # Prepare data for plotting     fig = go.Figure()     for cyl in cylinders:         fig.add_trace(go.Mesh3d(             x=cyl['x'],             y=cyl['y'],             z=cyl['z'],             color=cyl['color'],             opacity=1.0,             i=[face[0] for face in cyl['faces']],             j=[face[1] for face in cyl['faces']],             k=[face[2] for face in cyl['faces']],             flatshading=True,             showscale=False         ))      fig.update_layout(         scene=dict(             xaxis=dict(visible=False),             yaxis=dict(visible=False),             zaxis=dict(visible=False),             aspectmode='data'         ),         showlegend=False     )     fig.show()  interact(     plot_tree_3d,     depth=widgets.IntSlider(min=1, max=8, step=1, value=4, description='Depth'),     angle_range_deg=widgets.FloatSlider(min=0, max=180, step=1, value=30, description='Angle Range'),     length_factor=widgets.FloatSlider(min=1, max=10, step=1, value=5, description='Base Length'),     linewidth_factor=widgets.FloatSlider(min=0.1, max=2, step=0.1, value=0.5, description='Base Width'),     length_scale=widgets.FloatSlider(min=0.5, max=1.5, step=0.05, value=0.7, description='Length Scale'),     width_scale=widgets.FloatSlider(min=0.5, max=1.0, step=0.05, value=0.7, description='Width Scale'),     branching_factor=widgets.IntSlider(min=1, max=5, step=1, value=2, description='Branches'),     branching_scale=widgets.FloatSlider(min=0.5, max=1.0, step=0.1, value=1.0, description='Branching Scale') )  <pre>interactive(children=(IntSlider(value=4, description='Depth', max=8, min=1), FloatSlider(value=30.0, descripti\u2026</pre> Out[1]: <pre>&lt;function __main__.plot_tree_3d(depth, angle_range_deg, length_factor, linewidth_factor, length_scale, width_scale, branching_factor, branching_scale)&gt;</pre> In\u00a0[3]: Copied! <pre>import numpy as np\nimport plotly.graph_objects as go\nfrom ipywidgets import interact, widgets\n\ndef cylinder_between_points(p0, p1, radius_base, radius_top, n=8):\n    \"\"\"\n    Generate the mesh data for a tapered cylinder (frustum) between two points p0 and p1.\n    \"\"\"\n    # Vector from p0 to p1\n    v = np.array(p1) - np.array(p0)\n    # Length of the cylinder\n    length = np.linalg.norm(v)\n    if length == 0:\n        return None  # Avoid division by zero\n    # Unit vector in direction of cylinder axis\n    v = v / length\n\n    # Create arbitrary vectors orthogonal to v\n    not_v = np.array([1, 0, 0])\n    if (v == not_v).all():\n        not_v = np.array([0, 1, 0])\n    n1 = np.cross(v, not_v)\n    n1 /= np.linalg.norm(n1)\n    n2 = np.cross(v, n1)\n\n    # Generate circle points in the plane orthogonal to v\n    t = np.linspace(0, 2 * np.pi, n, endpoint=False)\n    circle_base = np.array([np.cos(t), np.sin(t)]) * radius_base\n    circle_top = np.array([np.cos(t), np.sin(t)]) * radius_top\n\n    # Base circle points\n    x_base = p0[0] + n1[0] * circle_base[0] + n2[0] * circle_base[1]\n    y_base = p0[1] + n1[1] * circle_base[0] + n2[1] * circle_base[1]\n    z_base = p0[2] + n1[2] * circle_base[0] + n2[2] * circle_base[1]\n\n    # Top circle points\n    x_top = p1[0] + n1[0] * circle_top[0] + n2[0] * circle_top[1]\n    y_top = p1[1] + n1[1] * circle_top[0] + n2[1] * circle_top[1]\n    z_top = p1[2] + n1[2] * circle_top[0] + n2[2] * circle_top[1]\n\n    # Combine base and top points\n    x = np.concatenate([x_base, x_top])\n    y = np.concatenate([y_base, y_top])\n    z = np.concatenate([z_base, z_top])\n\n    # Define faces of the cylinder\n    faces = []\n    n_points = n\n    for i in range(n_points):\n        next_i = (i + 1) % n_points\n        # Side faces (two triangles per side)\n        faces.append([i, next_i, n_points + next_i])\n        faces.append([i, n_points + next_i, n_points + i])\n    return x, y, z, faces\n\ndef draw_tree_3d(x1, y1, z1, theta, phi, depth, angle_range_deg, length_factor,\n                 linewidth_factor, length_scale, width_scale, branching_factor,\n                 branching_scale, initial_depth, cylinders):\n    if depth &gt; 0:\n        scale_exponent = initial_depth - depth\n        scaled_length = length_factor * (length_scale ** scale_exponent)\n        scaled_width_base = linewidth_factor * (width_scale ** scale_exponent)\n        # Calculate the top width\n        scaled_width_top = linewidth_factor * (width_scale ** (scale_exponent + 1))\n\n        # Compute the direction vector\n        direction = np.array([\n            np.sin(theta) * np.cos(phi),\n            np.sin(theta) * np.sin(phi),\n            np.cos(theta)\n        ])\n\n        # Compute the new point\n        x2 = x1 + direction[0] * scaled_length\n        y2 = y1 + direction[1] * scaled_length\n        z2 = z1 + direction[2] * scaled_length\n\n        # Store the cylinder data\n        cylinder_data = cylinder_between_points(\n            [x1, y1, z1],\n            [x2, y2, z2],\n            scaled_width_base,\n            scaled_width_top\n        )\n        if cylinder_data:\n            x_cyl, y_cyl, z_cyl, faces = cylinder_data\n            cylinders.append({\n                'x': x_cyl,\n                'y': y_cyl,\n                'z': z_cyl,\n                'faces': faces,\n                'color': 'green'\n            })\n\n        # Compute current branching factor\n        current_branching_factor = max(1, int(branching_factor * (branching_scale ** scale_exponent)))\n\n        # Generate new branches\n        angle_range_rad = np.deg2rad(angle_range_deg)\n\n        for _ in range(current_branching_factor):\n            # Random angles within the specified range\n            delta_theta = angle_range_rad * (np.random.rand() - 0.5)\n            delta_phi = angle_range_rad * (np.random.rand() - 0.5)\n            new_theta = theta + delta_theta\n            new_phi = phi + delta_phi\n            # Recursive call\n            draw_tree_3d(\n                x2, y2, z2, new_theta, new_phi, depth - 1, angle_range_deg,\n                length_factor, linewidth_factor, length_scale, width_scale,\n                branching_factor, branching_scale, initial_depth, cylinders\n            )\n\ndef plot_tree_3d(depth, angle_range_deg, length_factor, linewidth_factor,\n                 length_scale, width_scale, branching_factor, branching_scale):\n    cylinders = []\n    initial_theta = 0  # Initial angle from z-axis\n    initial_phi = 0    # Initial angle in x-y plane\n    initial_depth = depth\n    draw_tree_3d(\n        0, 0, 0, initial_theta, initial_phi, depth, angle_range_deg,\n        length_factor, linewidth_factor, length_scale, width_scale,\n        branching_factor, branching_scale, initial_depth, cylinders\n    )\n\n    # Prepare data for plotting\n    fig = go.Figure()\n    for cyl in cylinders:\n        fig.add_trace(go.Mesh3d(\n            x=cyl['x'],\n            y=cyl['y'],\n            z=cyl['z'],\n            color=cyl['color'],\n            opacity=1.0,\n            i=[face[0] for face in cyl['faces']],\n            j=[face[1] for face in cyl['faces']],\n            k=[face[2] for face in cyl['faces']],\n            flatshading=True,\n            showscale=False\n        ))\n\n    fig.update_layout(\n        scene=dict(\n            xaxis=dict(visible=False),\n            yaxis=dict(visible=False),\n            zaxis=dict(visible=False),\n            aspectmode='data'\n        ),\n        showlegend=False\n    )\n    fig.show()\n\ninteract(\n    plot_tree_3d,\n    depth=widgets.IntSlider(min=1, max=16, step=1, value=8, description='Depth'),\n    angle_range_deg=widgets.FloatSlider(min=0, max=180, step=1, value=30, description='Angle Range'),\n    length_factor=widgets.FloatSlider(min=1, max=10, step=1, value=5, description='Base Length'),\n    linewidth_factor=widgets.FloatSlider(min=0.1, max=2, step=0.1, value=0.5, description='Base Width'),\n    length_scale=widgets.FloatSlider(min=0.5, max=2, step=0.05, value=0.7, description='Length Scale'),\n    width_scale=widgets.FloatSlider(min=0.5, max=2, step=0.05, value=0.7, description='Width Scale'),\n    branching_factor=widgets.IntSlider(min=1, max=10, step=1, value=2, description='Branches'),\n    branching_scale=widgets.FloatSlider(min=0.5, max=1.0, step=0.1, value=1.0, description='Branching Scale')\n)\n</pre> import numpy as np import plotly.graph_objects as go from ipywidgets import interact, widgets  def cylinder_between_points(p0, p1, radius_base, radius_top, n=8):     \"\"\"     Generate the mesh data for a tapered cylinder (frustum) between two points p0 and p1.     \"\"\"     # Vector from p0 to p1     v = np.array(p1) - np.array(p0)     # Length of the cylinder     length = np.linalg.norm(v)     if length == 0:         return None  # Avoid division by zero     # Unit vector in direction of cylinder axis     v = v / length      # Create arbitrary vectors orthogonal to v     not_v = np.array([1, 0, 0])     if (v == not_v).all():         not_v = np.array([0, 1, 0])     n1 = np.cross(v, not_v)     n1 /= np.linalg.norm(n1)     n2 = np.cross(v, n1)      # Generate circle points in the plane orthogonal to v     t = np.linspace(0, 2 * np.pi, n, endpoint=False)     circle_base = np.array([np.cos(t), np.sin(t)]) * radius_base     circle_top = np.array([np.cos(t), np.sin(t)]) * radius_top      # Base circle points     x_base = p0[0] + n1[0] * circle_base[0] + n2[0] * circle_base[1]     y_base = p0[1] + n1[1] * circle_base[0] + n2[1] * circle_base[1]     z_base = p0[2] + n1[2] * circle_base[0] + n2[2] * circle_base[1]      # Top circle points     x_top = p1[0] + n1[0] * circle_top[0] + n2[0] * circle_top[1]     y_top = p1[1] + n1[1] * circle_top[0] + n2[1] * circle_top[1]     z_top = p1[2] + n1[2] * circle_top[0] + n2[2] * circle_top[1]      # Combine base and top points     x = np.concatenate([x_base, x_top])     y = np.concatenate([y_base, y_top])     z = np.concatenate([z_base, z_top])      # Define faces of the cylinder     faces = []     n_points = n     for i in range(n_points):         next_i = (i + 1) % n_points         # Side faces (two triangles per side)         faces.append([i, next_i, n_points + next_i])         faces.append([i, n_points + next_i, n_points + i])     return x, y, z, faces  def draw_tree_3d(x1, y1, z1, theta, phi, depth, angle_range_deg, length_factor,                  linewidth_factor, length_scale, width_scale, branching_factor,                  branching_scale, initial_depth, cylinders):     if depth &gt; 0:         scale_exponent = initial_depth - depth         scaled_length = length_factor * (length_scale ** scale_exponent)         scaled_width_base = linewidth_factor * (width_scale ** scale_exponent)         # Calculate the top width         scaled_width_top = linewidth_factor * (width_scale ** (scale_exponent + 1))          # Compute the direction vector         direction = np.array([             np.sin(theta) * np.cos(phi),             np.sin(theta) * np.sin(phi),             np.cos(theta)         ])          # Compute the new point         x2 = x1 + direction[0] * scaled_length         y2 = y1 + direction[1] * scaled_length         z2 = z1 + direction[2] * scaled_length          # Store the cylinder data         cylinder_data = cylinder_between_points(             [x1, y1, z1],             [x2, y2, z2],             scaled_width_base,             scaled_width_top         )         if cylinder_data:             x_cyl, y_cyl, z_cyl, faces = cylinder_data             cylinders.append({                 'x': x_cyl,                 'y': y_cyl,                 'z': z_cyl,                 'faces': faces,                 'color': 'green'             })          # Compute current branching factor         current_branching_factor = max(1, int(branching_factor * (branching_scale ** scale_exponent)))          # Generate new branches         angle_range_rad = np.deg2rad(angle_range_deg)          for _ in range(current_branching_factor):             # Random angles within the specified range             delta_theta = angle_range_rad * (np.random.rand() - 0.5)             delta_phi = angle_range_rad * (np.random.rand() - 0.5)             new_theta = theta + delta_theta             new_phi = phi + delta_phi             # Recursive call             draw_tree_3d(                 x2, y2, z2, new_theta, new_phi, depth - 1, angle_range_deg,                 length_factor, linewidth_factor, length_scale, width_scale,                 branching_factor, branching_scale, initial_depth, cylinders             )  def plot_tree_3d(depth, angle_range_deg, length_factor, linewidth_factor,                  length_scale, width_scale, branching_factor, branching_scale):     cylinders = []     initial_theta = 0  # Initial angle from z-axis     initial_phi = 0    # Initial angle in x-y plane     initial_depth = depth     draw_tree_3d(         0, 0, 0, initial_theta, initial_phi, depth, angle_range_deg,         length_factor, linewidth_factor, length_scale, width_scale,         branching_factor, branching_scale, initial_depth, cylinders     )      # Prepare data for plotting     fig = go.Figure()     for cyl in cylinders:         fig.add_trace(go.Mesh3d(             x=cyl['x'],             y=cyl['y'],             z=cyl['z'],             color=cyl['color'],             opacity=1.0,             i=[face[0] for face in cyl['faces']],             j=[face[1] for face in cyl['faces']],             k=[face[2] for face in cyl['faces']],             flatshading=True,             showscale=False         ))      fig.update_layout(         scene=dict(             xaxis=dict(visible=False),             yaxis=dict(visible=False),             zaxis=dict(visible=False),             aspectmode='data'         ),         showlegend=False     )     fig.show()  interact(     plot_tree_3d,     depth=widgets.IntSlider(min=1, max=16, step=1, value=8, description='Depth'),     angle_range_deg=widgets.FloatSlider(min=0, max=180, step=1, value=30, description='Angle Range'),     length_factor=widgets.FloatSlider(min=1, max=10, step=1, value=5, description='Base Length'),     linewidth_factor=widgets.FloatSlider(min=0.1, max=2, step=0.1, value=0.5, description='Base Width'),     length_scale=widgets.FloatSlider(min=0.5, max=2, step=0.05, value=0.7, description='Length Scale'),     width_scale=widgets.FloatSlider(min=0.5, max=2, step=0.05, value=0.7, description='Width Scale'),     branching_factor=widgets.IntSlider(min=1, max=10, step=1, value=2, description='Branches'),     branching_scale=widgets.FloatSlider(min=0.5, max=1.0, step=0.1, value=1.0, description='Branching Scale') )  <pre>interactive(children=(IntSlider(value=8, description='Depth', max=16, min=1), FloatSlider(value=30.0, descript\u2026</pre> Out[3]: <pre>&lt;function __main__.plot_tree_3d(depth, angle_range_deg, length_factor, linewidth_factor, length_scale, width_scale, branching_factor, branching_scale)&gt;</pre> In\u00a0[2]: Copied! <pre>import numpy as np\nimport plotly.graph_objects as go\nfrom ipywidgets import interact, widgets\n\ndef cylinder_mesh(p0, p1, radius_base, radius_top, sections=8):\n    \"\"\"\n    Generate mesh data for a tapered cylinder (frustum) between two points.\n    \"\"\"\n    # Vector from p0 to p1\n    v = np.array(p1) - np.array(p0)\n    # Length of the cylinder\n    length = np.linalg.norm(v)\n    if length == 0:\n        return None\n    # Unit vector in direction of the cylinder\n    v = v / length\n\n    # Create arbitrary vectors orthogonal to v\n    not_v = np.array([1, 0, 0])\n    if np.allclose(v, not_v):\n        not_v = np.array([0, 1, 0])\n    n1 = np.cross(v, not_v)\n    n1 /= np.linalg.norm(n1)\n    n2 = np.cross(v, n1)\n\n    # Create circle points in the plane orthogonal to v\n    t = np.linspace(0, 2 * np.pi, sections, endpoint=False)\n    circle_base = n1[:, None] * np.cos(t)[None, :] + n2[:, None] * np.sin(t)[None, :]\n    circle_top = circle_base.copy()\n\n    # Scale circles by radii\n    circle_base *= radius_base\n    circle_top *= radius_top\n\n    # Points at base and top\n    base_points = p0[:, None] + circle_base\n    top_points = p1[:, None] + circle_top\n\n    # Combine points\n    x = np.hstack([base_points[0], top_points[0]])\n    y = np.hstack([base_points[1], top_points[1]])\n    z = np.hstack([base_points[2], top_points[2]])\n\n    # Create faces\n    faces = []\n    n = sections\n    for i in range(n):\n        next_i = (i + 1) % n\n        faces.append([i, next_i, n + next_i])\n        faces.append([i, n + next_i, n + i])\n    return x, y, z, faces\n\ndef rotate_vector(v, k, theta):\n    \"\"\"\n    Rotate vector v around axis k by angle theta using Rodrigues' rotation formula.\n    \"\"\"\n    v_rot = v * np.cos(theta) + np.cross(k, v) * np.sin(theta) + k * np.dot(k, v) * (1 - np.cos(theta))\n    return v_rot\n\ndef grow_tree(p0, direction, length, radius_base, levels, angle, length_reduction, branches_per_level, tree_elements):\n    \"\"\"\n    Recursively grow the tree from point p0 in a given direction.\n    \"\"\"\n    if levels == 0:\n        return\n\n    p1 = p0 + direction * length\n\n    # Calculate the top radius (tapering)\n    radius_top = radius_base * 0.8  # Simple tapering factor\n\n    # Add the cylinder representing the trunk or branch\n    cylinder = cylinder_mesh(p0, p1, radius_base, radius_top)\n    if cylinder:\n        x, y, z, faces = cylinder\n        tree_elements.append({\n            'x': x,\n            'y': y,\n            'z': z,\n            'faces': faces,\n            'color': 'saddlebrown'\n        })\n\n    # Calculate child branch parameters\n    length_child = length * length_reduction\n    N = branches_per_level\n    radius_child = radius_base * np.sqrt((radius_top / radius_base)**2 * length / (N * length_child))\n\n    # Generate branches at this level\n    for _ in range(N):\n        # Random rotation for natural appearance\n        theta = angle + (np.random.rand() - 0.5) * np.deg2rad(10)\n        phi = np.random.rand() * 2 * np.pi\n\n        # Spherical to Cartesian coordinates\n        new_direction = np.array([\n            np.sin(theta) * np.cos(phi),\n            np.sin(theta) * np.sin(phi),\n            np.cos(theta)\n        ])\n        new_direction = new_direction / np.linalg.norm(new_direction)\n\n        # Rotate new_direction to align with the parent branch direction\n        rotation_axis = np.cross([0, 0, 1], direction)\n        rotation_angle = np.arccos(np.clip(np.dot(direction, [0, 0, 1]), -1.0, 1.0))\n        if np.linalg.norm(rotation_axis) &gt; 1e-6:\n            rotation_axis /= np.linalg.norm(rotation_axis)\n            new_direction = rotate_vector(new_direction, rotation_axis, rotation_angle)\n\n        # Recursive call to grow the branch\n        grow_tree(\n            p1,\n            new_direction,\n            length_child,\n            radius_child,\n            levels - 1,\n            angle,\n            length_reduction,\n            branches_per_level,\n            tree_elements\n        )\n\ndef plot_tree(levels, trunk_length, trunk_radius, angle_deg, length_reduction, branches_per_level):\n    tree_elements = []\n    # Start with the main trunk\n    p0 = np.array([0, 0, 0])\n    direction = np.array([0, 0, 1])  # Grow along z-axis\n    angle_rad = np.deg2rad(angle_deg)\n    grow_tree(\n        p0,\n        direction,\n        trunk_length,\n        trunk_radius,\n        levels,\n        angle_rad,\n        length_reduction,\n        branches_per_level,\n        tree_elements\n    )\n\n    # Plotting\n    fig = go.Figure()\n    for elem in tree_elements:\n        fig.add_trace(go.Mesh3d(\n            x=elem['x'],\n            y=elem['y'],\n            z=elem['z'],\n            i=[face[0] for face in elem['faces']],\n            j=[face[1] for face in elem['faces']],\n            k=[face[2] for face in elem['faces']],\n            color=elem['color'],\n            flatshading=True,\n            lighting=dict(ambient=0.5, diffuse=0.8, roughness=0.9),\n            showscale=False\n        ))\n    fig.update_layout(\n        scene=dict(\n            xaxis=dict(visible=False),\n            yaxis=dict(visible=False),\n            zaxis=dict(visible=False),\n            aspectmode='data'\n        ),\n        showlegend=False,\n        margin=dict(l=0, r=0, t=0, b=0)\n    )\n    fig.show()\n\n# Interactive widgets\ninteract(\n    plot_tree,\n    levels=widgets.IntSlider(min=1, max=8, step=1, value=5, description='Levels'),\n    trunk_length=widgets.FloatSlider(min=1, max=15, step=0.5, value=7, description='Trunk Length'),\n    trunk_radius=widgets.FloatSlider(min=0.1, max=1.5, step=0.1, value=0.5, description='Trunk Radius'),\n    angle_deg=widgets.FloatSlider(min=10, max=80, step=5, value=30, description='Branch Angle'),\n    length_reduction=widgets.FloatSlider(min=0.4, max=0.9, step=0.05, value=0.7, description='Length Reduction'),\n    branches_per_level=widgets.IntSlider(min=1, max=8, step=1, value=4, description='Branches/Level')\n)\n</pre> import numpy as np import plotly.graph_objects as go from ipywidgets import interact, widgets  def cylinder_mesh(p0, p1, radius_base, radius_top, sections=8):     \"\"\"     Generate mesh data for a tapered cylinder (frustum) between two points.     \"\"\"     # Vector from p0 to p1     v = np.array(p1) - np.array(p0)     # Length of the cylinder     length = np.linalg.norm(v)     if length == 0:         return None     # Unit vector in direction of the cylinder     v = v / length      # Create arbitrary vectors orthogonal to v     not_v = np.array([1, 0, 0])     if np.allclose(v, not_v):         not_v = np.array([0, 1, 0])     n1 = np.cross(v, not_v)     n1 /= np.linalg.norm(n1)     n2 = np.cross(v, n1)      # Create circle points in the plane orthogonal to v     t = np.linspace(0, 2 * np.pi, sections, endpoint=False)     circle_base = n1[:, None] * np.cos(t)[None, :] + n2[:, None] * np.sin(t)[None, :]     circle_top = circle_base.copy()      # Scale circles by radii     circle_base *= radius_base     circle_top *= radius_top      # Points at base and top     base_points = p0[:, None] + circle_base     top_points = p1[:, None] + circle_top      # Combine points     x = np.hstack([base_points[0], top_points[0]])     y = np.hstack([base_points[1], top_points[1]])     z = np.hstack([base_points[2], top_points[2]])      # Create faces     faces = []     n = sections     for i in range(n):         next_i = (i + 1) % n         faces.append([i, next_i, n + next_i])         faces.append([i, n + next_i, n + i])     return x, y, z, faces  def rotate_vector(v, k, theta):     \"\"\"     Rotate vector v around axis k by angle theta using Rodrigues' rotation formula.     \"\"\"     v_rot = v * np.cos(theta) + np.cross(k, v) * np.sin(theta) + k * np.dot(k, v) * (1 - np.cos(theta))     return v_rot  def grow_tree(p0, direction, length, radius_base, levels, angle, length_reduction, branches_per_level, tree_elements):     \"\"\"     Recursively grow the tree from point p0 in a given direction.     \"\"\"     if levels == 0:         return      p1 = p0 + direction * length      # Calculate the top radius (tapering)     radius_top = radius_base * 0.8  # Simple tapering factor      # Add the cylinder representing the trunk or branch     cylinder = cylinder_mesh(p0, p1, radius_base, radius_top)     if cylinder:         x, y, z, faces = cylinder         tree_elements.append({             'x': x,             'y': y,             'z': z,             'faces': faces,             'color': 'saddlebrown'         })      # Calculate child branch parameters     length_child = length * length_reduction     N = branches_per_level     radius_child = radius_base * np.sqrt((radius_top / radius_base)**2 * length / (N * length_child))      # Generate branches at this level     for _ in range(N):         # Random rotation for natural appearance         theta = angle + (np.random.rand() - 0.5) * np.deg2rad(10)         phi = np.random.rand() * 2 * np.pi          # Spherical to Cartesian coordinates         new_direction = np.array([             np.sin(theta) * np.cos(phi),             np.sin(theta) * np.sin(phi),             np.cos(theta)         ])         new_direction = new_direction / np.linalg.norm(new_direction)          # Rotate new_direction to align with the parent branch direction         rotation_axis = np.cross([0, 0, 1], direction)         rotation_angle = np.arccos(np.clip(np.dot(direction, [0, 0, 1]), -1.0, 1.0))         if np.linalg.norm(rotation_axis) &gt; 1e-6:             rotation_axis /= np.linalg.norm(rotation_axis)             new_direction = rotate_vector(new_direction, rotation_axis, rotation_angle)          # Recursive call to grow the branch         grow_tree(             p1,             new_direction,             length_child,             radius_child,             levels - 1,             angle,             length_reduction,             branches_per_level,             tree_elements         )  def plot_tree(levels, trunk_length, trunk_radius, angle_deg, length_reduction, branches_per_level):     tree_elements = []     # Start with the main trunk     p0 = np.array([0, 0, 0])     direction = np.array([0, 0, 1])  # Grow along z-axis     angle_rad = np.deg2rad(angle_deg)     grow_tree(         p0,         direction,         trunk_length,         trunk_radius,         levels,         angle_rad,         length_reduction,         branches_per_level,         tree_elements     )      # Plotting     fig = go.Figure()     for elem in tree_elements:         fig.add_trace(go.Mesh3d(             x=elem['x'],             y=elem['y'],             z=elem['z'],             i=[face[0] for face in elem['faces']],             j=[face[1] for face in elem['faces']],             k=[face[2] for face in elem['faces']],             color=elem['color'],             flatshading=True,             lighting=dict(ambient=0.5, diffuse=0.8, roughness=0.9),             showscale=False         ))     fig.update_layout(         scene=dict(             xaxis=dict(visible=False),             yaxis=dict(visible=False),             zaxis=dict(visible=False),             aspectmode='data'         ),         showlegend=False,         margin=dict(l=0, r=0, t=0, b=0)     )     fig.show()  # Interactive widgets interact(     plot_tree,     levels=widgets.IntSlider(min=1, max=8, step=1, value=5, description='Levels'),     trunk_length=widgets.FloatSlider(min=1, max=15, step=0.5, value=7, description='Trunk Length'),     trunk_radius=widgets.FloatSlider(min=0.1, max=1.5, step=0.1, value=0.5, description='Trunk Radius'),     angle_deg=widgets.FloatSlider(min=10, max=80, step=5, value=30, description='Branch Angle'),     length_reduction=widgets.FloatSlider(min=0.4, max=0.9, step=0.05, value=0.7, description='Length Reduction'),     branches_per_level=widgets.IntSlider(min=1, max=8, step=1, value=4, description='Branches/Level') )  <pre>interactive(children=(IntSlider(value=5, description='Levels', max=8, min=1), FloatSlider(value=7.0, descripti\u2026</pre> Out[2]: <pre>&lt;function __main__.plot_tree(levels, trunk_length, trunk_radius, angle_deg, length_reduction, branches_per_level)&gt;</pre> In\u00a0[4]: Copied! <pre>import numpy as np\nimport plotly.graph_objects as go\nfrom ipywidgets import interact, widgets\n\ndef cylinder_mesh(p0, p1, radius_base, radius_top, sections=8):\n    \"\"\"\n    Generate mesh data for a tapered cylinder (frustum) between two points.\n    \"\"\"\n    # Vector from p0 to p1\n    v = np.array(p1) - np.array(p0)\n    # Length of the cylinder\n    length = np.linalg.norm(v)\n    if length == 0:\n        return None\n    # Unit vector in direction of the cylinder\n    v = v / length\n\n    # Create arbitrary vectors orthogonal to v\n    not_v = np.array([1, 0, 0])\n    if np.allclose(v, not_v):\n        not_v = np.array([0, 1, 0])\n    n1 = np.cross(v, not_v)\n    n1 /= np.linalg.norm(n1)\n    n2 = np.cross(v, n1)\n\n    # Create circle points in the plane orthogonal to v\n    t = np.linspace(0, 2 * np.pi, sections, endpoint=False)\n    circle_base = n1[:, None] * np.cos(t)[None, :] + n2[:, None] * np.sin(t)[None, :]\n    circle_top = circle_base.copy()\n\n    # Scale circles by radii\n    circle_base *= radius_base\n    circle_top *= radius_top\n\n    # Points at base and top\n    base_points = p0[:, None] + circle_base\n    top_points = p1[:, None] + circle_top\n\n    # Combine points\n    x = np.hstack([base_points[0], top_points[0]])\n    y = np.hstack([base_points[1], top_points[1]])\n    z = np.hstack([base_points[2], top_points[2]])\n\n    # Create faces\n    faces = []\n    n = sections\n    for i in range(n):\n        next_i = (i + 1) % n\n        faces.append([i, next_i, n + next_i])\n        faces.append([i, n + next_i, n + i])\n    return x, y, z, faces\n\ndef rotate_vector(v, k, theta):\n    \"\"\"\n    Rotate vector v around axis k by angle theta using Rodrigues' rotation formula.\n    \"\"\"\n    v_rot = v * np.cos(theta) + np.cross(k, v) * np.sin(theta) + k * np.dot(k, v) * (1 - np.cos(theta))\n    return v_rot\n\ndef grow_tree(p0, direction, length, radius_base, taper_ratio, levels, angle, length_reduction, branches_per_level, tree_elements):\n    \"\"\"\n    Recursively grow the tree from point p0 in a given direction.\n    \"\"\"\n    if levels == 0:\n        return\n\n    # Calculate end point of the current branch\n    p1 = p0 + direction * length\n\n    # Calculate top radius using consistent tapering\n    radius_top = radius_base * taper_ratio\n\n    # Add the cylinder representing the trunk or branch\n    cylinder = cylinder_mesh(p0, p1, radius_base, radius_top)\n    if cylinder:\n        x, y, z, faces = cylinder\n        tree_elements.append({\n            'x': x,\n            'y': y,\n            'z': z,\n            'faces': faces,\n            'color': 'saddlebrown'\n        })\n\n    # Calculate base radius of child branches\n    N = branches_per_level\n    radius_base_child = radius_top / np.sqrt(N)\n\n    # Ensure the base radius of child branches equals the top radius of the parent branch divided by sqrt(N)\n    # Calculate top radius of child branches using the same taper ratio\n    radius_top_child = radius_base_child * taper_ratio\n\n    # Length of child branches\n    length_child = length * length_reduction\n\n    # Generate branches at this level\n    for _ in range(N):\n        # Random rotation for natural appearance\n        theta = angle + (np.random.rand() - 0.5) * np.deg2rad(10)\n        phi = np.random.rand() * 2 * np.pi\n\n        # Spherical to Cartesian coordinates\n        new_direction = np.array([\n            np.sin(theta) * np.cos(phi),\n            np.sin(theta) * np.sin(phi),\n            np.cos(theta)\n        ])\n        new_direction = new_direction / np.linalg.norm(new_direction)\n\n        # Rotate new_direction to align with the parent branch direction\n        rotation_axis = np.cross([0, 0, 1], direction)\n        rotation_angle = np.arccos(np.clip(np.dot(direction, [0, 0, 1]), -1.0, 1.0))\n        if np.linalg.norm(rotation_axis) &gt; 1e-6:\n            rotation_axis /= np.linalg.norm(rotation_axis)\n            new_direction = rotate_vector(new_direction, rotation_axis, rotation_angle)\n\n        # Recursive call to grow the branch\n        grow_tree(\n            p1,\n            new_direction,\n            length_child,\n            radius_base_child,\n            taper_ratio,\n            levels - 1,\n            angle,\n            length_reduction,\n            branches_per_level,\n            tree_elements\n        )\n\ndef plot_tree(levels, trunk_length, trunk_radius, taper_ratio, angle_deg, length_reduction, branches_per_level):\n    tree_elements = []\n    # Start with the main trunk\n    p0 = np.array([0, 0, 0])\n    direction = np.array([0, 0, 1])  # Grow along z-axis\n    angle_rad = np.deg2rad(angle_deg)\n    grow_tree(\n        p0,\n        direction,\n        trunk_length,\n        trunk_radius,\n        taper_ratio,\n        levels,\n        angle_rad,\n        length_reduction,\n        branches_per_level,\n        tree_elements\n    )\n\n    # Plotting\n    fig = go.Figure()\n    for elem in tree_elements:\n        fig.add_trace(go.Mesh3d(\n            x=elem['x'],\n            y=elem['y'],\n            z=elem['z'],\n            i=[face[0] for face in elem['faces']],\n            j=[face[1] for face in elem['faces']],\n            k=[face[2] for face in elem['faces']],\n            color=elem['color'],\n            flatshading=True,\n            lighting=dict(ambient=0.5, diffuse=0.8, roughness=0.9),\n            showscale=False\n        ))\n    fig.update_layout(\n        scene=dict(\n            xaxis=dict(visible=False),\n            yaxis=dict(visible=False),\n            zaxis=dict(visible=False),\n            aspectmode='data'\n        ),\n        showlegend=False,\n        margin=dict(l=0, r=0, t=0, b=0)\n    )\n    fig.show()\n\n# Interactive widgets\ninteract(\n    plot_tree,\n    levels=widgets.IntSlider(min=1, max=8, step=1, value=5, description='Levels'),\n    trunk_length=widgets.FloatSlider(min=1, max=15, step=0.5, value=7, description='Trunk Length'),\n    trunk_radius=widgets.FloatSlider(min=0.1, max=1.5, step=0.1, value=0.5, description='Trunk Radius'),\n    taper_ratio=widgets.FloatSlider(min=0.5, max=1.0, step=0.05, value=0.7, description='Taper Ratio'),\n    angle_deg=widgets.FloatSlider(min=10, max=80, step=5, value=30, description='Branch Angle'),\n    length_reduction=widgets.FloatSlider(min=0.5, max=1.0, step=0.05, value=0.7, description='Length Reduction'),\n    branches_per_level=widgets.IntSlider(min=1, max=8, step=1, value=3, description='Branches/Level')\n)\n</pre> import numpy as np import plotly.graph_objects as go from ipywidgets import interact, widgets  def cylinder_mesh(p0, p1, radius_base, radius_top, sections=8):     \"\"\"     Generate mesh data for a tapered cylinder (frustum) between two points.     \"\"\"     # Vector from p0 to p1     v = np.array(p1) - np.array(p0)     # Length of the cylinder     length = np.linalg.norm(v)     if length == 0:         return None     # Unit vector in direction of the cylinder     v = v / length      # Create arbitrary vectors orthogonal to v     not_v = np.array([1, 0, 0])     if np.allclose(v, not_v):         not_v = np.array([0, 1, 0])     n1 = np.cross(v, not_v)     n1 /= np.linalg.norm(n1)     n2 = np.cross(v, n1)      # Create circle points in the plane orthogonal to v     t = np.linspace(0, 2 * np.pi, sections, endpoint=False)     circle_base = n1[:, None] * np.cos(t)[None, :] + n2[:, None] * np.sin(t)[None, :]     circle_top = circle_base.copy()      # Scale circles by radii     circle_base *= radius_base     circle_top *= radius_top      # Points at base and top     base_points = p0[:, None] + circle_base     top_points = p1[:, None] + circle_top      # Combine points     x = np.hstack([base_points[0], top_points[0]])     y = np.hstack([base_points[1], top_points[1]])     z = np.hstack([base_points[2], top_points[2]])      # Create faces     faces = []     n = sections     for i in range(n):         next_i = (i + 1) % n         faces.append([i, next_i, n + next_i])         faces.append([i, n + next_i, n + i])     return x, y, z, faces  def rotate_vector(v, k, theta):     \"\"\"     Rotate vector v around axis k by angle theta using Rodrigues' rotation formula.     \"\"\"     v_rot = v * np.cos(theta) + np.cross(k, v) * np.sin(theta) + k * np.dot(k, v) * (1 - np.cos(theta))     return v_rot  def grow_tree(p0, direction, length, radius_base, taper_ratio, levels, angle, length_reduction, branches_per_level, tree_elements):     \"\"\"     Recursively grow the tree from point p0 in a given direction.     \"\"\"     if levels == 0:         return      # Calculate end point of the current branch     p1 = p0 + direction * length      # Calculate top radius using consistent tapering     radius_top = radius_base * taper_ratio      # Add the cylinder representing the trunk or branch     cylinder = cylinder_mesh(p0, p1, radius_base, radius_top)     if cylinder:         x, y, z, faces = cylinder         tree_elements.append({             'x': x,             'y': y,             'z': z,             'faces': faces,             'color': 'saddlebrown'         })      # Calculate base radius of child branches     N = branches_per_level     radius_base_child = radius_top / np.sqrt(N)      # Ensure the base radius of child branches equals the top radius of the parent branch divided by sqrt(N)     # Calculate top radius of child branches using the same taper ratio     radius_top_child = radius_base_child * taper_ratio      # Length of child branches     length_child = length * length_reduction      # Generate branches at this level     for _ in range(N):         # Random rotation for natural appearance         theta = angle + (np.random.rand() - 0.5) * np.deg2rad(10)         phi = np.random.rand() * 2 * np.pi          # Spherical to Cartesian coordinates         new_direction = np.array([             np.sin(theta) * np.cos(phi),             np.sin(theta) * np.sin(phi),             np.cos(theta)         ])         new_direction = new_direction / np.linalg.norm(new_direction)          # Rotate new_direction to align with the parent branch direction         rotation_axis = np.cross([0, 0, 1], direction)         rotation_angle = np.arccos(np.clip(np.dot(direction, [0, 0, 1]), -1.0, 1.0))         if np.linalg.norm(rotation_axis) &gt; 1e-6:             rotation_axis /= np.linalg.norm(rotation_axis)             new_direction = rotate_vector(new_direction, rotation_axis, rotation_angle)          # Recursive call to grow the branch         grow_tree(             p1,             new_direction,             length_child,             radius_base_child,             taper_ratio,             levels - 1,             angle,             length_reduction,             branches_per_level,             tree_elements         )  def plot_tree(levels, trunk_length, trunk_radius, taper_ratio, angle_deg, length_reduction, branches_per_level):     tree_elements = []     # Start with the main trunk     p0 = np.array([0, 0, 0])     direction = np.array([0, 0, 1])  # Grow along z-axis     angle_rad = np.deg2rad(angle_deg)     grow_tree(         p0,         direction,         trunk_length,         trunk_radius,         taper_ratio,         levels,         angle_rad,         length_reduction,         branches_per_level,         tree_elements     )      # Plotting     fig = go.Figure()     for elem in tree_elements:         fig.add_trace(go.Mesh3d(             x=elem['x'],             y=elem['y'],             z=elem['z'],             i=[face[0] for face in elem['faces']],             j=[face[1] for face in elem['faces']],             k=[face[2] for face in elem['faces']],             color=elem['color'],             flatshading=True,             lighting=dict(ambient=0.5, diffuse=0.8, roughness=0.9),             showscale=False         ))     fig.update_layout(         scene=dict(             xaxis=dict(visible=False),             yaxis=dict(visible=False),             zaxis=dict(visible=False),             aspectmode='data'         ),         showlegend=False,         margin=dict(l=0, r=0, t=0, b=0)     )     fig.show()  # Interactive widgets interact(     plot_tree,     levels=widgets.IntSlider(min=1, max=8, step=1, value=5, description='Levels'),     trunk_length=widgets.FloatSlider(min=1, max=15, step=0.5, value=7, description='Trunk Length'),     trunk_radius=widgets.FloatSlider(min=0.1, max=1.5, step=0.1, value=0.5, description='Trunk Radius'),     taper_ratio=widgets.FloatSlider(min=0.5, max=1.0, step=0.05, value=0.7, description='Taper Ratio'),     angle_deg=widgets.FloatSlider(min=10, max=80, step=5, value=30, description='Branch Angle'),     length_reduction=widgets.FloatSlider(min=0.5, max=1.0, step=0.05, value=0.7, description='Length Reduction'),     branches_per_level=widgets.IntSlider(min=1, max=8, step=1, value=3, description='Branches/Level') )  <pre>interactive(children=(IntSlider(value=5, description='Levels', max=8, min=1), FloatSlider(value=7.0, descripti\u2026</pre> Out[4]: <pre>&lt;function __main__.plot_tree(levels, trunk_length, trunk_radius, taper_ratio, angle_deg, length_reduction, branches_per_level)&gt;</pre> In\u00a0[5]: Copied! <pre>import numpy as np\nimport plotly.graph_objects as go\nfrom ipywidgets import interact, widgets\n\ndef cylinder_mesh(p0, p1, radius_base, radius_top, sections=8):\n    \"\"\"\n    Generate mesh data for a tapered cylinder (frustum) between two points.\n    \"\"\"\n    # Vector from p0 to p1\n    v = np.array(p1) - np.array(p0)\n    # Length of the cylinder\n    length = np.linalg.norm(v)\n    if length == 0:\n        return None\n    # Unit vector in direction of the cylinder\n    v = v / length\n\n    # Create arbitrary vectors orthogonal to v\n    not_v = np.array([1, 0, 0])\n    if np.allclose(v, not_v):\n        not_v = np.array([0, 1, 0])\n    n1 = np.cross(v, not_v)\n    n1 /= np.linalg.norm(n1)\n    n2 = np.cross(v, n1)\n\n    # Create circle points in the plane orthogonal to v\n    t = np.linspace(0, 2 * np.pi, sections, endpoint=False)\n    circle_base = n1[:, None] * np.cos(t)[None, :] + n2[:, None] * np.sin(t)[None, :]\n    circle_top = circle_base.copy()\n\n    # Scale circles by radii\n    circle_base *= radius_base\n    circle_top *= radius_top\n\n    # Points at base and top\n    base_points = p0[:, None] + circle_base\n    top_points = p1[:, None] + circle_top\n\n    # Combine points\n    x = np.hstack([base_points[0], top_points[0]])\n    y = np.hstack([base_points[1], top_points[1]])\n    z = np.hstack([base_points[2], top_points[2]])\n\n    # Create faces\n    faces = []\n    n = sections\n    for i in range(n):\n        next_i = (i + 1) % n\n        faces.append([i, next_i, n + next_i])\n        faces.append([i, n + next_i, n + i])\n    return x, y, z, faces\n\ndef rotate_vector(v, k, theta):\n    \"\"\"\n    Rotate vector v around axis k by angle theta using Rodrigues' rotation formula.\n    \"\"\"\n    v_rot = v * np.cos(theta) + np.cross(k, v) * np.sin(theta) + k * np.dot(k, v) * (1 - np.cos(theta))\n    return v_rot\n\ndef grow_tree(p0, direction, length, radius_base, taper_ratio, levels, angle, length_reduction,\n              branches_per_level, tree_elements, is_root=False):\n    \"\"\"\n    Recursively grow the tree from point p0 in a given direction.\n    \"\"\"\n    if levels == 0 or radius_base &lt; 0.01 or length &lt; 0.01:\n        return\n\n    # Calculate end point of the current branch\n    p1 = p0 + direction * length\n\n    # Ensure roots do not grow above ground level\n    if is_root and p1[2] &gt; 0:\n        p1[2] = 0\n\n    # Calculate top radius using consistent tapering\n    radius_top = radius_base * taper_ratio\n\n    # Add the cylinder representing the trunk or branch\n    cylinder = cylinder_mesh(p0, p1, radius_base, radius_top)\n    if cylinder:\n        x, y, z, faces = cylinder\n        tree_elements.append({\n            'x': x,\n            'y': y,\n            'z': z,\n            'faces': faces,\n            'color': 'saddlebrown' if not is_root else 'sienna'\n        })\n\n    # Calculate base radius of child branches\n    N = branches_per_level\n    if N &gt; 0:\n        radius_base_child = radius_top / np.sqrt(N)\n    else:\n        radius_base_child = 0\n\n    # Length of child branches\n    length_child = length * length_reduction\n\n    # Generate branches at this level\n    for _ in range(N):\n        # Random rotation for natural appearance\n        if is_root:\n            # For roots, theta ranges from \u03c0/2 to \u03c0 (90\u00b0 to 180\u00b0), pointing downward\n            min_theta = np.pi / 2\n            max_theta = np.pi / 2 + angle\n            theta = min_theta + np.random.rand() * (max_theta - min_theta)\n        else:\n            # For crown, theta ranges from 0 to angle (pointing upward)\n            min_theta = 0\n            max_theta = angle\n            theta = min_theta + np.random.rand() * (max_theta - min_theta)\n\n        # Add small random variation\n        theta += (np.random.rand() - 0.5) * np.deg2rad(10)\n        phi = np.random.rand() * 2 * np.pi\n\n        # Ensure theta is within valid range\n        if is_root:\n            theta = np.clip(theta, np.pi / 2, np.pi)\n        else:\n            theta = np.clip(theta, 0, np.pi / 2)\n\n        # Spherical to Cartesian coordinates\n        new_direction = np.array([\n            np.sin(theta) * np.cos(phi),\n            np.sin(theta) * np.sin(phi),\n            np.cos(theta)\n        ])\n\n        # Rotate new_direction to align with the parent branch direction\n        rotation_axis = np.cross([0, 0, 1], direction)\n        rotation_angle = np.arccos(np.clip(np.dot(direction, [0, 0, 1]), -1.0, 1.0))\n        if np.linalg.norm(rotation_axis) &gt; 1e-6:\n            rotation_axis /= np.linalg.norm(rotation_axis)\n            new_direction = rotate_vector(new_direction, rotation_axis, rotation_angle)\n\n        # Recursive call to grow the branch\n        grow_tree(\n            p1,\n            new_direction,\n            length_child,\n            radius_base_child,\n            taper_ratio,\n            levels - 1,\n            angle,\n            length_reduction,\n            branches_per_level,\n            tree_elements,\n            is_root=is_root\n        )\n\ndef plot_tree(\n    # Crown parameters\n    crown_levels, crown_length, crown_radius, crown_taper_ratio, crown_angle_deg, crown_length_reduction, crown_branches_per_level,\n    # Root parameters\n    root_levels, root_length, root_radius, root_taper_ratio, root_angle_deg, root_length_reduction, root_branches_per_level\n):\n    tree_elements = []\n    # Start with the main trunk (above ground)\n    p0 = np.array([0, 0, 0])\n    direction = np.array([0, 0, 1])  # Grow upwards\n    crown_angle_rad = np.deg2rad(crown_angle_deg)\n    grow_tree(\n        p0,\n        direction,\n        crown_length,\n        crown_radius,\n        crown_taper_ratio,\n        crown_levels,\n        crown_angle_rad,\n        crown_length_reduction,\n        crown_branches_per_level,\n        tree_elements,\n        is_root=False\n    )\n\n    # Now grow the roots (below ground)\n    direction_root = np.array([0, 0, -1])  # Grow downwards\n    root_angle_rad = np.deg2rad(root_angle_deg)\n    grow_tree(\n        p0,\n        direction_root,\n        root_length,\n        root_radius,\n        root_taper_ratio,\n        root_levels,\n        root_angle_rad,\n        root_length_reduction,\n        root_branches_per_level,\n        tree_elements,\n        is_root=True\n    )\n\n    # Plotting\n    fig = go.Figure()\n    for elem in tree_elements:\n        fig.add_trace(go.Mesh3d(\n            x=elem['x'],\n            y=elem['y'],\n            z=elem['z'],\n            i=[face[0] for face in elem['faces']],\n            j=[face[1] for face in elem['faces']],\n            k=[face[2] for face in elem['faces']],\n            color=elem['color'],\n            flatshading=True,\n            lighting=dict(ambient=0.5, diffuse=0.8, roughness=0.9),\n            showscale=False\n        ))\n    fig.update_layout(\n        scene=dict(\n            xaxis=dict(visible=False),\n            yaxis=dict(visible=False),\n            zaxis=dict(visible=False),\n            aspectmode='data'\n        ),\n        showlegend=False,\n        margin=dict(l=0, r=0, t=0, b=0)\n    )\n    fig.show()\n\n# Interactive widgets\ncrown_controls = {\n    'crown_levels': widgets.IntSlider(min=1, max=8, step=1, value=5, description='Crown Levels'),\n    'crown_length': widgets.FloatSlider(min=1, max=15, step=0.5, value=7, description='Crown Length'),\n    'crown_radius': widgets.FloatSlider(min=0.1, max=1.5, step=0.1, value=0.5, description='Crown Radius'),\n    'crown_taper_ratio': widgets.FloatSlider(min=0.5, max=1.0, step=0.05, value=0.7, description='Crown Taper'),\n    'crown_angle_deg': widgets.FloatSlider(min=10, max=80, step=5, value=30, description='Crown Angle'),\n    'crown_length_reduction': widgets.FloatSlider(min=0.5, max=1.0, step=0.05, value=0.7, description='Crown Length Red.'),\n    'crown_branches_per_level': widgets.IntSlider(min=0, max=8, step=1, value=3, description='Crown Branches')\n}\n\nroot_controls = {\n    'root_levels': widgets.IntSlider(min=1, max=8, step=1, value=4, description='Root Levels'),\n    'root_length': widgets.FloatSlider(min=1, max=15, step=0.5, value=5, description='Root Length'),\n    'root_radius': widgets.FloatSlider(min=0.1, max=1.5, step=0.1, value=0.4, description='Root Radius'),\n    'root_taper_ratio': widgets.FloatSlider(min=0.5, max=1.0, step=0.05, value=0.7, description='Root Taper'),\n    'root_angle_deg': widgets.FloatSlider(min=-80, max=80, step=5, value=45, description='Root Angle'),\n    'root_length_reduction': widgets.FloatSlider(min=0.5, max=1.0, step=0.05, value=0.8, description='Root Length Red.'),\n    'root_branches_per_level': widgets.IntSlider(min=0, max=8, step=1, value=2, description='Root Branches')\n}\n\ninteract(\n    plot_tree,\n    **crown_controls,\n    **root_controls\n)\n</pre> import numpy as np import plotly.graph_objects as go from ipywidgets import interact, widgets  def cylinder_mesh(p0, p1, radius_base, radius_top, sections=8):     \"\"\"     Generate mesh data for a tapered cylinder (frustum) between two points.     \"\"\"     # Vector from p0 to p1     v = np.array(p1) - np.array(p0)     # Length of the cylinder     length = np.linalg.norm(v)     if length == 0:         return None     # Unit vector in direction of the cylinder     v = v / length      # Create arbitrary vectors orthogonal to v     not_v = np.array([1, 0, 0])     if np.allclose(v, not_v):         not_v = np.array([0, 1, 0])     n1 = np.cross(v, not_v)     n1 /= np.linalg.norm(n1)     n2 = np.cross(v, n1)      # Create circle points in the plane orthogonal to v     t = np.linspace(0, 2 * np.pi, sections, endpoint=False)     circle_base = n1[:, None] * np.cos(t)[None, :] + n2[:, None] * np.sin(t)[None, :]     circle_top = circle_base.copy()      # Scale circles by radii     circle_base *= radius_base     circle_top *= radius_top      # Points at base and top     base_points = p0[:, None] + circle_base     top_points = p1[:, None] + circle_top      # Combine points     x = np.hstack([base_points[0], top_points[0]])     y = np.hstack([base_points[1], top_points[1]])     z = np.hstack([base_points[2], top_points[2]])      # Create faces     faces = []     n = sections     for i in range(n):         next_i = (i + 1) % n         faces.append([i, next_i, n + next_i])         faces.append([i, n + next_i, n + i])     return x, y, z, faces  def rotate_vector(v, k, theta):     \"\"\"     Rotate vector v around axis k by angle theta using Rodrigues' rotation formula.     \"\"\"     v_rot = v * np.cos(theta) + np.cross(k, v) * np.sin(theta) + k * np.dot(k, v) * (1 - np.cos(theta))     return v_rot  def grow_tree(p0, direction, length, radius_base, taper_ratio, levels, angle, length_reduction,               branches_per_level, tree_elements, is_root=False):     \"\"\"     Recursively grow the tree from point p0 in a given direction.     \"\"\"     if levels == 0 or radius_base &lt; 0.01 or length &lt; 0.01:         return      # Calculate end point of the current branch     p1 = p0 + direction * length      # Ensure roots do not grow above ground level     if is_root and p1[2] &gt; 0:         p1[2] = 0      # Calculate top radius using consistent tapering     radius_top = radius_base * taper_ratio      # Add the cylinder representing the trunk or branch     cylinder = cylinder_mesh(p0, p1, radius_base, radius_top)     if cylinder:         x, y, z, faces = cylinder         tree_elements.append({             'x': x,             'y': y,             'z': z,             'faces': faces,             'color': 'saddlebrown' if not is_root else 'sienna'         })      # Calculate base radius of child branches     N = branches_per_level     if N &gt; 0:         radius_base_child = radius_top / np.sqrt(N)     else:         radius_base_child = 0      # Length of child branches     length_child = length * length_reduction      # Generate branches at this level     for _ in range(N):         # Random rotation for natural appearance         if is_root:             # For roots, theta ranges from \u03c0/2 to \u03c0 (90\u00b0 to 180\u00b0), pointing downward             min_theta = np.pi / 2             max_theta = np.pi / 2 + angle             theta = min_theta + np.random.rand() * (max_theta - min_theta)         else:             # For crown, theta ranges from 0 to angle (pointing upward)             min_theta = 0             max_theta = angle             theta = min_theta + np.random.rand() * (max_theta - min_theta)          # Add small random variation         theta += (np.random.rand() - 0.5) * np.deg2rad(10)         phi = np.random.rand() * 2 * np.pi          # Ensure theta is within valid range         if is_root:             theta = np.clip(theta, np.pi / 2, np.pi)         else:             theta = np.clip(theta, 0, np.pi / 2)          # Spherical to Cartesian coordinates         new_direction = np.array([             np.sin(theta) * np.cos(phi),             np.sin(theta) * np.sin(phi),             np.cos(theta)         ])          # Rotate new_direction to align with the parent branch direction         rotation_axis = np.cross([0, 0, 1], direction)         rotation_angle = np.arccos(np.clip(np.dot(direction, [0, 0, 1]), -1.0, 1.0))         if np.linalg.norm(rotation_axis) &gt; 1e-6:             rotation_axis /= np.linalg.norm(rotation_axis)             new_direction = rotate_vector(new_direction, rotation_axis, rotation_angle)          # Recursive call to grow the branch         grow_tree(             p1,             new_direction,             length_child,             radius_base_child,             taper_ratio,             levels - 1,             angle,             length_reduction,             branches_per_level,             tree_elements,             is_root=is_root         )  def plot_tree(     # Crown parameters     crown_levels, crown_length, crown_radius, crown_taper_ratio, crown_angle_deg, crown_length_reduction, crown_branches_per_level,     # Root parameters     root_levels, root_length, root_radius, root_taper_ratio, root_angle_deg, root_length_reduction, root_branches_per_level ):     tree_elements = []     # Start with the main trunk (above ground)     p0 = np.array([0, 0, 0])     direction = np.array([0, 0, 1])  # Grow upwards     crown_angle_rad = np.deg2rad(crown_angle_deg)     grow_tree(         p0,         direction,         crown_length,         crown_radius,         crown_taper_ratio,         crown_levels,         crown_angle_rad,         crown_length_reduction,         crown_branches_per_level,         tree_elements,         is_root=False     )      # Now grow the roots (below ground)     direction_root = np.array([0, 0, -1])  # Grow downwards     root_angle_rad = np.deg2rad(root_angle_deg)     grow_tree(         p0,         direction_root,         root_length,         root_radius,         root_taper_ratio,         root_levels,         root_angle_rad,         root_length_reduction,         root_branches_per_level,         tree_elements,         is_root=True     )      # Plotting     fig = go.Figure()     for elem in tree_elements:         fig.add_trace(go.Mesh3d(             x=elem['x'],             y=elem['y'],             z=elem['z'],             i=[face[0] for face in elem['faces']],             j=[face[1] for face in elem['faces']],             k=[face[2] for face in elem['faces']],             color=elem['color'],             flatshading=True,             lighting=dict(ambient=0.5, diffuse=0.8, roughness=0.9),             showscale=False         ))     fig.update_layout(         scene=dict(             xaxis=dict(visible=False),             yaxis=dict(visible=False),             zaxis=dict(visible=False),             aspectmode='data'         ),         showlegend=False,         margin=dict(l=0, r=0, t=0, b=0)     )     fig.show()  # Interactive widgets crown_controls = {     'crown_levels': widgets.IntSlider(min=1, max=8, step=1, value=5, description='Crown Levels'),     'crown_length': widgets.FloatSlider(min=1, max=15, step=0.5, value=7, description='Crown Length'),     'crown_radius': widgets.FloatSlider(min=0.1, max=1.5, step=0.1, value=0.5, description='Crown Radius'),     'crown_taper_ratio': widgets.FloatSlider(min=0.5, max=1.0, step=0.05, value=0.7, description='Crown Taper'),     'crown_angle_deg': widgets.FloatSlider(min=10, max=80, step=5, value=30, description='Crown Angle'),     'crown_length_reduction': widgets.FloatSlider(min=0.5, max=1.0, step=0.05, value=0.7, description='Crown Length Red.'),     'crown_branches_per_level': widgets.IntSlider(min=0, max=8, step=1, value=3, description='Crown Branches') }  root_controls = {     'root_levels': widgets.IntSlider(min=1, max=8, step=1, value=4, description='Root Levels'),     'root_length': widgets.FloatSlider(min=1, max=15, step=0.5, value=5, description='Root Length'),     'root_radius': widgets.FloatSlider(min=0.1, max=1.5, step=0.1, value=0.4, description='Root Radius'),     'root_taper_ratio': widgets.FloatSlider(min=0.5, max=1.0, step=0.05, value=0.7, description='Root Taper'),     'root_angle_deg': widgets.FloatSlider(min=-80, max=80, step=5, value=45, description='Root Angle'),     'root_length_reduction': widgets.FloatSlider(min=0.5, max=1.0, step=0.05, value=0.8, description='Root Length Red.'),     'root_branches_per_level': widgets.IntSlider(min=0, max=8, step=1, value=2, description='Root Branches') }  interact(     plot_tree,     **crown_controls,     **root_controls )  <pre>interactive(children=(IntSlider(value=5, description='Crown Levels', max=8, min=1), FloatSlider(value=7.0, des\u2026</pre> Out[5]: <pre>&lt;function __main__.plot_tree(crown_levels, crown_length, crown_radius, crown_taper_ratio, crown_angle_deg, crown_length_reduction, crown_branches_per_level, root_levels, root_length, root_radius, root_taper_ratio, root_angle_deg, root_length_reduction, root_branches_per_level)&gt;</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"notebooks/fractal_generators/#setup","title":"Setup\u00b6","text":"<p>Install missing packages</p> <pre>mamba install -c conda-forge -y ipykernel ipywidgets matplotlib numba numpy plotly pythreejs streamlit\n</pre> <p>or create new conda environment</p> <pre>mamba env create -f streamlit-plotly.yaml\n</pre> <p>Activate the newly created environment:</p> <pre>mamba activate streamlit-plotly\n</pre> <pre>python -m ipykernel install --user --name=streamlit-plotly --display-name \"Python (Streamlit-Plotly)\"\n</pre>"},{"location":"notebooks/fractals/","title":"Self-similar Fractals","text":"<p>To get started with generating fractals and displaying them using Three.js in a browser, we can break down the task into two main parts:</p> <ol> <li>Generating Fractals in Python: We'll use scientific Python libraries such as NumPy and Matplotlib to create fractal patterns.</li> <li>Displaying Fractals with Three.js: We'll convert the generated data into a format that Three.js can use to render the fractals in a browser.</li> </ol> <p>Let's start with the Python part. We'll write code to generate examples of self-similar and self-affine fractals in 1D, 2D, and 3D.</p> In\u00a0[1]: Copied! <pre>import matplotlib.pyplot as plt\n\ndef cantor_set(ax, x, y, length, depth):\n    if depth == 0:\n        ax.plot([x, x + length], [y, y], color='black', lw=2)\n    else:\n        length /= 3\n        cantor_set(ax, x, y, length, depth-1)\n        cantor_set(ax, x + 2 * length, y, length, depth-1)\n\nfig, ax = plt.subplots(figsize=(10, 2))\nax.set_title('Cantor Set')\nax.set_axis_off()\ncantor_set(ax, 0, 0, 27, 5)\nplt.show()\n</pre> import matplotlib.pyplot as plt  def cantor_set(ax, x, y, length, depth):     if depth == 0:         ax.plot([x, x + length], [y, y], color='black', lw=2)     else:         length /= 3         cantor_set(ax, x, y, length, depth-1)         cantor_set(ax, x + 2 * length, y, length, depth-1)  fig, ax = plt.subplots(figsize=(10, 2)) ax.set_title('Cantor Set') ax.set_axis_off() cantor_set(ax, 0, 0, 27, 5) plt.show() In\u00a0[2]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\n\ndef sierpinski_triangle(ax, vertices, depth):\n    if depth == 0:\n        triangle = plt.Polygon(vertices, edgecolor='black')\n        ax.add_patch(triangle)\n    else:\n        midpoints = [(vertices[i] + vertices[(i + 1) % 3]) / 2 for i in range(3)]\n        sierpinski_triangle(ax, [vertices[0], midpoints[0], midpoints[2]], depth-1)\n        sierpinski_triangle(ax, [vertices[1], midpoints[1], midpoints[0]], depth-1)\n        sierpinski_triangle(ax, [vertices[2], midpoints[2], midpoints[1]], depth-1)\n\nfig, ax = plt.subplots()\nax.set_title('Sierpinski Triangle')\nax.set_axis_off()\nvertices = np.array([[0, 0], [1, 0], [0.5, np.sqrt(3) / 2]])\nsierpinski_triangle(ax, vertices, 5)\nplt.show()\n</pre> import matplotlib.pyplot as plt import numpy as np  def sierpinski_triangle(ax, vertices, depth):     if depth == 0:         triangle = plt.Polygon(vertices, edgecolor='black')         ax.add_patch(triangle)     else:         midpoints = [(vertices[i] + vertices[(i + 1) % 3]) / 2 for i in range(3)]         sierpinski_triangle(ax, [vertices[0], midpoints[0], midpoints[2]], depth-1)         sierpinski_triangle(ax, [vertices[1], midpoints[1], midpoints[0]], depth-1)         sierpinski_triangle(ax, [vertices[2], midpoints[2], midpoints[1]], depth-1)  fig, ax = plt.subplots() ax.set_title('Sierpinski Triangle') ax.set_axis_off() vertices = np.array([[0, 0], [1, 0], [0.5, np.sqrt(3) / 2]]) sierpinski_triangle(ax, vertices, 5) plt.show()  In\u00a0[3]: Copied! <pre>import numpy as np\nfrom mpl_toolkits.mplot3d.art3d import Poly3DCollection\nimport matplotlib.pyplot as plt\n\ndef menger_sponge(ax, x, y, z, size, depth):\n    if depth == 0:\n        r = [[x, y, z], [x + size, y, z], [x + size, y + size, z], [x, y + size, z]]\n        ax.add_collection3d(Poly3DCollection([r], facecolors='blue', linewidths=1, edgecolors='black'))\n    else:\n        size /= 3\n        for dx in [0, 1, 2]:\n            for dy in [0, 1, 2]:\n                for dz in [0, 1, 2]:\n                    if (dx == 1 and dy == 1) or (dx == 1 and dz == 1) or (dy == 1 and dz == 1):\n                        continue\n                    menger_sponge(ax, x + dx * size, y + dy * size, z + dz * size, size, depth - 1)\n\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\nax.set_title('Menger Sponge')\nmenger_sponge(ax, 0, 0, 0, 27, 3)\nplt.show()\n</pre> import numpy as np from mpl_toolkits.mplot3d.art3d import Poly3DCollection import matplotlib.pyplot as plt  def menger_sponge(ax, x, y, z, size, depth):     if depth == 0:         r = [[x, y, z], [x + size, y, z], [x + size, y + size, z], [x, y + size, z]]         ax.add_collection3d(Poly3DCollection([r], facecolors='blue', linewidths=1, edgecolors='black'))     else:         size /= 3         for dx in [0, 1, 2]:             for dy in [0, 1, 2]:                 for dz in [0, 1, 2]:                     if (dx == 1 and dy == 1) or (dx == 1 and dz == 1) or (dy == 1 and dz == 1):                         continue                     menger_sponge(ax, x + dx * size, y + dy * size, z + dz * size, size, depth - 1)  fig = plt.figure() ax = fig.add_subplot(111, projection='3d') ax.set_title('Menger Sponge') menger_sponge(ax, 0, 0, 0, 27, 3) plt.show()  In\u00a0[4]: Copied! <pre>import json\n\ndef generate_menger_sponge_data(x, y, z, size, depth):\n    vertices = []\n    faces = []\n    # Define a function to recursively add vertices and faces\n    # ...\n    # Return vertices and faces as lists\n    return vertices, faces\n\nvertices, faces = generate_menger_sponge_data(0, 0, 0, 27, 3)\n\nwith open('menger_sponge.json', 'w') as f:\n    json.dump({'vertices': vertices, 'faces': faces}, f)\n</pre> import json  def generate_menger_sponge_data(x, y, z, size, depth):     vertices = []     faces = []     # Define a function to recursively add vertices and faces     # ...     # Return vertices and faces as lists     return vertices, faces  vertices, faces = generate_menger_sponge_data(0, 0, 0, 27, 3)  with open('menger_sponge.json', 'w') as f:     json.dump({'vertices': vertices, 'faces': faces}, f) In\u00a0[5]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\n\ndef fractional_brownian_motion(H, length, n):\n    dt = length / n\n    t = np.linspace(0, length, n)\n    dB = np.random.normal(0, np.sqrt(dt), n)\n    B = np.cumsum(dB)\n    fBm = t ** H * B\n    return t, fBm\n\nH = 0.7  # Hurst exponent\nlength = 1.0\nn = 1000\nt, fBm = fractional_brownian_motion(H, length, n)\n\nplt.figure(figsize=(10, 4))\nplt.plot(t, fBm, label=f'H={H}')\nplt.title('Fractional Brownian Motion')\nplt.xlabel('Time')\nplt.ylabel('fBm')\nplt.legend()\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt  def fractional_brownian_motion(H, length, n):     dt = length / n     t = np.linspace(0, length, n)     dB = np.random.normal(0, np.sqrt(dt), n)     B = np.cumsum(dB)     fBm = t ** H * B     return t, fBm  H = 0.7  # Hurst exponent length = 1.0 n = 1000 t, fBm = fractional_brownian_motion(H, length, n)  plt.figure(figsize=(10, 4)) plt.plot(t, fBm, label=f'H={H}') plt.title('Fractional Brownian Motion') plt.xlabel('Time') plt.ylabel('fBm') plt.legend() plt.show() In\u00a0[6]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\n\ndef generate_perlin_noise_2d(shape, res):\n    def f(t):\n        return 6 * t**5 - 15 * t**4 + 10 * t**3\n\n    delta = (res[0] / shape[0], res[1] / shape[1])\n    d = (shape[0] // res[0], shape[1] // res[1])\n    grid = np.mgrid[0:res[0]:d[0]*1j, 0:res[1]:d[1]*1j]\n    grid = grid.transpose(1, 2, 0) % 1\n    angles = 2 * np.pi * np.random.rand(res[0] + 1, res[1] + 1)\n    gradients = np.dstack((np.cos(angles), np.sin(angles)))\n\n    g00 = gradients[:-1, :-1]\n    g10 = gradients[1:, :-1]\n    g01 = gradients[:-1, 1:]\n    g11 = gradients[1:, 1:]\n\n    n00 = np.sum(grid * g00.repeat(d[0], 0).repeat(d[1], 1), axis=2)\n    n10 = np.sum(np.dstack((grid[:, :, 0] - 1, grid[:, :, 1])) * g10.repeat(d[0], 0).repeat(d[1], 1), axis=2)\n    n01 = np.sum(np.dstack((grid[:, :, 0], grid[:, :, 1] - 1)) * g01.repeat(d[0], 0).repeat(d[1], 1), axis=2)\n    n11 = np.sum((grid - 1) * g11.repeat(d[0], 0).repeat(d[1], 1), axis=2)\n\n    t = f(grid)\n    n0 = n00 * (1 - t[:, :, 0]) + t[:, :, 0] * n10\n    n1 = n01 * (1 - t[:, :, 0]) + t[:, :, 0] * n11\n    return np.sqrt(2) * ((1 - t[:, :, 1]) * n0 + t[:, :, 1] * n1)\n\nshape = (512, 512)\nres = (8, 8)\nnoise = generate_perlin_noise_2d(shape, res)\n\nplt.figure(figsize=(10, 10))\nplt.imshow(noise, cmap='gray')\nplt.title('2D Perlin Noise')\nplt.axis('off')\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt  def generate_perlin_noise_2d(shape, res):     def f(t):         return 6 * t**5 - 15 * t**4 + 10 * t**3      delta = (res[0] / shape[0], res[1] / shape[1])     d = (shape[0] // res[0], shape[1] // res[1])     grid = np.mgrid[0:res[0]:d[0]*1j, 0:res[1]:d[1]*1j]     grid = grid.transpose(1, 2, 0) % 1     angles = 2 * np.pi * np.random.rand(res[0] + 1, res[1] + 1)     gradients = np.dstack((np.cos(angles), np.sin(angles)))      g00 = gradients[:-1, :-1]     g10 = gradients[1:, :-1]     g01 = gradients[:-1, 1:]     g11 = gradients[1:, 1:]      n00 = np.sum(grid * g00.repeat(d[0], 0).repeat(d[1], 1), axis=2)     n10 = np.sum(np.dstack((grid[:, :, 0] - 1, grid[:, :, 1])) * g10.repeat(d[0], 0).repeat(d[1], 1), axis=2)     n01 = np.sum(np.dstack((grid[:, :, 0], grid[:, :, 1] - 1)) * g01.repeat(d[0], 0).repeat(d[1], 1), axis=2)     n11 = np.sum((grid - 1) * g11.repeat(d[0], 0).repeat(d[1], 1), axis=2)      t = f(grid)     n0 = n00 * (1 - t[:, :, 0]) + t[:, :, 0] * n10     n1 = n01 * (1 - t[:, :, 0]) + t[:, :, 0] * n11     return np.sqrt(2) * ((1 - t[:, :, 1]) * n0 + t[:, :, 1] * n1)  shape = (512, 512) res = (8, 8) noise = generate_perlin_noise_2d(shape, res)  plt.figure(figsize=(10, 10)) plt.imshow(noise, cmap='gray') plt.title('2D Perlin Noise') plt.axis('off') plt.show() <pre>\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\nCell In[6], line 32\n     30 shape = (512, 512)\n     31 res = (8, 8)\n---&gt; 32 noise = generate_perlin_noise_2d(shape, res)\n     34 plt.figure(figsize=(10, 10))\n     35 plt.imshow(noise, cmap='gray')\n\nCell In[6], line 20, in generate_perlin_noise_2d(shape, res)\n     17 g01 = gradients[:-1, 1:]\n     18 g11 = gradients[1:, 1:]\n---&gt; 20 n00 = np.sum(grid * g00.repeat(d[0], 0).repeat(d[1], 1), axis=2)\n     21 n10 = np.sum(np.dstack((grid[:, :, 0] - 1, grid[:, :, 1])) * g10.repeat(d[0], 0).repeat(d[1], 1), axis=2)\n     22 n01 = np.sum(np.dstack((grid[:, :, 0], grid[:, :, 1] - 1)) * g01.repeat(d[0], 0).repeat(d[1], 1), axis=2)\n\nValueError: operands could not be broadcast together with shapes (64,64,2) (512,512,2) </pre> In\u00a0[\u00a0]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\ndef fractional_brownian_motion_3d(H, length, n):\n    dt = length / n\n    t = np.linspace(0, length, n)\n    dB = np.random.normal(0, np.sqrt(dt), (n, 3))\n    B = np.cumsum(dB, axis=0)\n    fBm = t[:, None] ** H * B\n    return t, fBm\n\nH = 0.7  # Hurst exponent\nlength = 1.0\nn = 1000\nt, fBm = fractional_brownian_motion_3d(H, length, n)\n\nfig = plt.figure(figsize=(10, 10))\nax = fig.add_subplot(111, projection='3d')\nax.plot(fBm[:, 0], fBm[:, 1], fBm[:, 2], label=f'H={H}')\nax.set_title('3D Fractional Brownian Motion')\nax.set_xlabel('X')\nax.set_ylabel('Y')\nax.set_zlabel('Z')\nplt.legend()\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt from mpl_toolkits.mplot3d import Axes3D  def fractional_brownian_motion_3d(H, length, n):     dt = length / n     t = np.linspace(0, length, n)     dB = np.random.normal(0, np.sqrt(dt), (n, 3))     B = np.cumsum(dB, axis=0)     fBm = t[:, None] ** H * B     return t, fBm  H = 0.7  # Hurst exponent length = 1.0 n = 1000 t, fBm = fractional_brownian_motion_3d(H, length, n)  fig = plt.figure(figsize=(10, 10)) ax = fig.add_subplot(111, projection='3d') ax.plot(fBm[:, 0], fBm[:, 1], fBm[:, 2], label=f'H={H}') ax.set_title('3D Fractional Brownian Motion') ax.set_xlabel('X') ax.set_ylabel('Y') ax.set_zlabel('Z') plt.legend() plt.show() <p>These examples provide a starting point for generating self-affine fractals in 1D, 2D, and 3D. You can expand and modify these examples based on your specific requirements and the details from the manuscript.</p> <p>Python code to create self-affine branching patterns resembling a fern and a tree using Matplotlib. These patterns are generated using Iterated Function Systems (IFS).</p> In\u00a0[7]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\n\ndef fern(n):\n    x, y = [0], [0]\n    for _ in range(n):\n        r = np.random.random()\n        if r &lt; 0.01:\n            x.append(0)\n            y.append(0.16 * y[-1])\n        elif r &lt; 0.86:\n            x.append(0.85 * x[-1] + 0.04 * y[-1])\n            y.append(-0.04 * x[-1] + 0.85 * y[-1] + 1.6)\n        elif r &lt; 0.93:\n            x.append(0.2 * x[-1] - 0.26 * y[-1])\n            y.append(0.23 * x[-1] + 0.22 * y[-1] + 1.6)\n        else:\n            x.append(-0.15 * x[-1] + 0.28 * y[-1])\n            y.append(0.26 * x[-1] + 0.24 * y[-1] + 0.44)\n    return x, y\n\nx, y = fern(100000)\n\nplt.figure(figsize=(10, 10))\nplt.scatter(x, y, s=0.1, color='green')\nplt.title('Self-Affine Fern Pattern')\nplt.axis('off')\nplt.show()\n</pre> import matplotlib.pyplot as plt import numpy as np  def fern(n):     x, y = [0], [0]     for _ in range(n):         r = np.random.random()         if r &lt; 0.01:             x.append(0)             y.append(0.16 * y[-1])         elif r &lt; 0.86:             x.append(0.85 * x[-1] + 0.04 * y[-1])             y.append(-0.04 * x[-1] + 0.85 * y[-1] + 1.6)         elif r &lt; 0.93:             x.append(0.2 * x[-1] - 0.26 * y[-1])             y.append(0.23 * x[-1] + 0.22 * y[-1] + 1.6)         else:             x.append(-0.15 * x[-1] + 0.28 * y[-1])             y.append(0.26 * x[-1] + 0.24 * y[-1] + 0.44)     return x, y  x, y = fern(100000)  plt.figure(figsize=(10, 10)) plt.scatter(x, y, s=0.1, color='green') plt.title('Self-Affine Fern Pattern') plt.axis('off') plt.show()  Tree Pattern In\u00a0[8]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\n\ndef tree(n):\n    x, y = [0], [0]\n    for _ in range(n):\n        r = np.random.random()\n        if r &lt; 0.05:\n            x.append(0)\n            y.append(0.5 * y[-1])\n        elif r &lt; 0.45:\n            x.append(0.42 * x[-1] - 0.42 * y[-1])\n            y.append(0.42 * x[-1] + 0.42 * y[-1] + 0.4)\n        else:\n            x.append(0.42 * x[-1] + 0.42 * y[-1])\n            y.append(-0.42 * x[-1] + 0.42 * y[-1] + 0.4)\n    return x, y\n\nx, y = tree(100000)\n\nplt.figure(figsize=(10, 10))\nplt.scatter(x, y, s=0.1, color='brown')\nplt.title('Self-Affine Tree Pattern')\nplt.axis('off')\nplt.show()\n</pre> import matplotlib.pyplot as plt import numpy as np  def tree(n):     x, y = [0], [0]     for _ in range(n):         r = np.random.random()         if r &lt; 0.05:             x.append(0)             y.append(0.5 * y[-1])         elif r &lt; 0.45:             x.append(0.42 * x[-1] - 0.42 * y[-1])             y.append(0.42 * x[-1] + 0.42 * y[-1] + 0.4)         else:             x.append(0.42 * x[-1] + 0.42 * y[-1])             y.append(-0.42 * x[-1] + 0.42 * y[-1] + 0.4)     return x, y  x, y = tree(100000)  plt.figure(figsize=(10, 10)) plt.scatter(x, y, s=0.1, color='brown') plt.title('Self-Affine Tree Pattern') plt.axis('off') plt.show()  In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[9]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\n\ndef draw_branch(x, y, angle, length, thickness, ax):\n    if length &gt; 0.1:\n        x_new = x + length * np.cos(angle)\n        y_new = y + length * np.sin(angle)\n        \n        ax.plot([x, x_new], [y, y_new], color='brown', lw=thickness)\n        \n        new_length = length * 0.7\n        new_thickness = thickness * 0.7\n        \n        draw_branch(x_new, y_new, angle + np.pi / 6, new_length, new_thickness, ax)\n        draw_branch(x_new, y_new, angle - np.pi / 6, new_length, new_thickness, ax)\n\nfig, ax = plt.subplots(figsize=(10, 10))\nax.set_axis_off()\n\ndraw_branch(0, 0, np.pi / 2, 10, 2, ax)\n\nplt.title('2D Fractal Tree with Varying Thickness')\nplt.show()\n</pre> import matplotlib.pyplot as plt import numpy as np  def draw_branch(x, y, angle, length, thickness, ax):     if length &gt; 0.1:         x_new = x + length * np.cos(angle)         y_new = y + length * np.sin(angle)                  ax.plot([x, x_new], [y, y_new], color='brown', lw=thickness)                  new_length = length * 0.7         new_thickness = thickness * 0.7                  draw_branch(x_new, y_new, angle + np.pi / 6, new_length, new_thickness, ax)         draw_branch(x_new, y_new, angle - np.pi / 6, new_length, new_thickness, ax)  fig, ax = plt.subplots(figsize=(10, 10)) ax.set_axis_off()  draw_branch(0, 0, np.pi / 2, 10, 2, ax)  plt.title('2D Fractal Tree with Varying Thickness') plt.show()  In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\n\ndef draw_branch(x, y, angle, length, thickness, splits, ax):\n    if length &gt; 0.1:\n        x_new = x + length * np.cos(angle)\n        y_new = y + length * np.sin(angle)\n        \n        ax.plot([x, x_new], [y, y_new], color='brown', lw=thickness)\n        \n        # Adjust new_length and new_thickness factors to vary branch length and thickness\n        new_length = length * 0.7\n        new_thickness = thickness * 0.7\n        \n        for i in range(splits):\n            # Vary the angle of splits, for example between -np.pi/6 and np.pi/6\n            new_angle = angle + np.pi * (i / (splits - 1) - 0.5) / 3\n            draw_branch(x_new, y_new, new_angle, new_length, new_thickness, splits, ax)\n\nfig, ax = plt.subplots(figsize=(10, 10))\nax.set_axis_off()\n\n# Initial parameters: origin, initial angle, initial length, initial thickness, number of splits\ndraw_branch(0, 0, np.pi / 2, 10, 2, 4, ax)\n\nplt.title('2D Fractal Tree with Varying Branches')\nplt.show()\n</pre> import matplotlib.pyplot as plt import numpy as np  def draw_branch(x, y, angle, length, thickness, splits, ax):     if length &gt; 0.1:         x_new = x + length * np.cos(angle)         y_new = y + length * np.sin(angle)                  ax.plot([x, x_new], [y, y_new], color='brown', lw=thickness)                  # Adjust new_length and new_thickness factors to vary branch length and thickness         new_length = length * 0.7         new_thickness = thickness * 0.7                  for i in range(splits):             # Vary the angle of splits, for example between -np.pi/6 and np.pi/6             new_angle = angle + np.pi * (i / (splits - 1) - 0.5) / 3             draw_branch(x_new, y_new, new_angle, new_length, new_thickness, splits, ax)  fig, ax = plt.subplots(figsize=(10, 10)) ax.set_axis_off()  # Initial parameters: origin, initial angle, initial length, initial thickness, number of splits draw_branch(0, 0, np.pi / 2, 10, 2, 4, ax)  plt.title('2D Fractal Tree with Varying Branches') plt.show()  <p>To leverage CUDA and parallel GPU threads for faster calculations in generating the fractal tree, we'll use the numba library, which supports CUDA for Python. Here's the updated code using numba for parallel computations:</p> <p>Prerequisites Ensure you have numba and numpy installed:</p> In\u00a0[8]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom numba import cuda, float32, int32\n\n@cuda.jit\ndef draw_branch(x, y, angle, length, thickness, splits, d_x, d_y, d_thickness):\n    idx = cuda.grid(1)\n    if idx &lt; x.size:\n        x_new = x[idx] + length * np.cos(angle[idx])\n        y_new = y[idx] + length * np.sin(angle[idx])\n        \n        new_length = length * 0.7\n        new_thickness = thickness[idx] * 0.7\n        \n        for i in range(splits):\n            new_angle = angle[idx] + np.pi * (i / (splits - 1) - 0.5) / 3\n            d_x[idx, i] = x_new\n            d_y[idx, i] = y_new\n            d_thickness[idx, i] = new_thickness\n\ndef generate_tree(num_branches, splits):\n    x = np.zeros(num_branches, dtype=np.float32)\n    y = np.zeros(num_branches, dtype=np.float32)\n    angle = np.ones(num_branches, dtype=np.float32) * (np.pi / 2)\n    thickness = np.ones(num_branches, dtype=np.float32) * 2\n\n    d_x = np.zeros((num_branches, splits), dtype=np.float32)\n    d_y = np.zeros((num_branches, splits), dtype=np.float32)\n    d_thickness = np.zeros((num_branches, splits), dtype=np.float32)\n    \n    threads_per_block = 128\n    blocks_per_grid = (num_branches + (threads_per_block - 1)) // threads_per_block\n    \n    draw_branch[blocks_per_grid, threads_per_block](x, y, angle, 10.0, thickness, splits, d_x, d_y, d_thickness)\n    \n    return d_x.flatten(), d_y.flatten(), d_thickness.flatten()\n\nnum_branches = 1024\nsplits = 4\nx, y, thickness = generate_tree(num_branches, splits)\n\nplt.figure(figsize=(10, 10))\nfor i in range(1, len(x)):\n    plt.plot([x[i-1], x[i]], [y[i-1], y[i]], color='brown', lw=thickness[i])\nplt.title('2D Fractal Tree with Varying Thickness (CUDA Accelerated)')\nplt.axis('off')\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt from numba import cuda, float32, int32  @cuda.jit def draw_branch(x, y, angle, length, thickness, splits, d_x, d_y, d_thickness):     idx = cuda.grid(1)     if idx &lt; x.size:         x_new = x[idx] + length * np.cos(angle[idx])         y_new = y[idx] + length * np.sin(angle[idx])                  new_length = length * 0.7         new_thickness = thickness[idx] * 0.7                  for i in range(splits):             new_angle = angle[idx] + np.pi * (i / (splits - 1) - 0.5) / 3             d_x[idx, i] = x_new             d_y[idx, i] = y_new             d_thickness[idx, i] = new_thickness  def generate_tree(num_branches, splits):     x = np.zeros(num_branches, dtype=np.float32)     y = np.zeros(num_branches, dtype=np.float32)     angle = np.ones(num_branches, dtype=np.float32) * (np.pi / 2)     thickness = np.ones(num_branches, dtype=np.float32) * 2      d_x = np.zeros((num_branches, splits), dtype=np.float32)     d_y = np.zeros((num_branches, splits), dtype=np.float32)     d_thickness = np.zeros((num_branches, splits), dtype=np.float32)          threads_per_block = 128     blocks_per_grid = (num_branches + (threads_per_block - 1)) // threads_per_block          draw_branch[blocks_per_grid, threads_per_block](x, y, angle, 10.0, thickness, splits, d_x, d_y, d_thickness)          return d_x.flatten(), d_y.flatten(), d_thickness.flatten()  num_branches = 1024 splits = 4 x, y, thickness = generate_tree(num_branches, splits)  plt.figure(figsize=(10, 10)) for i in range(1, len(x)):     plt.plot([x[i-1], x[i]], [y[i-1], y[i]], color='brown', lw=thickness[i]) plt.title('2D Fractal Tree with Varying Thickness (CUDA Accelerated)') plt.axis('off') plt.show()  <pre>/opt/conda/lib/python3.10/site-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 8 will likely result in GPU under-utilization due to low occupancy.\n  warn(NumbaPerformanceWarning(msg))\n</pre> <pre>\n---------------------------------------------------------------------------\nCudaSupportError                          Traceback (most recent call last)\nCell In[8], line 40\n     38 num_branches = 1024\n     39 splits = 4\n---&gt; 40 x, y, thickness = generate_tree(num_branches, splits)\n     42 plt.figure(figsize=(10, 10))\n     43 for i in range(1, len(x)):\n\nCell In[8], line 34, in generate_tree(num_branches, splits)\n     31 threads_per_block = 128\n     32 blocks_per_grid = (num_branches + (threads_per_block - 1)) // threads_per_block\n---&gt; 34 draw_branch[blocks_per_grid, threads_per_block](x, y, angle, 10.0, thickness, splits, d_x, d_y, d_thickness)\n     36 return d_x.flatten(), d_y.flatten(), d_thickness.flatten()\n\nFile /opt/conda/lib/python3.10/site-packages/numba/cuda/dispatcher.py:539, in _LaunchConfiguration.__call__(self, *args)\n    538 def __call__(self, *args):\n--&gt; 539     return self.dispatcher.call(args, self.griddim, self.blockdim,\n    540                                 self.stream, self.sharedmem)\n\nFile /opt/conda/lib/python3.10/site-packages/numba/cuda/dispatcher.py:681, in CUDADispatcher.call(self, args, griddim, blockdim, stream, sharedmem)\n    679     kernel = next(iter(self.overloads.values()))\n    680 else:\n--&gt; 681     kernel = _dispatcher.Dispatcher._cuda_call(self, *args)\n    683 kernel.launch(args, griddim, blockdim, stream, sharedmem)\n\nFile /opt/conda/lib/python3.10/site-packages/numba/cuda/dispatcher.py:689, in CUDADispatcher._compile_for_args(self, *args, **kws)\n    687 assert not kws\n    688 argtypes = [self.typeof_pyval(a) for a in args]\n--&gt; 689 return self.compile(tuple(argtypes))\n\nFile /opt/conda/lib/python3.10/site-packages/numba/cuda/dispatcher.py:932, in CUDADispatcher.compile(self, sig)\n    929 if not self._can_compile:\n    930     raise RuntimeError(\"Compilation disabled\")\n--&gt; 932 kernel = _Kernel(self.py_func, argtypes, **self.targetoptions)\n    933 # We call bind to force codegen, so that there is a cubin to cache\n    934 kernel.bind()\n\nFile /opt/conda/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.&lt;locals&gt;._acquire_compile_lock(*args, **kwargs)\n     32 @functools.wraps(func)\n     33 def _acquire_compile_lock(*args, **kwargs):\n     34     with self:\n---&gt; 35         return func(*args, **kwargs)\n\nFile /opt/conda/lib/python3.10/site-packages/numba/cuda/dispatcher.py:82, in _Kernel.__init__(self, py_func, argtypes, link, debug, lineinfo, inline, fastmath, extensions, max_registers, opt, device)\n     75 self.extensions = extensions or []\n     77 nvvm_options = {\n     78     'fastmath': fastmath,\n     79     'opt': 3 if opt else 0\n     80 }\n---&gt; 82 cc = get_current_device().compute_capability\n     83 cres = compile_cuda(self.py_func, types.void, self.argtypes,\n     84                     debug=self.debug,\n     85                     lineinfo=lineinfo,\n   (...)\n     88                     nvvm_options=nvvm_options,\n     89                     cc=cc)\n     90 tgt_ctx = cres.target_context\n\nFile /opt/conda/lib/python3.10/site-packages/numba/cuda/api.py:443, in get_current_device()\n    441 def get_current_device():\n    442     \"Get current device associated with the current thread\"\n--&gt; 443     return current_context().device\n\nFile /opt/conda/lib/python3.10/site-packages/numba/cuda/cudadrv/devices.py:220, in get_context(devnum)\n    216 def get_context(devnum=None):\n    217     \"\"\"Get the current device or use a device by device number, and\n    218     return the CUDA context.\n    219     \"\"\"\n--&gt; 220     return _runtime.get_or_create_context(devnum)\n\nFile /opt/conda/lib/python3.10/site-packages/numba/cuda/cudadrv/devices.py:138, in _Runtime.get_or_create_context(self, devnum)\n    136 attached_ctx = self._get_attached_context()\n    137 if attached_ctx is None:\n--&gt; 138     return self._get_or_create_context_uncached(devnum)\n    139 else:\n    140     return attached_ctx\n\nFile /opt/conda/lib/python3.10/site-packages/numba/cuda/cudadrv/devices.py:153, in _Runtime._get_or_create_context_uncached(self, devnum)\n    147 \"\"\"See also ``get_or_create_context(devnum)``.\n    148 This version does not read the cache.\n    149 \"\"\"\n    150 with self._lock:\n    151     # Try to get the active context in the CUDA stack or\n    152     # activate GPU-0 with the primary context\n--&gt; 153     with driver.get_active_context() as ac:\n    154         if not ac:\n    155             return self._activate_context_for(0)\n\nFile /opt/conda/lib/python3.10/site-packages/numba/cuda/cudadrv/driver.py:495, in _ActiveContext.__enter__(self)\n    493 else:\n    494     hctx = drvapi.cu_context(0)\n--&gt; 495     driver.cuCtxGetCurrent(byref(hctx))\n    496     hctx = hctx if hctx.value else None\n    498 if hctx is None:\n\nFile /opt/conda/lib/python3.10/site-packages/numba/cuda/cudadrv/driver.py:295, in Driver.__getattr__(self, fname)\n    292 self.ensure_initialized()\n    294 if self.initialization_error is not None:\n--&gt; 295     raise CudaSupportError(\"Error at driver init: \\n%s:\" %\n    296                            self.initialization_error)\n    298 if USE_NV_BINDING:\n    299     return self._cuda_python_wrap_fn(fname)\n\nCudaSupportError: Error at driver init: \n\nCUDA driver library cannot be found.\nIf you are sure that a CUDA driver is installed,\ntry setting environment variable NUMBA_CUDA_DRIVER\nwith the file path of the CUDA driver shared library.\n:</pre> In\u00a0[9]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom numba import cuda\n\n@cuda.jit\ndef generate_fern(n, x, y):\n    idx = cuda.grid(1)\n    if idx &lt; n:\n        for i in range(10000):  # Adjust the number of iterations if needed\n            r = np.random.random()\n            if r &lt; 0.01:\n                x[idx, i+1] = 0\n                y[idx, i+1] = 0.16 * y[idx, i]\n            elif r &lt; 0.86:\n                x[idx, i+1] = 0.85 * x[idx, i] + 0.04 * y[idx, i]\n                y[idx, i+1] = -0.04 * x[idx, i] + 0.85 * y[idx, i] + 1.6\n            elif r &lt; 0.93:\n                x[idx, i+1] = 0.2 * x[idx, i] - 0.26 * y[idx, i]\n                y[idx, i+1] = 0.23 * x[idx, i] + 0.22 * y[idx, i] + 1.6\n            else:\n                x[idx, i+1] = -0.15 * x[idx, i] + 0.28 * y[idx, i]\n                y[idx, i+1] = 0.26 * x[idx, i] + 0.24 * y[idx, i] + 0.44\n\ndef plot_fern():\n    n = 1024\n    iterations = 10000\n    x = np.zeros((n, iterations + 1), dtype=np.float32)\n    y = np.zeros((n, iterations + 1), dtype=np.float32)\n\n    threads_per_block = 128\n    blocks_per_grid = (n + (threads_per_block - 1)) // threads_per_block\n\n    generate_fern[blocks_per_grid, threads_per_block](n, x, y)\n\n    x_flat = x.flatten()\n    y_flat = y.flatten()\n\n    plt.figure(figsize=(10, 10))\n    plt.scatter(x_flat, y_flat, s=0.1, color='green')\n    plt.title('CUDA Accelerated 2D Fractal Fern Pattern')\n    plt.axis('off')\n    plt.show()\n\nplot_fern()\n</pre> import numpy as np import matplotlib.pyplot as plt from numba import cuda  @cuda.jit def generate_fern(n, x, y):     idx = cuda.grid(1)     if idx &lt; n:         for i in range(10000):  # Adjust the number of iterations if needed             r = np.random.random()             if r &lt; 0.01:                 x[idx, i+1] = 0                 y[idx, i+1] = 0.16 * y[idx, i]             elif r &lt; 0.86:                 x[idx, i+1] = 0.85 * x[idx, i] + 0.04 * y[idx, i]                 y[idx, i+1] = -0.04 * x[idx, i] + 0.85 * y[idx, i] + 1.6             elif r &lt; 0.93:                 x[idx, i+1] = 0.2 * x[idx, i] - 0.26 * y[idx, i]                 y[idx, i+1] = 0.23 * x[idx, i] + 0.22 * y[idx, i] + 1.6             else:                 x[idx, i+1] = -0.15 * x[idx, i] + 0.28 * y[idx, i]                 y[idx, i+1] = 0.26 * x[idx, i] + 0.24 * y[idx, i] + 0.44  def plot_fern():     n = 1024     iterations = 10000     x = np.zeros((n, iterations + 1), dtype=np.float32)     y = np.zeros((n, iterations + 1), dtype=np.float32)      threads_per_block = 128     blocks_per_grid = (n + (threads_per_block - 1)) // threads_per_block      generate_fern[blocks_per_grid, threads_per_block](n, x, y)      x_flat = x.flatten()     y_flat = y.flatten()      plt.figure(figsize=(10, 10))     plt.scatter(x_flat, y_flat, s=0.1, color='green')     plt.title('CUDA Accelerated 2D Fractal Fern Pattern')     plt.axis('off')     plt.show()  plot_fern()  <pre>\n---------------------------------------------------------------------------\nCudaSupportError                          Traceback (most recent call last)\nCell In[9], line 44\n     41     plt.axis('off')\n     42     plt.show()\n---&gt; 44 plot_fern()\n\nCell In[9], line 33, in plot_fern()\n     30 threads_per_block = 128\n     31 blocks_per_grid = (n + (threads_per_block - 1)) // threads_per_block\n---&gt; 33 generate_fern[blocks_per_grid, threads_per_block](n, x, y)\n     35 x_flat = x.flatten()\n     36 y_flat = y.flatten()\n\nFile /opt/conda/lib/python3.10/site-packages/numba/cuda/dispatcher.py:539, in _LaunchConfiguration.__call__(self, *args)\n    538 def __call__(self, *args):\n--&gt; 539     return self.dispatcher.call(args, self.griddim, self.blockdim,\n    540                                 self.stream, self.sharedmem)\n\nFile /opt/conda/lib/python3.10/site-packages/numba/cuda/dispatcher.py:681, in CUDADispatcher.call(self, args, griddim, blockdim, stream, sharedmem)\n    679     kernel = next(iter(self.overloads.values()))\n    680 else:\n--&gt; 681     kernel = _dispatcher.Dispatcher._cuda_call(self, *args)\n    683 kernel.launch(args, griddim, blockdim, stream, sharedmem)\n\nFile /opt/conda/lib/python3.10/site-packages/numba/cuda/dispatcher.py:689, in CUDADispatcher._compile_for_args(self, *args, **kws)\n    687 assert not kws\n    688 argtypes = [self.typeof_pyval(a) for a in args]\n--&gt; 689 return self.compile(tuple(argtypes))\n\nFile /opt/conda/lib/python3.10/site-packages/numba/cuda/dispatcher.py:932, in CUDADispatcher.compile(self, sig)\n    929 if not self._can_compile:\n    930     raise RuntimeError(\"Compilation disabled\")\n--&gt; 932 kernel = _Kernel(self.py_func, argtypes, **self.targetoptions)\n    933 # We call bind to force codegen, so that there is a cubin to cache\n    934 kernel.bind()\n\nFile /opt/conda/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.&lt;locals&gt;._acquire_compile_lock(*args, **kwargs)\n     32 @functools.wraps(func)\n     33 def _acquire_compile_lock(*args, **kwargs):\n     34     with self:\n---&gt; 35         return func(*args, **kwargs)\n\nFile /opt/conda/lib/python3.10/site-packages/numba/cuda/dispatcher.py:82, in _Kernel.__init__(self, py_func, argtypes, link, debug, lineinfo, inline, fastmath, extensions, max_registers, opt, device)\n     75 self.extensions = extensions or []\n     77 nvvm_options = {\n     78     'fastmath': fastmath,\n     79     'opt': 3 if opt else 0\n     80 }\n---&gt; 82 cc = get_current_device().compute_capability\n     83 cres = compile_cuda(self.py_func, types.void, self.argtypes,\n     84                     debug=self.debug,\n     85                     lineinfo=lineinfo,\n   (...)\n     88                     nvvm_options=nvvm_options,\n     89                     cc=cc)\n     90 tgt_ctx = cres.target_context\n\nFile /opt/conda/lib/python3.10/site-packages/numba/cuda/api.py:443, in get_current_device()\n    441 def get_current_device():\n    442     \"Get current device associated with the current thread\"\n--&gt; 443     return current_context().device\n\nFile /opt/conda/lib/python3.10/site-packages/numba/cuda/cudadrv/devices.py:220, in get_context(devnum)\n    216 def get_context(devnum=None):\n    217     \"\"\"Get the current device or use a device by device number, and\n    218     return the CUDA context.\n    219     \"\"\"\n--&gt; 220     return _runtime.get_or_create_context(devnum)\n\nFile /opt/conda/lib/python3.10/site-packages/numba/cuda/cudadrv/devices.py:138, in _Runtime.get_or_create_context(self, devnum)\n    136 attached_ctx = self._get_attached_context()\n    137 if attached_ctx is None:\n--&gt; 138     return self._get_or_create_context_uncached(devnum)\n    139 else:\n    140     return attached_ctx\n\nFile /opt/conda/lib/python3.10/site-packages/numba/cuda/cudadrv/devices.py:153, in _Runtime._get_or_create_context_uncached(self, devnum)\n    147 \"\"\"See also ``get_or_create_context(devnum)``.\n    148 This version does not read the cache.\n    149 \"\"\"\n    150 with self._lock:\n    151     # Try to get the active context in the CUDA stack or\n    152     # activate GPU-0 with the primary context\n--&gt; 153     with driver.get_active_context() as ac:\n    154         if not ac:\n    155             return self._activate_context_for(0)\n\nFile /opt/conda/lib/python3.10/site-packages/numba/cuda/cudadrv/driver.py:495, in _ActiveContext.__enter__(self)\n    493 else:\n    494     hctx = drvapi.cu_context(0)\n--&gt; 495     driver.cuCtxGetCurrent(byref(hctx))\n    496     hctx = hctx if hctx.value else None\n    498 if hctx is None:\n\nFile /opt/conda/lib/python3.10/site-packages/numba/cuda/cudadrv/driver.py:295, in Driver.__getattr__(self, fname)\n    292 self.ensure_initialized()\n    294 if self.initialization_error is not None:\n--&gt; 295     raise CudaSupportError(\"Error at driver init: \\n%s:\" %\n    296                            self.initialization_error)\n    298 if USE_NV_BINDING:\n    299     return self._cuda_python_wrap_fn(fname)\n\nCudaSupportError: Error at driver init: \n\nCUDA driver library cannot be found.\nIf you are sure that a CUDA driver is installed,\ntry setting environment variable NUMBA_CUDA_DRIVER\nwith the file path of the CUDA driver shared library.\n:</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"notebooks/fractals/#create-new-python-environment","title":"create new python environment\u00b6","text":"<pre>mamba create -n fractal-env python=3.11 -y\n\n# initialize \nmamba init\n\n# close terminal\n</pre> <pre>mamba activate fractal-env\n\nmamba install numpy matplotlib numba pytorch torchvision torchaudio cudatoolkit=11.8 -c pytorch -c nvidia\n</pre> <pre>python -m ipykernel install --name fractal-env --display-name \"Fractal Env\"\n</pre>"},{"location":"notebooks/fractals/#1d-fractals","title":"1D Fractals\u00b6","text":"<p>Example: Cantor Set</p>"},{"location":"notebooks/fractals/#2d-fractals","title":"2D Fractals\u00b6","text":"<p>Example: Sierpinski Triangle</p>"},{"location":"notebooks/fractals/#3d-fractals","title":"3D Fractals\u00b6","text":"<p>Example: Menger Sponge</p>"},{"location":"notebooks/fractals/#converting-to-threejs","title":"Converting to Three.js\u00b6","text":"<p>We can convert the fractal data into a format that Three.js can render. For instance, we'll export the vertex positions and faces for the 3D Menger Sponge.</p> <p>Here's a simple example of how you might export data for use in Three.js:</p>"},{"location":"notebooks/fractals/#displaying-with-threejs","title":"Displaying with Three.js\u00b6","text":"<p>In your HTML file, you would load this JSON data and use Three.js to render it:</p> <pre>&lt;!DOCTYPE html&gt;\n&lt;html lang=\"en\"&gt;\n&lt;head&gt;\n    &lt;meta charset=\"UTF-8\"&gt;\n    &lt;title&gt;Menger Sponge&lt;/title&gt;\n    &lt;style&gt;\n        body { margin: 0; }\n        canvas { display: block; }\n    &lt;/style&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;script src=\"https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js\"&gt;&lt;/script&gt;\n    &lt;script&gt;\n        let scene = new THREE.Scene();\n        let camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);\n        let renderer = new THREE.WebGLRenderer();\n        renderer.setSize(window.innerWidth, window.innerHeight);\n        document.body.appendChild(renderer.domElement);\n\n        fetch('menger_sponge.json')\n            .then(response =&gt; response.json())\n            .then(data =&gt; {\n                let geometry = new THREE.Geometry();\n                data.vertices.forEach(v =&gt; geometry.vertices.push(new THREE.Vector3(v[0], v[1], v[2])));\n                data.faces.forEach(f =&gt; geometry.faces.push(new THREE.Face3(f[0], f[1], f[2])));\n                let material = new THREE.MeshBasicMaterial({ color: 0x00ff00, wireframe: true });\n                let mesh = new THREE.Mesh(geometry, material);\n                scene.add(mesh);\n\n                camera.position.z = 50;\n                let animate = function () {\n                    requestAnimationFrame(animate);\n                    mesh.rotation.x += 0.01;\n                    mesh.rotation.y += 0.01;\n                    renderer.render(scene, camera);\n                };\n                animate();\n            });\n    &lt;/script&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</pre> <p>With these examples, you should be able to generate fractal data in Python and display it using Three.js. Feel free to modify and expand these examples based on your specific needs</p>"},{"location":"notebooks/fractals/#1d-self-affine-fractal-fractional-brownian-motion","title":"1D Self-Affine Fractal: Fractional Brownian Motion\u00b6","text":"<p>Fractional Brownian motion (fBm) is a generalization of Brownian motion and can be used to create self-affine fractals.</p>"},{"location":"notebooks/fractals/#2d-self-affine-fractal-perlin-noise","title":"2D Self-Affine Fractal: Perlin Noise\u00b6","text":"<p>Perlin noise is used to generate textures that are self-affine.</p>"},{"location":"notebooks/fractals/#3d-self-affine-fractal-3d-fractional-brownian-motion","title":"3D Self-Affine Fractal: 3D Fractional Brownian Motion\u00b6","text":""},{"location":"notebooks/old_dla/","title":"Diffusion Limited Aggregation (DLA)","text":"In\u00a0[16]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\n\n# Parameters for the simulation\ncluster_radius_limit = 100.0  # Maximum radius the cluster can grow to before walkers are removed\nnum_walkers = 5000            # Number of random walkers in the simulation\nstick_distance = 1.5          # Distance at which a walker sticks to the cluster\ncenter = np.array([0.0, 0.0])  # Center of the simulation\n\n# List of particle positions (start with one particle at the center)\ncluster = [center.copy()]\n\ndef random_walk():\n    \"\"\" Perform random walk in continuous 2D space until the particle sticks to the cluster. \"\"\"\n    # Start at a random point on a circle just outside the current cluster radius\n    angle = 2 * np.pi * np.random.random()\n    r = cluster_radius_limit - 10  # Start walkers near the radius limit\n    x, y = r * np.cos(angle), r * np.sin(angle)\n    walker = np.array([x, y])\n\n    while True:\n        # Calculate distance to origin (if too far, remove walker)\n        if np.linalg.norm(walker) &gt; cluster_radius_limit:\n            return None\n        \n        # Check if the walker is near any particle in the cluster\n        for particle in cluster:\n            if np.linalg.norm(walker - particle) &lt; stick_distance:\n                return walker\n\n        # Move the walker in a random direction\n        angle = 2 * np.pi * np.random.random()  # Random direction\n        step_size = np.random.uniform(0.8, 1.2)  # Variable step size\n        walker[0] += step_size * np.cos(angle)\n        walker[1] += step_size * np.sin(angle)\n\ndef simulate_dla_parallel(num_walkers, max_workers=8):\n    \"\"\" Simulate the diffusion-limited aggregation process in parallel. \"\"\"\n    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n        futures = [executor.submit(random_walk) for _ in range(num_walkers)]\n        for future in as_completed(futures):\n            result = future.result()\n            if result is not None:\n                cluster.append(result)\n    \n    # Extract X and Y coordinates of all particles in the cluster\n    cluster_coords = np.array(cluster)\n    x_coords = cluster_coords[:, 0]\n    y_coords = cluster_coords[:, 1]\n\n    # Plot the resulting cluster\n    plt.figure(figsize=(8, 8))\n    plt.scatter(x_coords, y_coords, s=1, color='black')\n    plt.title(f'Diffusion-Limited Aggregation with {num_walkers} Walkers (Parallel)')\n    plt.axis('equal')\n    plt.show()\n\n# Run the parallel simulation\nsimulate_dla_parallel(num_walkers)\n</pre> import numpy as np import matplotlib.pyplot as plt from concurrent.futures import ThreadPoolExecutor, as_completed  # Parameters for the simulation cluster_radius_limit = 100.0  # Maximum radius the cluster can grow to before walkers are removed num_walkers = 5000            # Number of random walkers in the simulation stick_distance = 1.5          # Distance at which a walker sticks to the cluster center = np.array([0.0, 0.0])  # Center of the simulation  # List of particle positions (start with one particle at the center) cluster = [center.copy()]  def random_walk():     \"\"\" Perform random walk in continuous 2D space until the particle sticks to the cluster. \"\"\"     # Start at a random point on a circle just outside the current cluster radius     angle = 2 * np.pi * np.random.random()     r = cluster_radius_limit - 10  # Start walkers near the radius limit     x, y = r * np.cos(angle), r * np.sin(angle)     walker = np.array([x, y])      while True:         # Calculate distance to origin (if too far, remove walker)         if np.linalg.norm(walker) &gt; cluster_radius_limit:             return None                  # Check if the walker is near any particle in the cluster         for particle in cluster:             if np.linalg.norm(walker - particle) &lt; stick_distance:                 return walker          # Move the walker in a random direction         angle = 2 * np.pi * np.random.random()  # Random direction         step_size = np.random.uniform(0.8, 1.2)  # Variable step size         walker[0] += step_size * np.cos(angle)         walker[1] += step_size * np.sin(angle)  def simulate_dla_parallel(num_walkers, max_workers=8):     \"\"\" Simulate the diffusion-limited aggregation process in parallel. \"\"\"     with ThreadPoolExecutor(max_workers=max_workers) as executor:         futures = [executor.submit(random_walk) for _ in range(num_walkers)]         for future in as_completed(futures):             result = future.result()             if result is not None:                 cluster.append(result)          # Extract X and Y coordinates of all particles in the cluster     cluster_coords = np.array(cluster)     x_coords = cluster_coords[:, 0]     y_coords = cluster_coords[:, 1]      # Plot the resulting cluster     plt.figure(figsize=(8, 8))     plt.scatter(x_coords, y_coords, s=1, color='black')     plt.title(f'Diffusion-Limited Aggregation with {num_walkers} Walkers (Parallel)')     plt.axis('equal')     plt.show()  # Run the parallel simulation simulate_dla_parallel(num_walkers)  <pre>\n---------------------------------------------------------------------------\nKeyboardInterrupt                         Traceback (most recent call last)\nCell In[16], line 42, in simulate_dla_parallel(num_walkers, max_workers)\n     41 futures = [executor.submit(random_walk) for _ in range(num_walkers)]\n---&gt; 42 for future in as_completed(futures):\n     43     result = future.result()\n\nFile /opt/homebrew/Cellar/python@3.11/3.11.4_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py:243, in as_completed(fs, timeout)\n    239         raise TimeoutError(\n    240                 '%d (of %d) futures unfinished' % (\n    241                 len(pending), total_futures))\n--&gt; 243 waiter.event.wait(wait_timeout)\n    245 with waiter.lock:\n\nFile /opt/homebrew/Cellar/python@3.11/3.11.4_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py:622, in Event.wait(self, timeout)\n    621 if not signaled:\n--&gt; 622     signaled = self._cond.wait(timeout)\n    623 return signaled\n\nFile /opt/homebrew/Cellar/python@3.11/3.11.4_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py:320, in Condition.wait(self, timeout)\n    319 if timeout is None:\n--&gt; 320     waiter.acquire()\n    321     gotit = True\n\nKeyboardInterrupt: \n\nDuring handling of the above exception, another exception occurred:\n\nKeyboardInterrupt                         Traceback (most recent call last)\nCell In[16], line 60\n     57     plt.show()\n     59 # Run the parallel simulation\n---&gt; 60 simulate_dla_parallel(num_walkers)\n\nCell In[16], line 40, in simulate_dla_parallel(num_walkers, max_workers)\n     38 def simulate_dla_parallel(num_walkers, max_workers=8):\n     39     \"\"\" Simulate the diffusion-limited aggregation process in parallel. \"\"\"\n---&gt; 40     with ThreadPoolExecutor(max_workers=max_workers) as executor:\n     41         futures = [executor.submit(random_walk) for _ in range(num_walkers)]\n     42         for future in as_completed(futures):\n\nFile /opt/homebrew/Cellar/python@3.11/3.11.4_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py:647, in Executor.__exit__(self, exc_type, exc_val, exc_tb)\n    646 def __exit__(self, exc_type, exc_val, exc_tb):\n--&gt; 647     self.shutdown(wait=True)\n    648     return False\n\nFile /opt/homebrew/Cellar/python@3.11/3.11.4_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py:235, in ThreadPoolExecutor.shutdown(self, wait, cancel_futures)\n    233 if wait:\n    234     for t in self._threads:\n--&gt; 235         t.join()\n\nFile /opt/homebrew/Cellar/python@3.11/3.11.4_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py:1112, in Thread.join(self, timeout)\n   1109     raise RuntimeError(\"cannot join current thread\")\n   1111 if timeout is None:\n-&gt; 1112     self._wait_for_tstate_lock()\n   1113 else:\n   1114     # the behavior of a negative timeout isn't documented, but\n   1115     # historically .join(timeout=x) for x&lt;0 has acted as if timeout=0\n   1116     self._wait_for_tstate_lock(timeout=max(timeout, 0))\n\nFile /opt/homebrew/Cellar/python@3.11/3.11.4_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py:1132, in Thread._wait_for_tstate_lock(self, block, timeout)\n   1129     return\n   1131 try:\n-&gt; 1132     if lock.acquire(block, timeout):\n   1133         lock.release()\n   1134         self._stop()\n\nKeyboardInterrupt: </pre> In\u00a0[15]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.spatial import cKDTree\nfrom multiprocessing import Pool, cpu_count\n\n# Parameters for the simulation\ncluster_radius_limit = 100.0  # Maximum radius the cluster can grow to before walkers are removed\nnum_walkers = 5000            # Number of random walkers to simulate\nstick_distance = 1.5          # Distance at which a walker sticks to the cluster\ncenter = np.array([0.0, 0.0])  # Center of the simulation\nbatch_size = 100              # Number of walkers to simulate in each batch\n\n# Initialize cluster with one particle at the center\ncluster = [center.copy()]\n\ndef random_walk(args):\n    \"\"\"Perform random walk until the particle sticks to the cluster.\"\"\"\n    cluster_positions, stick_distance, cluster_radius_limit = args\n    cluster_tree = cKDTree(cluster_positions)\n    angle = 2 * np.pi * np.random.random()\n    r = cluster_radius_limit - 10  # Start walkers near the radius limit\n    x, y = r * np.cos(angle), r * np.sin(angle)\n    walker = np.array([x, y], dtype=np.float64)\n\n    while True:\n        # Check if the walker is within the cluster radius limit\n        if np.hypot(walker[0], walker[1]) &gt; cluster_radius_limit:\n            return None\n\n        # Check if the walker is near any particle in the cluster\n        indices = cluster_tree.query_ball_point(walker, stick_distance)\n        if indices:\n            return walker\n\n        # Move the walker in a random direction\n        angle = 2 * np.pi * np.random.random()  # Random direction\n        step_size = np.random.uniform(0.8, 1.2)  # Variable step size\n        walker[0] += step_size * np.cos(angle)\n        walker[1] += step_size * np.sin(angle)\n\ndef simulate_dla(num_walkers, stick_distance, cluster_radius_limit, batch_size=100):\n    \"\"\"Simulate the diffusion-limited aggregation process.\"\"\"\n    cluster = [np.array([0.0, 0.0], dtype=np.float64)]\n    num_particles = 1  # Start with the seed particle\n\n    while num_particles &lt; num_walkers:\n        cluster_positions = np.array(cluster)\n        args_list = [(cluster_positions, stick_distance, cluster_radius_limit)] * batch_size\n\n        with Pool(processes=cpu_count()) as pool:\n            results = pool.map(random_walk, args_list)\n\n        # Add new particles that stuck to the cluster\n        new_particles = [walker for walker in results if walker is not None]\n        cluster.extend(new_particles)\n        num_particles += len(new_particles)\n        print(f'Number of particles in cluster: {num_particles}')\n\n    return np.array(cluster[:num_walkers])\n\n# Run the simulation\ncluster = simulate_dla(num_walkers, stick_distance, cluster_radius_limit, batch_size)\n\n# Extract X and Y coordinates of all particles in the cluster\nx_coords = cluster[:, 0]\ny_coords = cluster[:, 1]\n\n# Plot the resulting cluster\nplt.figure(figsize=(8, 8))\nplt.scatter(x_coords, y_coords, s=1, color='black')\nplt.title(f'Diffusion-Limited Aggregation with {num_walkers} Walkers (Parallelized)')\nplt.axis('equal')\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt from scipy.spatial import cKDTree from multiprocessing import Pool, cpu_count  # Parameters for the simulation cluster_radius_limit = 100.0  # Maximum radius the cluster can grow to before walkers are removed num_walkers = 5000            # Number of random walkers to simulate stick_distance = 1.5          # Distance at which a walker sticks to the cluster center = np.array([0.0, 0.0])  # Center of the simulation batch_size = 100              # Number of walkers to simulate in each batch  # Initialize cluster with one particle at the center cluster = [center.copy()]  def random_walk(args):     \"\"\"Perform random walk until the particle sticks to the cluster.\"\"\"     cluster_positions, stick_distance, cluster_radius_limit = args     cluster_tree = cKDTree(cluster_positions)     angle = 2 * np.pi * np.random.random()     r = cluster_radius_limit - 10  # Start walkers near the radius limit     x, y = r * np.cos(angle), r * np.sin(angle)     walker = np.array([x, y], dtype=np.float64)      while True:         # Check if the walker is within the cluster radius limit         if np.hypot(walker[0], walker[1]) &gt; cluster_radius_limit:             return None          # Check if the walker is near any particle in the cluster         indices = cluster_tree.query_ball_point(walker, stick_distance)         if indices:             return walker          # Move the walker in a random direction         angle = 2 * np.pi * np.random.random()  # Random direction         step_size = np.random.uniform(0.8, 1.2)  # Variable step size         walker[0] += step_size * np.cos(angle)         walker[1] += step_size * np.sin(angle)  def simulate_dla(num_walkers, stick_distance, cluster_radius_limit, batch_size=100):     \"\"\"Simulate the diffusion-limited aggregation process.\"\"\"     cluster = [np.array([0.0, 0.0], dtype=np.float64)]     num_particles = 1  # Start with the seed particle      while num_particles &lt; num_walkers:         cluster_positions = np.array(cluster)         args_list = [(cluster_positions, stick_distance, cluster_radius_limit)] * batch_size          with Pool(processes=cpu_count()) as pool:             results = pool.map(random_walk, args_list)          # Add new particles that stuck to the cluster         new_particles = [walker for walker in results if walker is not None]         cluster.extend(new_particles)         num_particles += len(new_particles)         print(f'Number of particles in cluster: {num_particles}')      return np.array(cluster[:num_walkers])  # Run the simulation cluster = simulate_dla(num_walkers, stick_distance, cluster_radius_limit, batch_size)  # Extract X and Y coordinates of all particles in the cluster x_coords = cluster[:, 0] y_coords = cluster[:, 1]  # Plot the resulting cluster plt.figure(figsize=(8, 8)) plt.scatter(x_coords, y_coords, s=1, color='black') plt.title(f'Diffusion-Limited Aggregation with {num_walkers} Walkers (Parallelized)') plt.axis('equal') plt.show()  <pre>\n---------------------------------------------------------------------------\nTypingError                               Traceback (most recent call last)\nCell In[15], line 56\n     53     return np.array(cluster)\n     55 # Run the GPU-accelerated simulation\n---&gt; 56 cluster = simulate_dla_gpu(num_walkers, stick_distance, cluster_radius_limit)\n     58 # Extract X and Y coordinates of all particles in the cluster\n     59 x_coords = cluster[:, 0]\n\nFile ~/github/fractal-notebooks/.venv/lib/python3.11/site-packages/numba/core/dispatcher.py:423, in _DispatcherBase._compile_for_args(self, *args, **kws)\n    419         msg = (f\"{str(e).rstrip()} \\n\\nThis error may have been caused \"\n    420                f\"by the following argument(s):\\n{args_str}\\n\")\n    421         e.patch_message(msg)\n--&gt; 423     error_rewrite(e, 'typing')\n    424 except errors.UnsupportedError as e:\n    425     # Something unsupported is present in the user code, add help info\n    426     error_rewrite(e, 'unsupported_error')\n\nFile ~/github/fractal-notebooks/.venv/lib/python3.11/site-packages/numba/core/dispatcher.py:364, in _DispatcherBase._compile_for_args.&lt;locals&gt;.error_rewrite(e, issue_type)\n    362     raise e\n    363 else:\n--&gt; 364     raise e.with_traceback(None)\n\nTypingError: Failed in nopython mode pipeline (step: nopython frontend)\nFailed in nopython mode pipeline (step: nopython frontend)\nFailed in nopython mode pipeline (step: native parfor lowering)\nFailed in full_parfor_gufunc mode pipeline (step: nopython frontend)\nNo implementation of function Function(&lt;built-in function iadd&gt;) found for signature:\n \n &gt;&gt;&gt; iadd(float64, array(float64, 1d, C))\n \nThere are 18 candidate implementations:\n  - Of which 16 did not match due to:\n  Overload of function 'iadd': File: &lt;numerous&gt;: Line N/A.\n    With argument(s): '(float64, array(float64, 1d, C))':\n   No match.\n  - Of which 2 did not match due to:\n  Operator Overload in function 'iadd': File: unknown: Line unknown.\n    With argument(s): '(float64, array(float64, 1d, C))':\n   No match for registered cases:\n    * (int64, int64) -&gt; int64\n    * (int64, uint64) -&gt; int64\n    * (uint64, int64) -&gt; int64\n    * (uint64, uint64) -&gt; uint64\n    * (float32, float32) -&gt; float32\n    * (float64, float64) -&gt; float64\n    * (complex64, complex64) -&gt; complex64\n    * (complex128, complex128) -&gt; complex128\n\nDuring: typing of intrinsic-call at /Users/tswetnam/github/fractal-notebooks/.venv/lib/python3.11/site-packages/numba/parfors/parfor.py (283)\n\nFile \"../../.venv/lib/python3.11/site-packages/numba/parfors/parfor.py\", line 283:\n        def sum_1(in_arr):\n            &lt;source elided&gt;\n            for i in numba.parfors.parfor.internal_prange(len(in_arr)):\n                val += in_arr[i]\n                ^\n\nDuring: lowering \"id=5[LoopNest(index_variable = parfor_index.273, range = (0, p1_size0.271, 1))]{1636: &lt;ir.Block at /var/folders/l4/d18992bj657ctzkbchnx_s5h0000gp/T/ipykernel_59340/3949247615.py (17)&gt;}Var(parfor_index.273, 3949247615.py:17)\" at /var/folders/l4/d18992bj657ctzkbchnx_s5h0000gp/T/ipykernel_59340/3949247615.py (17)\nDuring: resolving callee type: type(CPUDispatcher(&lt;function distance at 0x126207ba0&gt;))\nDuring: typing of call at /var/folders/l4/d18992bj657ctzkbchnx_s5h0000gp/T/ipykernel_59340/3949247615.py (35)\n\nDuring: resolving callee type: type(CPUDispatcher(&lt;function distance at 0x126207ba0&gt;))\nDuring: typing of call at /var/folders/l4/d18992bj657ctzkbchnx_s5h0000gp/T/ipykernel_59340/3949247615.py (35)\n\n\nFile \"../../../../../../var/folders/l4/d18992bj657ctzkbchnx_s5h0000gp/T/ipykernel_59340/3949247615.py\", line 35:\n&lt;source missing, REPL/exec in use?&gt;\n\nDuring: resolving callee type: type(CPUDispatcher(&lt;function random_walk at 0x126205c60&gt;))\nDuring: typing of call at /var/folders/l4/d18992bj657ctzkbchnx_s5h0000gp/T/ipykernel_59340/3949247615.py (49)\n\nDuring: resolving callee type: type(CPUDispatcher(&lt;function random_walk at 0x126205c60&gt;))\nDuring: typing of call at /var/folders/l4/d18992bj657ctzkbchnx_s5h0000gp/T/ipykernel_59340/3949247615.py (49)\n\n\nFile \"../../../../../../var/folders/l4/d18992bj657ctzkbchnx_s5h0000gp/T/ipykernel_59340/3949247615.py\", line 49:\n&lt;source missing, REPL/exec in use?&gt;\n</pre> In\u00a0[1]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom numba import njit, prange\n</pre> import numpy as np import matplotlib.pyplot as plt from numba import njit, prange  In\u00a0[2]: Copied! <pre># Grid size\ngrid_size = 1000\n\n# Number of particles\nnum_particles = 200000\n\n# Maximum steps per particle\nmax_steps = 1000000\n\n# Initialize the grid\ngrid = np.zeros((grid_size, grid_size), dtype=np.float64)\n\n# Set the seed particle at the center\ncenter = grid_size // 2\ngrid[center, center] = 1\n</pre> # Grid size grid_size = 1000  # Number of particles num_particles = 200000  # Maximum steps per particle max_steps = 1000000  # Initialize the grid grid = np.zeros((grid_size, grid_size), dtype=np.float64)  # Set the seed particle at the center center = grid_size // 2 grid[center, center] = 1  In\u00a0[3]: Copied! <pre>@njit(parallel=True)\ndef dla_simulation(grid, num_particles, max_steps):\n    grid_size = grid.shape[0]\n    center = grid_size // 2\n\n    for n in prange(num_particles):\n        # Start the particle at a random position on the boundary\n        angle = 2 * np.pi * np.random.rand()\n        x = int(center + (grid_size // 2 - 1) * np.cos(angle))\n        y = int(center + (grid_size // 2 - 1) * np.sin(angle))\n\n        for _ in range(max_steps):\n            # Random movement\n            direction = np.random.randint(4)\n            if direction == 0 and x &gt; 0:\n                x -= 1  # Left\n            elif direction == 1 and x &lt; grid_size - 1:\n                x += 1  # Right\n            elif direction == 2 and y &gt; 0:\n                y -= 1  # Up\n            elif direction == 3 and y &lt; grid_size - 1:\n                y += 1  # Down\n\n            # Check if the particle is adjacent to the cluster\n            if (grid[(x - 1) % grid_size, y] == 1 or\n                grid[(x + 1) % grid_size, y] == 1 or\n                grid[x, (y - 1) % grid_size] == 1 or\n                grid[x, (y + 1) % grid_size] == 1):\n                grid[x, y] = 1\n                break\n            # If the particle moves out of bounds, reposition it\n            if x &lt;= 0 or x &gt;= grid_size - 1 or y &lt;= 0 or y &gt;= grid_size - 1:\n                break\n</pre> @njit(parallel=True) def dla_simulation(grid, num_particles, max_steps):     grid_size = grid.shape[0]     center = grid_size // 2      for n in prange(num_particles):         # Start the particle at a random position on the boundary         angle = 2 * np.pi * np.random.rand()         x = int(center + (grid_size // 2 - 1) * np.cos(angle))         y = int(center + (grid_size // 2 - 1) * np.sin(angle))          for _ in range(max_steps):             # Random movement             direction = np.random.randint(4)             if direction == 0 and x &gt; 0:                 x -= 1  # Left             elif direction == 1 and x &lt; grid_size - 1:                 x += 1  # Right             elif direction == 2 and y &gt; 0:                 y -= 1  # Up             elif direction == 3 and y &lt; grid_size - 1:                 y += 1  # Down              # Check if the particle is adjacent to the cluster             if (grid[(x - 1) % grid_size, y] == 1 or                 grid[(x + 1) % grid_size, y] == 1 or                 grid[x, (y - 1) % grid_size] == 1 or                 grid[x, (y + 1) % grid_size] == 1):                 grid[x, y] = 1                 break             # If the particle moves out of bounds, reposition it             if x &lt;= 0 or x &gt;= grid_size - 1 or y &lt;= 0 or y &gt;= grid_size - 1:                 break  In\u00a0[4]: Copied! <pre># Run the DLA simulation\ndla_simulation(grid, num_particles, max_steps)\n</pre> # Run the DLA simulation dla_simulation(grid, num_particles, max_steps)  In\u00a0[5]: Copied! <pre>plt.figure(figsize=(16, 16))\nplt.imshow(grid, cmap='Reds')\nplt.axis('off')\nplt.title('DLA Simulation Resembling a Lichen')\nplt.show()\n</pre> plt.figure(figsize=(16, 16)) plt.imshow(grid, cmap='Reds') plt.axis('off') plt.title('DLA Simulation Resembling a Lichen') plt.show()  In\u00a0[6]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nimport ipywidgets as widgets\nfrom ipywidgets import interact\nfrom numba import njit\n\n# DLA Simulation Function\n@njit\ndef dla_simulation(grid_size, num_particles, max_steps):\n    grid = np.zeros((grid_size, grid_size), dtype=np.float64)\n    center = grid_size // 2\n    grid[center, center] = 1\n\n    for _ in range(num_particles):\n        angle = 2 * np.pi * np.random.rand()\n        x = int(center + (grid_size // 2 - 1) * np.cos(angle))\n        y = int(center + (grid_size // 2 - 1) * np.sin(angle))\n\n        for _ in range(max_steps):\n            direction = np.random.randint(4)\n            if direction == 0 and x &gt; 0:\n                x -= 1\n            elif direction == 1 and x &lt; grid_size - 1:\n                x += 1\n            elif direction == 2 and y &gt; 0:\n                y -= 1\n            elif direction == 3 and y &lt; grid_size - 1:\n                y += 1\n\n            if (grid[(x - 1) % grid_size, y] == 1 or\n                grid[(x + 1) % grid_size, y] == 1 or\n                grid[x, (y - 1) % grid_size] == 1 or\n                grid[x, (y + 1) % grid_size] == 1):\n                grid[x, y] = 1\n                break\n\n    return grid\n\n# Plotting Function\ndef plot_dla(grid_size, num_particles, max_steps):\n    grid = dla_simulation(grid_size, num_particles, max_steps)\n    plt.figure(figsize=(16, 16))\n    plt.imshow(grid, cmap='Reds')\n    plt.axis('off')\n    plt.title(f'DLA Simulation\\nGrid Size: {grid_size}, Particles: {num_particles}, Max Steps: {max_steps}')\n    plt.show()\n\n# Sliders for interactive inputs\ngrid_size_slider = widgets.IntSlider(min=100, max=800, step=50, value=500, description='Grid Size')\nnum_particles_slider = widgets.IntSlider(min=1000, max=100000, step=5000, value=50000, description='Particles')\nmax_steps_slider = widgets.IntSlider(min=1000, max=2000000, step=1000, value=10000, description='Max Steps')\n\n# Interactive widget display\ninteract(plot_dla, \n         grid_size=grid_size_slider, \n         num_particles=num_particles_slider, \n         max_steps=max_steps_slider)\n</pre> import numpy as np import matplotlib.pyplot as plt import ipywidgets as widgets from ipywidgets import interact from numba import njit  # DLA Simulation Function @njit def dla_simulation(grid_size, num_particles, max_steps):     grid = np.zeros((grid_size, grid_size), dtype=np.float64)     center = grid_size // 2     grid[center, center] = 1      for _ in range(num_particles):         angle = 2 * np.pi * np.random.rand()         x = int(center + (grid_size // 2 - 1) * np.cos(angle))         y = int(center + (grid_size // 2 - 1) * np.sin(angle))          for _ in range(max_steps):             direction = np.random.randint(4)             if direction == 0 and x &gt; 0:                 x -= 1             elif direction == 1 and x &lt; grid_size - 1:                 x += 1             elif direction == 2 and y &gt; 0:                 y -= 1             elif direction == 3 and y &lt; grid_size - 1:                 y += 1              if (grid[(x - 1) % grid_size, y] == 1 or                 grid[(x + 1) % grid_size, y] == 1 or                 grid[x, (y - 1) % grid_size] == 1 or                 grid[x, (y + 1) % grid_size] == 1):                 grid[x, y] = 1                 break      return grid  # Plotting Function def plot_dla(grid_size, num_particles, max_steps):     grid = dla_simulation(grid_size, num_particles, max_steps)     plt.figure(figsize=(16, 16))     plt.imshow(grid, cmap='Reds')     plt.axis('off')     plt.title(f'DLA Simulation\\nGrid Size: {grid_size}, Particles: {num_particles}, Max Steps: {max_steps}')     plt.show()  # Sliders for interactive inputs grid_size_slider = widgets.IntSlider(min=100, max=800, step=50, value=500, description='Grid Size') num_particles_slider = widgets.IntSlider(min=1000, max=100000, step=5000, value=50000, description='Particles') max_steps_slider = widgets.IntSlider(min=1000, max=2000000, step=1000, value=10000, description='Max Steps')  # Interactive widget display interact(plot_dla,           grid_size=grid_size_slider,           num_particles=num_particles_slider,           max_steps=max_steps_slider)  <pre>interactive(children=(IntSlider(value=500, description='Grid Size', max=800, min=100, step=50), IntSlider(valu\u2026</pre> Out[6]: <pre>&lt;function __main__.plot_dla(grid_size, num_particles, max_steps)&gt;</pre> In\u00a0[7]: Copied! <pre>import numpy as np\nimport plotly.graph_objects as go\nimport ipywidgets as widgets\nfrom ipywidgets import interact\nfrom numba import njit\n\n# DLA Simulation Function\n@njit\ndef dla_simulation(grid_size, num_particles, max_steps):\n    grid = np.zeros((grid_size, grid_size), dtype=np.float64)\n    center = grid_size // 2\n    grid[center, center] = 1\n\n    for _ in range(num_particles):\n        angle = 2 * np.pi * np.random.rand()\n        x = int(center + (grid_size // 2 - 1) * np.cos(angle))\n        y = int(center + (grid_size // 2 - 1) * np.sin(angle))\n\n        for _ in range(max_steps):\n            direction = np.random.randint(4)\n            if direction == 0 and x &gt; 0:\n                x -= 1\n            elif direction == 1 and x &lt; grid_size - 1:\n                x += 1\n            elif direction == 2 and y &gt; 0:\n                y -= 1\n            elif direction == 3 and y &lt; grid_size - 1:\n                y += 1\n\n            if (grid[(x - 1) % grid_size, y] == 1 or\n                grid[(x + 1) % grid_size, y] == 1 or\n                grid[x, (y - 1) % grid_size] == 1 or\n                grid[x, (y + 1) % grid_size] == 1):\n                grid[x, y] = 1\n                break\n\n    return grid\n\n# Plotting Function using Plotly\ndef plot_dla(grid_size, num_particles, max_steps):\n    grid = dla_simulation(grid_size, num_particles, max_steps)\n    \n    fig = go.Figure(data=go.Heatmap(\n        z=grid, \n        colorscale='Greys',\n        showscale=False\n    ))\n\n    fig.update_layout(\n        title=f'DLA Simulation\\nGrid Size: {grid_size}, Particles: {num_particles}, Max Steps: {max_steps}',\n        width=800,\n        height=800,\n        xaxis=dict(showgrid=False, zeroline=False, visible=False),\n        yaxis=dict(showgrid=False, zeroline=False, visible=False),\n    )\n\n    fig.show()\n\n# Sliders for interactive inputs\ngrid_size_slider = widgets.IntSlider(min=100, max=800, step=50, value=500, description='Grid Size')\nnum_particles_slider = widgets.IntSlider(min=1000, max=1000000, step=5000, value=50000, description='Particles')\nmax_steps_slider = widgets.IntSlider(min=1000, max=1000000, step=1000, value=10000, description='Max Steps')\n\n# Interactive widget display\ninteract(plot_dla, \n         grid_size=grid_size_slider, \n         num_particles=num_particles_slider, \n         max_steps=max_steps_slider)\n</pre> import numpy as np import plotly.graph_objects as go import ipywidgets as widgets from ipywidgets import interact from numba import njit  # DLA Simulation Function @njit def dla_simulation(grid_size, num_particles, max_steps):     grid = np.zeros((grid_size, grid_size), dtype=np.float64)     center = grid_size // 2     grid[center, center] = 1      for _ in range(num_particles):         angle = 2 * np.pi * np.random.rand()         x = int(center + (grid_size // 2 - 1) * np.cos(angle))         y = int(center + (grid_size // 2 - 1) * np.sin(angle))          for _ in range(max_steps):             direction = np.random.randint(4)             if direction == 0 and x &gt; 0:                 x -= 1             elif direction == 1 and x &lt; grid_size - 1:                 x += 1             elif direction == 2 and y &gt; 0:                 y -= 1             elif direction == 3 and y &lt; grid_size - 1:                 y += 1              if (grid[(x - 1) % grid_size, y] == 1 or                 grid[(x + 1) % grid_size, y] == 1 or                 grid[x, (y - 1) % grid_size] == 1 or                 grid[x, (y + 1) % grid_size] == 1):                 grid[x, y] = 1                 break      return grid  # Plotting Function using Plotly def plot_dla(grid_size, num_particles, max_steps):     grid = dla_simulation(grid_size, num_particles, max_steps)          fig = go.Figure(data=go.Heatmap(         z=grid,          colorscale='Greys',         showscale=False     ))      fig.update_layout(         title=f'DLA Simulation\\nGrid Size: {grid_size}, Particles: {num_particles}, Max Steps: {max_steps}',         width=800,         height=800,         xaxis=dict(showgrid=False, zeroline=False, visible=False),         yaxis=dict(showgrid=False, zeroline=False, visible=False),     )      fig.show()  # Sliders for interactive inputs grid_size_slider = widgets.IntSlider(min=100, max=800, step=50, value=500, description='Grid Size') num_particles_slider = widgets.IntSlider(min=1000, max=1000000, step=5000, value=50000, description='Particles') max_steps_slider = widgets.IntSlider(min=1000, max=1000000, step=1000, value=10000, description='Max Steps')  # Interactive widget display interact(plot_dla,           grid_size=grid_size_slider,           num_particles=num_particles_slider,           max_steps=max_steps_slider)  <pre>interactive(children=(IntSlider(value=500, description='Grid Size', max=800, min=100, step=50), IntSlider(valu\u2026</pre> Out[7]: <pre>&lt;function __main__.plot_dla(grid_size, num_particles, max_steps)&gt;</pre> In\u00a0[8]: Copied! <pre>@njit(parallel=True)\ndef dla_simulation_saprophyte(grid, num_particles, max_steps):\n    grid_size = grid.shape[0]\n\n    for n in prange(num_particles):\n        # Start the particle at a random position at the bottom\n        x = np.random.randint(0, grid_size)\n        y = grid_size - 1\n\n        for _ in range(max_steps):\n            # Introduce upward bias\n            prob = np.random.rand()\n            if prob &lt; 0.7 and y &gt; 0:\n                y -= 1  # Up\n            elif prob &lt; 0.85 and x &gt; 0:\n                x -= 1  # Left\n            elif prob &lt; 1.0 and x &lt; grid_size - 1:\n                x += 1  # Right\n\n            # Check if the particle is adjacent to the cluster\n            if (grid[x, (y - 1) % grid_size] == 1 or\n                grid[(x - 1) % grid_size, y] == 1 or\n                grid[(x + 1) % grid_size, y] == 1):\n                grid[x, y] = 1\n                break\n            # Break if out of bounds\n            if y &lt;= 0:\n                break\n</pre> @njit(parallel=True) def dla_simulation_saprophyte(grid, num_particles, max_steps):     grid_size = grid.shape[0]      for n in prange(num_particles):         # Start the particle at a random position at the bottom         x = np.random.randint(0, grid_size)         y = grid_size - 1          for _ in range(max_steps):             # Introduce upward bias             prob = np.random.rand()             if prob &lt; 0.7 and y &gt; 0:                 y -= 1  # Up             elif prob &lt; 0.85 and x &gt; 0:                 x -= 1  # Left             elif prob &lt; 1.0 and x &lt; grid_size - 1:                 x += 1  # Right              # Check if the particle is adjacent to the cluster             if (grid[x, (y - 1) % grid_size] == 1 or                 grid[(x - 1) % grid_size, y] == 1 or                 grid[(x + 1) % grid_size, y] == 1):                 grid[x, y] = 1                 break             # Break if out of bounds             if y &lt;= 0:                 break  In\u00a0[9]: Copied! <pre># Initialize the grid\ngrid_saprophyte = np.zeros((grid_size, grid_size), dtype=np.uint8)\n\n# Set the seed particles at the bottom row\ngrid_saprophyte[:, grid_size - 1] = 1\n\n# Run the DLA simulation with upward bias\ndla_simulation_saprophyte(grid_saprophyte, num_particles, max_steps)\n</pre> # Initialize the grid grid_saprophyte = np.zeros((grid_size, grid_size), dtype=np.uint8)  # Set the seed particles at the bottom row grid_saprophyte[:, grid_size - 1] = 1  # Run the DLA simulation with upward bias dla_simulation_saprophyte(grid_saprophyte, num_particles, max_steps)  In\u00a0[10]: Copied! <pre>plt.figure(figsize=(8, 8))\nplt.imshow(grid_saprophyte.T, cmap='Greens')\nplt.axis('off')\nplt.title('DLA Simulation Resembling a Saprophyte')\nplt.show()\n</pre> plt.figure(figsize=(8, 8)) plt.imshow(grid_saprophyte.T, cmap='Greens') plt.axis('off') plt.title('DLA Simulation Resembling a Saprophyte') plt.show() In\u00a0[11]: Copied! <pre>@njit(parallel=True)\ndef dla_simulation_bryophyte(grid, num_particles, max_steps):\n    grid_size = grid.shape[0]\n    center = grid_size // 2\n\n    for n in prange(num_particles):\n        # Start the particle near the bottom center\n        x = np.random.randint(center - 50, center + 50)\n        y = grid_size - 1\n\n        for _ in range(max_steps):\n            # Introduce upward and lateral bias\n            prob = np.random.rand()\n            if prob &lt; 0.6 and y &gt; 0:\n                y -= 1  # Up\n            elif prob &lt; 0.8 and x &gt; 0:\n                x -= 1  # Left\n            elif prob &lt; 1.0 and x &lt; grid_size - 1:\n                x += 1  # Right\n\n            # Check if the particle is adjacent to the cluster\n            if (grid[x, (y - 1) % grid_size] == 1 or\n                grid[(x - 1) % grid_size, y] == 1 or\n                grid[(x + 1) % grid_size, y] == 1):\n                # Introduce lower sticking probability to encourage branching\n                if np.random.rand() &lt; 0.5:\n                    grid[x, y] = 1\n                    break\n            # Break if out of bounds\n            if y &lt;= 0:\n                break\n</pre> @njit(parallel=True) def dla_simulation_bryophyte(grid, num_particles, max_steps):     grid_size = grid.shape[0]     center = grid_size // 2      for n in prange(num_particles):         # Start the particle near the bottom center         x = np.random.randint(center - 50, center + 50)         y = grid_size - 1          for _ in range(max_steps):             # Introduce upward and lateral bias             prob = np.random.rand()             if prob &lt; 0.6 and y &gt; 0:                 y -= 1  # Up             elif prob &lt; 0.8 and x &gt; 0:                 x -= 1  # Left             elif prob &lt; 1.0 and x &lt; grid_size - 1:                 x += 1  # Right              # Check if the particle is adjacent to the cluster             if (grid[x, (y - 1) % grid_size] == 1 or                 grid[(x - 1) % grid_size, y] == 1 or                 grid[(x + 1) % grid_size, y] == 1):                 # Introduce lower sticking probability to encourage branching                 if np.random.rand() &lt; 0.5:                     grid[x, y] = 1                     break             # Break if out of bounds             if y &lt;= 0:                 break In\u00a0[12]: Copied! <pre># Initialize the grid\ngrid_bryophyte = np.zeros((grid_size, grid_size), dtype=np.uint8)\n\n# Set the seed particles at the bottom center\ngrid_bryophyte[center - 5:center + 5, grid_size - 1] = 1\n\n# Run the DLA simulation for bryophyte\ndla_simulation_bryophyte(grid_bryophyte, num_particles, max_steps)\n</pre> # Initialize the grid grid_bryophyte = np.zeros((grid_size, grid_size), dtype=np.uint8)  # Set the seed particles at the bottom center grid_bryophyte[center - 5:center + 5, grid_size - 1] = 1  # Run the DLA simulation for bryophyte dla_simulation_bryophyte(grid_bryophyte, num_particles, max_steps)  In\u00a0[13]: Copied! <pre>plt.figure(figsize=(16, 16))\nplt.imshow(grid_bryophyte.T, cmap='Blues')\nplt.axis('off')\nplt.title('DLA Simulation Resembling a Bryophyte')\nplt.show()\n</pre> plt.figure(figsize=(16, 16)) plt.imshow(grid_bryophyte.T, cmap='Blues') plt.axis('off') plt.title('DLA Simulation Resembling a Bryophyte') plt.show()"},{"location":"notebooks/old_dla/#diffusion-limited-aggregates-dla","title":"Diffusion Limited Aggregates (DLA)\u00b6","text":"<p>In this notebook, we generate self-affine fractal patterns using Python.</p> <p>Specifically, we will create Diffusion Limited Aggregation (DLA) models that resemble an e-coli community, a lichen, a saprophyte, and a bryophyte.</p>"},{"location":"notebooks/old_dla/#e-coli","title":"E. coli &amp;\u00b6","text":"<p>Tronnolone et al. 2018</p> <p>To simulate the diffusion-limited aggregation (DLA) of bacterial cells, we can implement a model where bacterial cells \"diffuse\" randomly until they stick to a growing cluster that begins from a central seed. The DLA process leads to fractal-like growth patterns, which we can simulate using Python and Matplotlib for visualization.</p> <p>Here\u2019s a simple Python implementation to simulate this:</p>"},{"location":"notebooks/old_dla/#dla-resembling-a-lichen","title":"DLA resembling a lichen\u00b6","text":""},{"location":"notebooks/old_dla/#lichen","title":"Lichen\u00b6","text":""},{"location":"notebooks/old_dla/#saprophyte","title":"Saprophyte\u00b6","text":""},{"location":"notebooks/old_dla/#bryophyte","title":"Bryophyte\u00b6","text":"<p>Note: While GPU acceleration can significantly speed up computations, implementing DLA on a GPU is challenging due to the inherently serial and random nature of the algorithm. Therefore, we will use Numba's Just-In-Time (JIT) compilation to optimize our code for better performance.</p>"},{"location":"notebooks/old_dla/#dla-model-resembling-a-saprophyte","title":"DLA Model Resembling a Saprophyte\u00b6","text":""},{"location":"notebooks/old_dla/#dla-model-resembling-a-bryophyte","title":"DLA Model Resembling a Bryophyte\u00b6","text":""},{"location":"notebooks/torch_test/","title":"PyTorch test","text":"In\u00a0[1]: Copied! <pre>import torch\n</pre> import torch In\u00a0[2]: Copied! <pre>print(torch.cuda.is_available())\n</pre> print(torch.cuda.is_available()) <pre>False\n</pre> In\u00a0[3]: Copied! <pre>print(torch.cuda.device_count())\n</pre> print(torch.cuda.device_count()) <pre>0\n</pre> In\u00a0[4]: Copied! <pre>print(torch.cuda.current_device())\n</pre> print(torch.cuda.current_device()) <pre>\n---------------------------------------------------------------------------\nAssertionError                            Traceback (most recent call last)\nCell In[4], line 1\n----&gt; 1 print(torch.cuda.current_device())\n\nFile ~/.local/lib/python3.12/site-packages/torch/cuda/__init__.py:878, in current_device()\n    876 def current_device() -&gt; int:\n    877     r\"\"\"Return the index of a currently selected device.\"\"\"\n--&gt; 878     _lazy_init()\n    879     return torch._C._cuda_getDevice()\n\nFile ~/.local/lib/python3.12/site-packages/torch/cuda/__init__.py:305, in _lazy_init()\n    300     raise RuntimeError(\n    301         \"Cannot re-initialize CUDA in forked subprocess. To use CUDA with \"\n    302         \"multiprocessing, you must use the 'spawn' start method\"\n    303     )\n    304 if not hasattr(torch._C, \"_cuda_getDeviceCount\"):\n--&gt; 305     raise AssertionError(\"Torch not compiled with CUDA enabled\")\n    306 if _cudart is None:\n    307     raise AssertionError(\n    308         \"libcudart functions unavailable. It looks like you have a broken build?\"\n    309     )\n\nAssertionError: Torch not compiled with CUDA enabled</pre> In\u00a0[\u00a0]: Copied! <pre>torch.cuda.device(0)\n</pre> torch.cuda.device(0) In\u00a0[\u00a0]: Copied! <pre>torch.cuda.get_device_name(0)\n</pre> torch.cuda.get_device_name(0) In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"notebooks/zeta_3d/","title":"Riemann Zeta Functions in 3D","text":"<p>Install requirements into the <code>pytorch-gpu</code> environment</p> <pre><code>{bash}\nmamba install -c conda-forge -y gcc_linux-64=9.5.0 pycuda pythreejs ipywidgets jupyter_contrib_nbextensions cudatoolkit numba\njupyter labextension install jupyter-threejs \n</code></pre> In\u00a0[1]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib import cm\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom mpl_toolkits.mplot3d.art3d import Poly3DCollection\nimport pycuda.autoinit\nimport pycuda.driver as drv\nfrom pycuda.compiler import SourceModule\n\n%matplotlib widget\n</pre> import numpy as np import matplotlib.pyplot as plt from matplotlib import cm from mpl_toolkits.mplot3d import Axes3D from mpl_toolkits.mplot3d.art3d import Poly3DCollection import pycuda.autoinit import pycuda.driver as drv from pycuda.compiler import SourceModule  %matplotlib widget  In\u00a0[2]: Copied! <pre>import os\n# Add the directory containing 'nvcc' to the PATH\nos.environ['PATH'] += os.pathsep + '/opt/conda/envs/pytorch-gpu/bin/'\n</pre> import os # Add the directory containing 'nvcc' to the PATH os.environ['PATH'] += os.pathsep + '/opt/conda/envs/pytorch-gpu/bin/' In\u00a0[3]: Copied! <pre># Define CUDA kernel for overlap checking\ncuda_code = \"\"\"\n__global__ void check_overlap(\n    float *positions, float *sizes, int *types,\n    float x_new, float y_new, float z_new, float size_new, int type_new,\n    int num_shapes, int *result)\n{\n    int idx = threadIdx.x + blockIdx.x * blockDim.x;\n    if (idx &gt;= num_shapes)\n        return;\n\n    float x = positions[3 * idx];\n    float y = positions[3 * idx + 1];\n    float z = positions[3 * idx + 2];\n    float size = sizes[idx];\n    int type = types[idx];\n\n    // Approximate all shapes with spheres for overlap checking\n    float dx = x_new - x;\n    float dy = y_new - y;\n    float dz = z_new - z;\n    float distance = sqrtf(dx * dx + dy * dy + dz * dz);\n    float radius_new = size_new;\n    float radius = size;\n\n    if (distance &lt; (radius_new + radius))\n        *result = 1;\n}\n\"\"\"\n\nmod = SourceModule(cuda_code)\ncheck_overlap_cuda = mod.get_function(\"check_overlap\")\n</pre>  # Define CUDA kernel for overlap checking cuda_code = \"\"\" __global__ void check_overlap(     float *positions, float *sizes, int *types,     float x_new, float y_new, float z_new, float size_new, int type_new,     int num_shapes, int *result) {     int idx = threadIdx.x + blockIdx.x * blockDim.x;     if (idx &gt;= num_shapes)         return;      float x = positions[3 * idx];     float y = positions[3 * idx + 1];     float z = positions[3 * idx + 2];     float size = sizes[idx];     int type = types[idx];      // Approximate all shapes with spheres for overlap checking     float dx = x_new - x;     float dy = y_new - y;     float dz = z_new - z;     float distance = sqrtf(dx * dx + dy * dy + dz * dz);     float radius_new = size_new;     float radius = size;      if (distance &lt; (radius_new + radius))         *result = 1; } \"\"\"  mod = SourceModule(cuda_code) check_overlap_cuda = mod.get_function(\"check_overlap\") In\u00a0[4]: Copied! <pre># Parameters\nA_volume = 10000.0  # Total volume to be filled\nA0 = 100.0           # Initial volume of the shape\np = 1.2            # Exponent in the decreasing function\nn_shapes = 2000000     # Number of shapes to attempt to place\nmax_particle_size = 50.0\nmin_particle_size = 0.1\n\n# Shape types: 1 - Sphere, 2 - Cube, 3 - Tetrahedron\nshape_types_list = [1,3]\n</pre>  # Parameters A_volume = 10000.0  # Total volume to be filled A0 = 100.0           # Initial volume of the shape p = 1.2            # Exponent in the decreasing function n_shapes = 2000000     # Number of shapes to attempt to place max_particle_size = 50.0 min_particle_size = 0.1  # Shape types: 1 - Sphere, 2 - Cube, 3 - Tetrahedron shape_types_list = [1,3] In\u00a0[5]: Copied! <pre># Generate volumes for each shape\nvolumes = [A0]\ni = 1\nwhile len(volumes) &lt; n_shapes:\n    volume = A0 / ((i ** p))\n    size = (3 * volume / (4 * np.pi)) ** (1 / 3)  # Radius for spheres\n    if size &gt; max_particle_size:\n        i += 1\n        continue\n    volumes.append(volume)\n    i += 1\n\n# Shuffle volumes to distribute sizes among shapes\nnp.random.shuffle(volumes)\n\n# Assign volumes and sizes to shapes\npositions = []\nsizes = []\ntypes = []\n\n# Define the space dimensions (cube)\nL = A_volume ** (1 / 3)\n\n# Initialize arrays for CUDA\npositions_array = np.array([], dtype=np.float32)\nsizes_array = np.array([], dtype=np.float32)\ntypes_array = np.array([], dtype=np.int32)\n\n# Place the shapes\nfor idx, volume in enumerate(volumes):\n    shape_type = np.random.choice(shape_types_list)\n    if shape_type == 1:\n        # Sphere\n        size = (3 * volume / (4 * np.pi)) ** (1 / 3)\n    elif shape_type == 2:\n        # Cube\n        size = volume ** (1 / 3)\n    elif shape_type == 3:\n        # Tetrahedron\n        size = (volume * (12 / np.sqrt(2))) ** (1 / 3)\n    else:\n        continue\n\n    current_size = size\n    placed = False\n    while current_size &gt;= min_particle_size and not placed:\n        max_attempts = 1000\n        for attempt in range(max_attempts):\n            # Generate random position within the space\n            x = np.random.uniform(current_size, L - current_size)\n            y = np.random.uniform(current_size, L - current_size)\n            z = np.random.uniform(current_size, L - current_size)\n\n            # Check for overlap using CUDA\n            num_existing = len(sizes_array)\n            if num_existing == 0:\n                overlap = False\n            else:\n                overlap_result = np.zeros(1, dtype=np.int32)\n                block_size = 256\n                grid_size = (num_existing + block_size - 1) // block_size\n\n                check_overlap_cuda(\n                    drv.In(positions_array),\n                    drv.In(sizes_array),\n                    drv.In(types_array),\n                    np.float32(x), np.float32(y), np.float32(z),\n                    np.float32(current_size),\n                    np.int32(shape_type),\n                    np.int32(num_existing),\n                    drv.Out(overlap_result),\n                    block=(block_size, 1, 1),\n                    grid=(grid_size, 1)\n                )\n\n                overlap = overlap_result[0] == 1\n\n            if not overlap:\n                # Place the shape\n                positions.append([x, y, z])\n                sizes.append(current_size)\n                types.append(shape_type)\n\n                # Update CUDA arrays\n                positions_array = np.array(positions, dtype=np.float32).flatten()\n                sizes_array = np.array(sizes, dtype=np.float32)\n                types_array = np.array(types, dtype=np.int32)\n                placed = True\n                break\n        if not placed:\n            current_size /= 2.0  # Reduce size and try again\n    #if not placed:\n        #print(f\"Could not place shape {idx+1} even after reducing to minimum size.\")\n        continue\n</pre>  # Generate volumes for each shape volumes = [A0] i = 1 while len(volumes) &lt; n_shapes:     volume = A0 / ((i ** p))     size = (3 * volume / (4 * np.pi)) ** (1 / 3)  # Radius for spheres     if size &gt; max_particle_size:         i += 1         continue     volumes.append(volume)     i += 1  # Shuffle volumes to distribute sizes among shapes np.random.shuffle(volumes)  # Assign volumes and sizes to shapes positions = [] sizes = [] types = []  # Define the space dimensions (cube) L = A_volume ** (1 / 3)  # Initialize arrays for CUDA positions_array = np.array([], dtype=np.float32) sizes_array = np.array([], dtype=np.float32) types_array = np.array([], dtype=np.int32)  # Place the shapes for idx, volume in enumerate(volumes):     shape_type = np.random.choice(shape_types_list)     if shape_type == 1:         # Sphere         size = (3 * volume / (4 * np.pi)) ** (1 / 3)     elif shape_type == 2:         # Cube         size = volume ** (1 / 3)     elif shape_type == 3:         # Tetrahedron         size = (volume * (12 / np.sqrt(2))) ** (1 / 3)     else:         continue      current_size = size     placed = False     while current_size &gt;= min_particle_size and not placed:         max_attempts = 1000         for attempt in range(max_attempts):             # Generate random position within the space             x = np.random.uniform(current_size, L - current_size)             y = np.random.uniform(current_size, L - current_size)             z = np.random.uniform(current_size, L - current_size)              # Check for overlap using CUDA             num_existing = len(sizes_array)             if num_existing == 0:                 overlap = False             else:                 overlap_result = np.zeros(1, dtype=np.int32)                 block_size = 256                 grid_size = (num_existing + block_size - 1) // block_size                  check_overlap_cuda(                     drv.In(positions_array),                     drv.In(sizes_array),                     drv.In(types_array),                     np.float32(x), np.float32(y), np.float32(z),                     np.float32(current_size),                     np.int32(shape_type),                     np.int32(num_existing),                     drv.Out(overlap_result),                     block=(block_size, 1, 1),                     grid=(grid_size, 1)                 )                  overlap = overlap_result[0] == 1              if not overlap:                 # Place the shape                 positions.append([x, y, z])                 sizes.append(current_size)                 types.append(shape_type)                  # Update CUDA arrays                 positions_array = np.array(positions, dtype=np.float32).flatten()                 sizes_array = np.array(sizes, dtype=np.float32)                 types_array = np.array(types, dtype=np.int32)                 placed = True                 break         if not placed:             current_size /= 2.0  # Reduce size and try again     #if not placed:         #print(f\"Could not place shape {idx+1} even after reducing to minimum size.\")         continue   In\u00a0[6]: Copied! <pre># Visualization\nfig = plt.figure(figsize=(10, 10))\nax = fig.add_subplot(111, projection='3d')\n\nfor (x, y, z), size, shape_type in zip(positions, sizes, types):\n    if shape_type == 1:\n        # Sphere\n        u, v = np.mgrid[0:2 * np.pi:20j, 0:np.pi:10j]\n        xs = x + size * np.cos(u) * np.sin(v)\n        ys = y + size * np.sin(u) * np.sin(v)\n        zs = z + size * np.cos(v)\n        ax.plot_surface(xs, ys, zs, color='b', alpha=0.6)\n    elif shape_type == 2:\n        # Cube\n        r = [-size / 2, size / 2]\n        # Generate vertices for the cube\n        vertices = np.array(list(product(r, r, r))) + np.array([x, y, z])\n        # Generate faces of the cube\n        faces = [\n            [vertices[0], vertices[1], vertices[3], vertices[2]],\n            [vertices[4], vertices[5], vertices[7], vertices[6]],\n            [vertices[0], vertices[1], vertices[5], vertices[4]],\n            [vertices[2], vertices[3], vertices[7], vertices[6]],\n            [vertices[1], vertices[3], vertices[7], vertices[5]],\n            [vertices[0], vertices[2], vertices[6], vertices[4]],\n        ]\n        # Add cube to plot\n        ax.add_collection3d(\n            Poly3DCollection(faces, facecolors='g', linewidths=1, edgecolors='g', alpha=0.6)\n        )\n    elif shape_type == 3:\n        # Tetrahedron\n        vertices = np.array([\n            [0, 0, 0],\n            [size, 0, 0],\n            [size / 2, np.sqrt(3) * size / 2, 0],\n            [size / 2, np.sqrt(3) * size / 6, np.sqrt(6) * size / 3]\n        ]) - size / 2\n        vertices += np.array([x, y, z])\n        faces = [\n            [vertices[0], vertices[1], vertices[2]],\n            [vertices[0], vertices[1], vertices[3]],\n            [vertices[0], vertices[2], vertices[3]],\n            [vertices[1], vertices[2], vertices[3]],\n        ]\n        poly3d = [[tuple(vertex) for vertex in face] for face in faces]\n        ax.add_collection3d(\n            Poly3DCollection(poly3d, facecolors='r', linewidths=1, edgecolors='r', alpha=0.6)\n        )\n\n# Set plot parameters\nax.set_xlim(0, L)\nax.set_ylim(0, L)\nax.set_zlim(0, L)\nax.set_xlabel('X-axis')\nax.set_ylabel('Y-axis')\nax.set_zlabel('Z-axis')\nax.set_title('3D Tiling with Spheres, Cubes, and Tetrahedrons')\nplt.show()\n</pre>  # Visualization fig = plt.figure(figsize=(10, 10)) ax = fig.add_subplot(111, projection='3d')  for (x, y, z), size, shape_type in zip(positions, sizes, types):     if shape_type == 1:         # Sphere         u, v = np.mgrid[0:2 * np.pi:20j, 0:np.pi:10j]         xs = x + size * np.cos(u) * np.sin(v)         ys = y + size * np.sin(u) * np.sin(v)         zs = z + size * np.cos(v)         ax.plot_surface(xs, ys, zs, color='b', alpha=0.6)     elif shape_type == 2:         # Cube         r = [-size / 2, size / 2]         # Generate vertices for the cube         vertices = np.array(list(product(r, r, r))) + np.array([x, y, z])         # Generate faces of the cube         faces = [             [vertices[0], vertices[1], vertices[3], vertices[2]],             [vertices[4], vertices[5], vertices[7], vertices[6]],             [vertices[0], vertices[1], vertices[5], vertices[4]],             [vertices[2], vertices[3], vertices[7], vertices[6]],             [vertices[1], vertices[3], vertices[7], vertices[5]],             [vertices[0], vertices[2], vertices[6], vertices[4]],         ]         # Add cube to plot         ax.add_collection3d(             Poly3DCollection(faces, facecolors='g', linewidths=1, edgecolors='g', alpha=0.6)         )     elif shape_type == 3:         # Tetrahedron         vertices = np.array([             [0, 0, 0],             [size, 0, 0],             [size / 2, np.sqrt(3) * size / 2, 0],             [size / 2, np.sqrt(3) * size / 6, np.sqrt(6) * size / 3]         ]) - size / 2         vertices += np.array([x, y, z])         faces = [             [vertices[0], vertices[1], vertices[2]],             [vertices[0], vertices[1], vertices[3]],             [vertices[0], vertices[2], vertices[3]],             [vertices[1], vertices[2], vertices[3]],         ]         poly3d = [[tuple(vertex) for vertex in face] for face in faces]         ax.add_collection3d(             Poly3DCollection(poly3d, facecolors='r', linewidths=1, edgecolors='r', alpha=0.6)         )  # Set plot parameters ax.set_xlim(0, L) ax.set_ylim(0, L) ax.set_zlim(0, L) ax.set_xlabel('X-axis') ax.set_ylabel('Y-axis') ax.set_zlabel('Z-axis') ax.set_title('3D Tiling with Spheres, Cubes, and Tetrahedrons') plt.show()                      Figure                  In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"notebooks/zeta_space/","title":"Riemann Zeta Functions 2D","text":"<ol> <li><p>Run in a Jupyter Notebook:</p> <ul> <li><p>The interactive widgets require an environment that supports <code>ipywidgets</code>.</p> </li> <li><p>Ensure you have <code>ipywidgets</code> installed:</p> <pre>pip install ipywidgets\n</pre> <p>And enable widgets extensions:</p> <pre>jupyter nbextension enable --py widgetsnbextension\n</pre> </li> </ul> </li> <li><p>Interactive Controls:</p> <ul> <li>Shape Types: Use the <code>SelectMultiple</code> widget to choose one or more shapes ('Circle', 'Square', 'Triangle').</li> <li>Plane Area (<code>A_plane</code>): Adjust the total area of the plane to be filled.</li> <li>Initial Area (<code>A0</code>): Set the area of the initial shape.</li> <li>Exponent (<code>p</code>): Modify the exponent in the decreasing function ( g(i) ).</li> <li>Number of Shapes (<code>n_shapes</code>): Set the maximum number of shapes to attempt to place.</li> <li>Max Particle Size (<code>max_particle_size</code>): Specify the maximum size for the shapes.</li> <li>Random Orientation (<code>random_orientation</code>): Toggle random rotations for squares and triangles.</li> </ul> </li> <li><p>Dynamic Updates:</p> <ul> <li>Adjust the controls to see the tiling update in real-time.</li> <li>Observe how changing parameters affects the placement, size, and types of shapes.</li> </ul> </li> </ol> In\u00a0[1]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nfrom scipy.special import zeta\nimport random\nfrom ipywidgets import interact, FloatSlider, IntSlider, Dropdown, Checkbox\n\n# Function to generate the tiling\ndef generate_tiling(\n    shape_type='Circle',\n    A_plane=100.0,\n    A0=2,\n    p=1.2,\n    n_shapes=200000,\n    max_particle_size=15.0,\n    random_orientation=True\n):\n    # Calculate c using the Riemann zeta function\n    zeta_p = zeta(p)\n    c = A0 * zeta_p / (A_plane - A0)\n    \n    # Generate areas for each shape\n    areas = [A0]\n    i = 1\n    while len(areas) &lt; n_shapes:\n        area = A0 / ((i**p) * c)\n        if area &lt;= 0 or np.sqrt(area) &gt; max_particle_size:\n            i += 1\n            continue\n        areas.append(area)\n        i += 1\n\n    # Compute dimensions of the shapes\n    if shape_type == 'Circle':\n        sizes = [np.sqrt(area / np.pi) for area in areas]  # Radii\n    else:\n        sizes = [np.sqrt(area) for area in areas]  # Side lengths for squares and triangles\n\n    # Define the plane dimensions (square)\n    L = np.sqrt(A_plane)  # Length of the side of the square plane\n\n    # Initialize list to store positions and sizes of the shapes\n    positions = []\n\n    # Function to check if a new shape overlaps with existing ones\n    def is_overlapping(x_new, y_new, size_new, positions):\n        for x, y, size, angle in positions:\n            if shape_type == 'Circle':\n                distance = np.hypot(x_new - x, y_new - y)\n                if distance &lt; (size_new + size):\n                    return True\n            else:\n                # Approximate the shapes with circles for overlap checking\n                distance = np.hypot(x_new - x, y_new - y)\n                radius_new = size_new * np.sqrt(2) / 2\n                radius = size * np.sqrt(2) / 2\n                if distance &lt; (radius_new + radius):\n                    return True\n        return False\n\n    # Place the shapes randomly without overlapping\n    for size in sizes:\n        max_attempts = 1000\n        for attempt in range(max_attempts):\n            # Generate random position within the plane, ensuring the shape stays within bounds\n            x = random.uniform(size, L - size)\n            y = random.uniform(size, L - size)\n            angle = random.uniform(0, 360) if random_orientation else 0\n            # Check for overlap\n            if not is_overlapping(x, y, size, positions):\n                positions.append((x, y, size, angle))\n                break\n        else:\n            print(f\"Could not place a shape of size {size} without overlap after {max_attempts} attempts.\")\n            break\n\n    # Plot the shapes\n    fig, ax = plt.subplots(figsize=(8, 8))\n    for x, y, size, angle in positions:\n        if shape_type == 'Circle':\n            shape = plt.Circle((x, y), size, edgecolor='blue', facecolor='lightblue', alpha=0.6)\n        elif shape_type == 'Square':\n            shape = patches.Rectangle(\n                (x - size / 2, y - size / 2),\n                size,\n                size,\n                angle=angle,\n                edgecolor='green',\n                facecolor='lightgreen',\n                alpha=0.6\n            )\n        elif shape_type == 'Triangle':\n            # Equilateral triangle\n            h = size * np.sqrt(3) / 2\n            points = np.array([\n                [x, y + 2 * h / 3],\n                [x - size / 2, y - h / 3],\n                [x + size / 2, y - h / 3]\n            ])\n            t = patches.Polygon(\n                points,\n                closed=True,\n                edgecolor='red',\n                facecolor='salmon',\n                alpha=0.6\n            )\n            shape = t\n            shape.set_transform(\n                plt.matplotlib.transforms.Affine2D().rotate_deg_around(x, y, angle) + ax.transData\n            )\n        else:\n            continue\n\n        if shape_type in ['Circle', 'Square']:\n            shape.set_transform(\n                plt.matplotlib.transforms.Affine2D().rotate_deg_around(x, y, angle) + ax.transData\n            )\n            ax.add_patch(shape)\n        elif shape_type == 'Triangle':\n            ax.add_patch(shape)\n\n    # Set plot parameters\n    ax.set_xlim(0, L)\n    ax.set_ylim(0, L)\n    ax.set_aspect('equal', 'box')\n    ax.set_title(f'Iterative Tiling Using Riemann Zeta Function - {shape_type}s')\n    ax.set_xlabel('X-axis')\n    ax.set_ylabel('Y-axis')\n    plt.grid(True)\n    plt.show()\n\n# Interactive widget function\ndef interactive_tiling(\n    shape_type,\n    A_plane,\n    A0,\n    p,\n    n_shapes,\n    max_particle_size,\n    random_orientation\n):\n    generate_tiling(\n        shape_type=shape_type,\n        A_plane=A_plane,\n        A0=A0,\n        p=p,\n        n_shapes=n_shapes,\n        max_particle_size=max_particle_size,\n        random_orientation=random_orientation\n    )\n\n# Create interactive sliders and dropdowns\ninteract(\n    interactive_tiling,\n    shape_type=Dropdown(options=['Circle', 'Square', 'Triangle'], value='Circle', description='Shape Type'),\n    A_plane=FloatSlider(value=100.0, min=50.0, max=500.0, step=10.0, description='Plane Area'),\n    A0=FloatSlider(value=1.0, min=0.1, max=10.0, step=0.1, description='Initial Area A0'),\n    p=FloatSlider(value=2.0, min=1.1, max=5.0, step=0.1, description='Exponent p'),\n    n_shapes=IntSlider(value=200, min=50, max=1000, step=50, description='Number of Shapes'),\n    max_particle_size=FloatSlider(value=5.0, min=0.5, max=20.0, step=0.5, description='Max Particle Size'),\n    random_orientation=Checkbox(value=True, description='Random Orientation')\n)\n</pre> import numpy as np import matplotlib.pyplot as plt import matplotlib.patches as patches from scipy.special import zeta import random from ipywidgets import interact, FloatSlider, IntSlider, Dropdown, Checkbox  # Function to generate the tiling def generate_tiling(     shape_type='Circle',     A_plane=100.0,     A0=2,     p=1.2,     n_shapes=200000,     max_particle_size=15.0,     random_orientation=True ):     # Calculate c using the Riemann zeta function     zeta_p = zeta(p)     c = A0 * zeta_p / (A_plane - A0)          # Generate areas for each shape     areas = [A0]     i = 1     while len(areas) &lt; n_shapes:         area = A0 / ((i**p) * c)         if area &lt;= 0 or np.sqrt(area) &gt; max_particle_size:             i += 1             continue         areas.append(area)         i += 1      # Compute dimensions of the shapes     if shape_type == 'Circle':         sizes = [np.sqrt(area / np.pi) for area in areas]  # Radii     else:         sizes = [np.sqrt(area) for area in areas]  # Side lengths for squares and triangles      # Define the plane dimensions (square)     L = np.sqrt(A_plane)  # Length of the side of the square plane      # Initialize list to store positions and sizes of the shapes     positions = []      # Function to check if a new shape overlaps with existing ones     def is_overlapping(x_new, y_new, size_new, positions):         for x, y, size, angle in positions:             if shape_type == 'Circle':                 distance = np.hypot(x_new - x, y_new - y)                 if distance &lt; (size_new + size):                     return True             else:                 # Approximate the shapes with circles for overlap checking                 distance = np.hypot(x_new - x, y_new - y)                 radius_new = size_new * np.sqrt(2) / 2                 radius = size * np.sqrt(2) / 2                 if distance &lt; (radius_new + radius):                     return True         return False      # Place the shapes randomly without overlapping     for size in sizes:         max_attempts = 1000         for attempt in range(max_attempts):             # Generate random position within the plane, ensuring the shape stays within bounds             x = random.uniform(size, L - size)             y = random.uniform(size, L - size)             angle = random.uniform(0, 360) if random_orientation else 0             # Check for overlap             if not is_overlapping(x, y, size, positions):                 positions.append((x, y, size, angle))                 break         else:             print(f\"Could not place a shape of size {size} without overlap after {max_attempts} attempts.\")             break      # Plot the shapes     fig, ax = plt.subplots(figsize=(8, 8))     for x, y, size, angle in positions:         if shape_type == 'Circle':             shape = plt.Circle((x, y), size, edgecolor='blue', facecolor='lightblue', alpha=0.6)         elif shape_type == 'Square':             shape = patches.Rectangle(                 (x - size / 2, y - size / 2),                 size,                 size,                 angle=angle,                 edgecolor='green',                 facecolor='lightgreen',                 alpha=0.6             )         elif shape_type == 'Triangle':             # Equilateral triangle             h = size * np.sqrt(3) / 2             points = np.array([                 [x, y + 2 * h / 3],                 [x - size / 2, y - h / 3],                 [x + size / 2, y - h / 3]             ])             t = patches.Polygon(                 points,                 closed=True,                 edgecolor='red',                 facecolor='salmon',                 alpha=0.6             )             shape = t             shape.set_transform(                 plt.matplotlib.transforms.Affine2D().rotate_deg_around(x, y, angle) + ax.transData             )         else:             continue          if shape_type in ['Circle', 'Square']:             shape.set_transform(                 plt.matplotlib.transforms.Affine2D().rotate_deg_around(x, y, angle) + ax.transData             )             ax.add_patch(shape)         elif shape_type == 'Triangle':             ax.add_patch(shape)      # Set plot parameters     ax.set_xlim(0, L)     ax.set_ylim(0, L)     ax.set_aspect('equal', 'box')     ax.set_title(f'Iterative Tiling Using Riemann Zeta Function - {shape_type}s')     ax.set_xlabel('X-axis')     ax.set_ylabel('Y-axis')     plt.grid(True)     plt.show()  # Interactive widget function def interactive_tiling(     shape_type,     A_plane,     A0,     p,     n_shapes,     max_particle_size,     random_orientation ):     generate_tiling(         shape_type=shape_type,         A_plane=A_plane,         A0=A0,         p=p,         n_shapes=n_shapes,         max_particle_size=max_particle_size,         random_orientation=random_orientation     )  # Create interactive sliders and dropdowns interact(     interactive_tiling,     shape_type=Dropdown(options=['Circle', 'Square', 'Triangle'], value='Circle', description='Shape Type'),     A_plane=FloatSlider(value=100.0, min=50.0, max=500.0, step=10.0, description='Plane Area'),     A0=FloatSlider(value=1.0, min=0.1, max=10.0, step=0.1, description='Initial Area A0'),     p=FloatSlider(value=2.0, min=1.1, max=5.0, step=0.1, description='Exponent p'),     n_shapes=IntSlider(value=200, min=50, max=1000, step=50, description='Number of Shapes'),     max_particle_size=FloatSlider(value=5.0, min=0.5, max=20.0, step=0.5, description='Max Particle Size'),     random_orientation=Checkbox(value=True, description='Random Orientation') )  <pre>interactive(children=(Dropdown(description='Shape Type', options=('Circle', 'Square', 'Triangle'), value='Circ\u2026</pre> Out[1]: <pre>&lt;function __main__.interactive_tiling(shape_type, A_plane, A0, p, n_shapes, max_particle_size, random_orientation)&gt;</pre> In\u00a0[3]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nfrom scipy.special import zeta\nimport random\nfrom ipywidgets import interact, FloatSlider, IntSlider, SelectMultiple, Checkbox, HBox, VBox, Label\n\n# Function to generate a random polygon\ndef generate_polygon(center, avg_radius, irregularity, spikiness, num_vertices):\n    '''Generates the points of a random polygon.\n\n    Parameters:\n    - center: tuple (x, y)\n    - avg_radius: float, average radius of the polygon\n    - irregularity: float between 0 and 1, the variance of the angular spacing\n    - spikiness: float between 0 and 1, the variance of the radius\n    - num_vertices: int, number of vertices of the polygon\n\n    Returns:\n    - A list of (x, y) tuples representing the vertices of the polygon.\n    '''\n    irregularity = np.clip(irregularity, 0, 1) * 2 * np.pi / num_vertices\n    spikiness = np.clip(spikiness, 0, 1) * avg_radius\n\n    # Generate angle steps\n    angle_steps = []\n    lower = (2 * np.pi / num_vertices) - irregularity\n    upper = (2 * np.pi / num_vertices) + irregularity\n    sum = 0\n    for _ in range(num_vertices):\n        tmp = random.uniform(lower, upper)\n        angle_steps.append(tmp)\n        sum += tmp\n\n    # Normalize the steps so that the sum is 2*pi\n    k = sum / (2 * np.pi)\n    for i in range(num_vertices):\n        angle_steps[i] /= k\n\n    # Generate the points\n    points = []\n    angle = random.uniform(0, 2 * np.pi)\n    for i in range(num_vertices):\n        r_i = np.clip(random.gauss(avg_radius, spikiness), 0, 2 * avg_radius)\n        x = center[0] + r_i * np.cos(angle)\n        y = center[1] + r_i * np.sin(angle)\n        points.append((x, y))\n        angle += angle_steps[i]\n\n    return points\n\n# Function to generate the tiling\ndef generate_tiling(\n    shape_types=['Circle', 'Square', 'Triangle', 'Polygon'],\n    A_plane=100.0,\n    A0=1.0,\n    p=2.0,\n    n_shapes=200,\n    max_particle_size=5.0,\n    random_orientation=True,\n    polygon_sides=6,\n    irregularity=0.0,\n    spikiness=0.0\n):\n    # Calculate c using the Riemann zeta function\n    zeta_p = zeta(p)\n    c = A0 * zeta_p / (A_plane - A0)\n    \n    # Generate areas for each shape\n    areas = [A0]\n    i = 1\n    while len(areas) &lt; n_shapes:\n        area = A0 / ((i**p) * c)\n        if area &lt;= 0:\n            break\n        size = np.sqrt(area / np.pi) if 'Circle' in shape_types else np.sqrt(area)\n        if size &gt; max_particle_size:\n            i += 1\n            continue\n        areas.append(area)\n        i += 1\n    \n    # Shuffle the areas to distribute sizes among shapes\n    random.shuffle(areas)\n    \n    # Assign areas to shapes\n    shape_assignments = []\n    sizes_list = []\n    for area in areas:\n        shape = random.choice(shape_types)\n        if shape == 'Circle':\n            size = np.sqrt(area / np.pi)  # Radius\n        else:\n            size = np.sqrt(area)  # Side length for squares and triangles\n        sizes_list.append(size)\n        shape_assignments.append(shape)\n    \n    # Define the plane dimensions (square)\n    L = np.sqrt(A_plane)  # Length of the side of the square plane\n    \n    # Initialize list to store positions and sizes of the shapes\n    positions = []\n    \n    # Function to check if a new shape overlaps with existing ones\n    def is_overlapping(x_new, y_new, size_new, shape_new, positions):\n        # Approximate the shape with a circle for overlap checking\n        if shape_new == 'Circle':\n            radius_new = size_new\n        elif shape_new == 'Polygon':\n            radius_new = size_new  # Approximate radius for polygons\n        else:\n            radius_new = size_new * np.sqrt(2) / 2  # For squares and triangles\n        for x, y, size, shape, angle, params in positions:\n            if shape == 'Circle':\n                radius = size\n            elif shape == 'Polygon':\n                radius = size\n            else:\n                radius = size * np.sqrt(2) / 2\n            distance = np.hypot(x_new - x, y_new - y)\n            if distance &lt; (radius_new + radius):\n                return True\n        return False\n    \n    # Place the shapes randomly without overlapping\n    for idx, (size, shape_type) in enumerate(zip(sizes_list, shape_assignments)):\n        max_attempts = 1000\n        for attempt in range(max_attempts):\n            # Generate random position within the plane, ensuring the shape stays within bounds\n            x = random.uniform(size, L - size)\n            y = random.uniform(size, L - size)\n            angle = random.uniform(0, 360) if random_orientation else 0\n            # Check for overlap\n            if not is_overlapping(x, y, size, shape_type, positions):\n                # For polygons, store additional parameters\n                params = {}\n                if shape_type == 'Polygon':\n                    params['num_vertices'] = polygon_sides\n                    params['irregularity'] = irregularity\n                    params['spikiness'] = spikiness\n                else:\n                    params = None\n                positions.append((x, y, size, shape_type, angle, params))\n                break\n        else:\n            print(f\"Could not place a shape of size {size} without overlap after {max_attempts} attempts.\")\n            break\n    \n    # Plot the shapes\n    fig, ax = plt.subplots(figsize=(8, 8))\n    for x, y, size, shape_type, angle, params in positions:\n        if shape_type == 'Circle':\n            shape = plt.Circle((x, y), size, edgecolor='blue', facecolor='lightblue', alpha=0.6)\n            shape.set_transform(\n                plt.matplotlib.transforms.Affine2D().rotate_deg_around(x, y, angle) + ax.transData\n            )\n            ax.add_patch(shape)\n        elif shape_type == 'Square':\n            shape = patches.Rectangle(\n                (x - size / 2, y - size / 2),\n                size,\n                size,\n                angle=angle,\n                edgecolor='green',\n                facecolor='lightgreen',\n                alpha=0.6\n            )\n            ax.add_patch(shape)\n        elif shape_type == 'Triangle':\n            # Equilateral triangle\n            h = size * np.sqrt(3) / 2\n            points = np.array([\n                [x, y + 2 * h / 3],\n                [x - size / 2, y - h / 3],\n                [x + size / 2, y - h / 3]\n            ])\n            t = patches.Polygon(\n                points,\n                closed=True,\n                edgecolor='red',\n                facecolor='salmon',\n                alpha=0.6\n            )\n            t.set_transform(\n                plt.matplotlib.transforms.Affine2D().rotate_deg_around(x, y, angle) + ax.transData\n            )\n            ax.add_patch(t)\n        elif shape_type == 'Polygon':\n            num_vertices = params['num_vertices']\n            irregularity = params['irregularity']\n            spikiness = params['spikiness']\n            avg_radius = size\n            points = generate_polygon(\n                center=(x, y),\n                avg_radius=avg_radius,\n                irregularity=irregularity,\n                spikiness=spikiness,\n                num_vertices=num_vertices\n            )\n            poly = patches.Polygon(\n                points,\n                closed=True,\n                edgecolor='purple',\n                facecolor='violet',\n                alpha=0.6\n            )\n            ax.add_patch(poly)\n        else:\n            continue\n    \n    # Set plot parameters\n    ax.set_xlim(0, L)\n    ax.set_ylim(0, L)\n    ax.set_aspect('equal', 'box')\n    title_shapes = ', '.join(shape_types)\n    ax.set_title(f'Iterative Tiling Using Riemann Zeta Function - {title_shapes}')\n    ax.set_xlabel('X-axis')\n    ax.set_ylabel('Y-axis')\n    plt.grid(True)\n    plt.show()\n    \n# Interactive widget function\ndef interactive_tiling(\n    shape_types,\n    A_plane,\n    A0,\n    p,\n    n_shapes,\n    max_particle_size,\n    random_orientation,\n    polygon_sides,\n    irregularity,\n    spikiness\n):\n    generate_tiling(\n        shape_types=list(shape_types),\n        A_plane=A_plane,\n        A0=A0,\n        p=p,\n        n_shapes=n_shapes,\n        max_particle_size=max_particle_size,\n        random_orientation=random_orientation,\n        polygon_sides=polygon_sides,\n        irregularity=irregularity,\n        spikiness=spikiness\n    )\n\n# Create interactive sliders and widgets\ninteract(\n    interactive_tiling,\n    shape_types=SelectMultiple(\n        options=['Circle', 'Square', 'Triangle', 'Polygon'],\n        value=['Circle', 'Square', 'Triangle', 'Polygon'],\n        description='Shape Types'\n    ),\n    A_plane=FloatSlider(value=100.0, min=50.0, max=500.0, step=10.0, description='Plane Area'),\n    A0=FloatSlider(value=1.0, min=0.1, max=10.0, step=0.1, description='Initial Area A0'),\n    p=FloatSlider(value=2.0, min=1.1, max=5.0, step=0.1, description='Exponent p'),\n    n_shapes=IntSlider(value=200, min=50, max=1000, step=50, description='Number of Shapes'),\n    max_particle_size=FloatSlider(value=5.0, min=0.5, max=20.0, step=0.5, description='Max Particle Size'),\n    random_orientation=Checkbox(value=True, description='Random Orientation'),\n    polygon_sides=IntSlider(value=6, min=3, max=12, step=1, description='Polygon Sides'),\n    irregularity=FloatSlider(value=0.0, min=0.0, max=1.0, step=0.05, description='Irregularity'),\n    spikiness=FloatSlider(value=0.0, min=0.0, max=1.0, step=0.05, description='Spikiness')\n)\n</pre> import numpy as np import matplotlib.pyplot as plt import matplotlib.patches as patches from scipy.special import zeta import random from ipywidgets import interact, FloatSlider, IntSlider, SelectMultiple, Checkbox, HBox, VBox, Label  # Function to generate a random polygon def generate_polygon(center, avg_radius, irregularity, spikiness, num_vertices):     '''Generates the points of a random polygon.      Parameters:     - center: tuple (x, y)     - avg_radius: float, average radius of the polygon     - irregularity: float between 0 and 1, the variance of the angular spacing     - spikiness: float between 0 and 1, the variance of the radius     - num_vertices: int, number of vertices of the polygon      Returns:     - A list of (x, y) tuples representing the vertices of the polygon.     '''     irregularity = np.clip(irregularity, 0, 1) * 2 * np.pi / num_vertices     spikiness = np.clip(spikiness, 0, 1) * avg_radius      # Generate angle steps     angle_steps = []     lower = (2 * np.pi / num_vertices) - irregularity     upper = (2 * np.pi / num_vertices) + irregularity     sum = 0     for _ in range(num_vertices):         tmp = random.uniform(lower, upper)         angle_steps.append(tmp)         sum += tmp      # Normalize the steps so that the sum is 2*pi     k = sum / (2 * np.pi)     for i in range(num_vertices):         angle_steps[i] /= k      # Generate the points     points = []     angle = random.uniform(0, 2 * np.pi)     for i in range(num_vertices):         r_i = np.clip(random.gauss(avg_radius, spikiness), 0, 2 * avg_radius)         x = center[0] + r_i * np.cos(angle)         y = center[1] + r_i * np.sin(angle)         points.append((x, y))         angle += angle_steps[i]      return points  # Function to generate the tiling def generate_tiling(     shape_types=['Circle', 'Square', 'Triangle', 'Polygon'],     A_plane=100.0,     A0=1.0,     p=2.0,     n_shapes=200,     max_particle_size=5.0,     random_orientation=True,     polygon_sides=6,     irregularity=0.0,     spikiness=0.0 ):     # Calculate c using the Riemann zeta function     zeta_p = zeta(p)     c = A0 * zeta_p / (A_plane - A0)          # Generate areas for each shape     areas = [A0]     i = 1     while len(areas) &lt; n_shapes:         area = A0 / ((i**p) * c)         if area &lt;= 0:             break         size = np.sqrt(area / np.pi) if 'Circle' in shape_types else np.sqrt(area)         if size &gt; max_particle_size:             i += 1             continue         areas.append(area)         i += 1          # Shuffle the areas to distribute sizes among shapes     random.shuffle(areas)          # Assign areas to shapes     shape_assignments = []     sizes_list = []     for area in areas:         shape = random.choice(shape_types)         if shape == 'Circle':             size = np.sqrt(area / np.pi)  # Radius         else:             size = np.sqrt(area)  # Side length for squares and triangles         sizes_list.append(size)         shape_assignments.append(shape)          # Define the plane dimensions (square)     L = np.sqrt(A_plane)  # Length of the side of the square plane          # Initialize list to store positions and sizes of the shapes     positions = []          # Function to check if a new shape overlaps with existing ones     def is_overlapping(x_new, y_new, size_new, shape_new, positions):         # Approximate the shape with a circle for overlap checking         if shape_new == 'Circle':             radius_new = size_new         elif shape_new == 'Polygon':             radius_new = size_new  # Approximate radius for polygons         else:             radius_new = size_new * np.sqrt(2) / 2  # For squares and triangles         for x, y, size, shape, angle, params in positions:             if shape == 'Circle':                 radius = size             elif shape == 'Polygon':                 radius = size             else:                 radius = size * np.sqrt(2) / 2             distance = np.hypot(x_new - x, y_new - y)             if distance &lt; (radius_new + radius):                 return True         return False          # Place the shapes randomly without overlapping     for idx, (size, shape_type) in enumerate(zip(sizes_list, shape_assignments)):         max_attempts = 1000         for attempt in range(max_attempts):             # Generate random position within the plane, ensuring the shape stays within bounds             x = random.uniform(size, L - size)             y = random.uniform(size, L - size)             angle = random.uniform(0, 360) if random_orientation else 0             # Check for overlap             if not is_overlapping(x, y, size, shape_type, positions):                 # For polygons, store additional parameters                 params = {}                 if shape_type == 'Polygon':                     params['num_vertices'] = polygon_sides                     params['irregularity'] = irregularity                     params['spikiness'] = spikiness                 else:                     params = None                 positions.append((x, y, size, shape_type, angle, params))                 break         else:             print(f\"Could not place a shape of size {size} without overlap after {max_attempts} attempts.\")             break          # Plot the shapes     fig, ax = plt.subplots(figsize=(8, 8))     for x, y, size, shape_type, angle, params in positions:         if shape_type == 'Circle':             shape = plt.Circle((x, y), size, edgecolor='blue', facecolor='lightblue', alpha=0.6)             shape.set_transform(                 plt.matplotlib.transforms.Affine2D().rotate_deg_around(x, y, angle) + ax.transData             )             ax.add_patch(shape)         elif shape_type == 'Square':             shape = patches.Rectangle(                 (x - size / 2, y - size / 2),                 size,                 size,                 angle=angle,                 edgecolor='green',                 facecolor='lightgreen',                 alpha=0.6             )             ax.add_patch(shape)         elif shape_type == 'Triangle':             # Equilateral triangle             h = size * np.sqrt(3) / 2             points = np.array([                 [x, y + 2 * h / 3],                 [x - size / 2, y - h / 3],                 [x + size / 2, y - h / 3]             ])             t = patches.Polygon(                 points,                 closed=True,                 edgecolor='red',                 facecolor='salmon',                 alpha=0.6             )             t.set_transform(                 plt.matplotlib.transforms.Affine2D().rotate_deg_around(x, y, angle) + ax.transData             )             ax.add_patch(t)         elif shape_type == 'Polygon':             num_vertices = params['num_vertices']             irregularity = params['irregularity']             spikiness = params['spikiness']             avg_radius = size             points = generate_polygon(                 center=(x, y),                 avg_radius=avg_radius,                 irregularity=irregularity,                 spikiness=spikiness,                 num_vertices=num_vertices             )             poly = patches.Polygon(                 points,                 closed=True,                 edgecolor='purple',                 facecolor='violet',                 alpha=0.6             )             ax.add_patch(poly)         else:             continue          # Set plot parameters     ax.set_xlim(0, L)     ax.set_ylim(0, L)     ax.set_aspect('equal', 'box')     title_shapes = ', '.join(shape_types)     ax.set_title(f'Iterative Tiling Using Riemann Zeta Function - {title_shapes}')     ax.set_xlabel('X-axis')     ax.set_ylabel('Y-axis')     plt.grid(True)     plt.show()      # Interactive widget function def interactive_tiling(     shape_types,     A_plane,     A0,     p,     n_shapes,     max_particle_size,     random_orientation,     polygon_sides,     irregularity,     spikiness ):     generate_tiling(         shape_types=list(shape_types),         A_plane=A_plane,         A0=A0,         p=p,         n_shapes=n_shapes,         max_particle_size=max_particle_size,         random_orientation=random_orientation,         polygon_sides=polygon_sides,         irregularity=irregularity,         spikiness=spikiness     )  # Create interactive sliders and widgets interact(     interactive_tiling,     shape_types=SelectMultiple(         options=['Circle', 'Square', 'Triangle', 'Polygon'],         value=['Circle', 'Square', 'Triangle', 'Polygon'],         description='Shape Types'     ),     A_plane=FloatSlider(value=100.0, min=50.0, max=500.0, step=10.0, description='Plane Area'),     A0=FloatSlider(value=1.0, min=0.1, max=10.0, step=0.1, description='Initial Area A0'),     p=FloatSlider(value=2.0, min=1.1, max=5.0, step=0.1, description='Exponent p'),     n_shapes=IntSlider(value=200, min=50, max=1000, step=50, description='Number of Shapes'),     max_particle_size=FloatSlider(value=5.0, min=0.5, max=20.0, step=0.5, description='Max Particle Size'),     random_orientation=Checkbox(value=True, description='Random Orientation'),     polygon_sides=IntSlider(value=6, min=3, max=12, step=1, description='Polygon Sides'),     irregularity=FloatSlider(value=0.0, min=0.0, max=1.0, step=0.05, description='Irregularity'),     spikiness=FloatSlider(value=0.0, min=0.0, max=1.0, step=0.05, description='Spikiness') )  <pre>Could not place a shape of size 4.376918031368705 without overlap after 1000 attempts.\n</pre> <pre>interactive(children=(SelectMultiple(description='Shape Types', index=(0, 1, 2, 3), options=('Circle', 'Square\u2026</pre> Out[3]: <pre>&lt;function __main__.interactive_tiling(shape_types, A_plane, A0, p, n_shapes, max_particle_size, random_orientation, polygon_sides, irregularity, spikiness)&gt;</pre> In\u00a0[3]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nfrom scipy.special import zeta\nimport random\nfrom ipywidgets import interact, FloatSlider, IntSlider, Dropdown, Checkbox\n</pre> import numpy as np import matplotlib.pyplot as plt import matplotlib.patches as patches from scipy.special import zeta import random from ipywidgets import interact, FloatSlider, IntSlider, Dropdown, Checkbox  In\u00a0[2]: Copied! <pre># Function to generate the tiling\ndef generate_tiling(\n    shape_type='Circle',\n    A_plane=100.0,\n    A0=1.0,\n    p=2.0,\n    n_shapes=200,\n    max_particle_size=5.0,\n    random_orientation=True\n):\n    # Calculate c using the Riemann zeta function\n    zeta_p = zeta(p)\n    c = A0 * zeta_p / (A_plane - A0)\n    \n    # Generate areas for each shape\n    areas = [A0]\n    i = 1\n    while len(areas) &lt; n_shapes:\n        area = A0 / ((i**p) * c)\n        if area &lt;= 0 or np.sqrt(area) &gt; max_particle_size:\n            i += 1\n            continue\n        areas.append(area)\n        i += 1\n\n    # Compute dimensions of the shapes\n    if shape_type == 'Circle':\n        sizes = [np.sqrt(area / np.pi) for area in areas]  # Radii\n    else:\n        sizes = [np.sqrt(area) for area in areas]  # Side lengths for squares and triangles\n\n    # Define the plane dimensions (square)\n    L = np.sqrt(A_plane)  # Length of the side of the square plane\n\n    # Initialize list to store positions and sizes of the shapes\n    positions = []\n\n    # Function to check if a new shape overlaps with existing ones\n    def is_overlapping(x_new, y_new, size_new, positions):\n        for x, y, size, angle in positions:\n            if shape_type == 'Circle':\n                distance = np.hypot(x_new - x, y_new - y)\n                if distance &lt; (size_new + size):\n                    return True\n            else:\n                # Approximate the shapes with circles for overlap checking\n                distance = np.hypot(x_new - x, y_new - y)\n                radius_new = size_new * np.sqrt(2) / 2\n                radius = size * np.sqrt(2) / 2\n                if distance &lt; (radius_new + radius):\n                    return True\n        return False\n\n    # Place the shapes randomly without overlapping\n    for size in sizes:\n        max_attempts = 1000\n        for attempt in range(max_attempts):\n            # Generate random position within the plane, ensuring the shape stays within bounds\n            x = random.uniform(size, L - size)\n            y = random.uniform(size, L - size)\n            angle = random.uniform(0, 360) if random_orientation else 0\n            # Check for overlap\n            if not is_overlapping(x, y, size, positions):\n                positions.append((x, y, size, angle))\n                break\n        else:\n            print(f\"Could not place a shape of size {size} without overlap after {max_attempts} attempts.\")\n            break\n\n    # Plot the shapes\n    fig, ax = plt.subplots(figsize=(8, 8))\n    for x, y, size, angle in positions:\n        if shape_type == 'Circle':\n            shape = plt.Circle((x, y), size, edgecolor='blue', facecolor='lightblue', alpha=0.6)\n        elif shape_type == 'Square':\n            shape = patches.Rectangle(\n                (x - size / 2, y - size / 2),\n                size,\n                size,\n                angle=angle,\n                edgecolor='green',\n                facecolor='lightgreen',\n                alpha=0.6\n            )\n        elif shape_type == 'Triangle':\n            # Equilateral triangle\n            h = size * np.sqrt(3) / 2\n            points = np.array([\n                [x, y + 2 * h / 3],\n                [x - size / 2, y - h / 3],\n                [x + size / 2, y - h / 3]\n            ])\n            t = patches.Polygon(\n                points,\n                closed=True,\n                edgecolor='red',\n                facecolor='salmon',\n                alpha=0.6\n            )\n            shape = t\n            shape.set_transform(\n                plt.matplotlib.transforms.Affine2D().rotate_deg_around(x, y, angle) + ax.transData\n            )\n        else:\n            continue\n\n        if shape_type in ['Circle', 'Square']:\n            shape.set_transform(\n                plt.matplotlib.transforms.Affine2D().rotate_deg_around(x, y, angle) + ax.transData\n            )\n            ax.add_patch(shape)\n        elif shape_type == 'Triangle':\n            ax.add_patch(shape)\n\n    # Set plot parameters\n    ax.set_xlim(0, L)\n    ax.set_ylim(0, L)\n    ax.set_aspect('equal', 'box')\n    ax.set_title(f'Iterative Tiling Using Riemann Zeta Function - {shape_type}s')\n    ax.set_xlabel('X-axis')\n    ax.set_ylabel('Y-axis')\n    plt.grid(True)\n    plt.show()\n\n# Interactive widget function\ndef interactive_tiling(\n    shape_type,\n    A_plane,\n    A0,\n    p,\n    n_shapes,\n    max_particle_size,\n    random_orientation\n):\n    generate_tiling(\n        shape_type=shape_type,\n        A_plane=A_plane,\n        A0=A0,\n        p=p,\n        n_shapes=n_shapes,\n        max_particle_size=max_particle_size,\n        random_orientation=random_orientation\n    )\n\n# Create interactive sliders and dropdowns\ninteract(\n    interactive_tiling,\n    shape_type=Dropdown(options=['Circle', 'Square', 'Triangle'], value='Circle', description='Shape Type'),\n    A_plane=FloatSlider(value=100.0, min=50.0, max=50000.0, step=100.0, description='Plane Area'),\n    A0=FloatSlider(value=1.0, min=0.1, max=100.0, step=0.01, description='Initial Area A0'),\n    p=FloatSlider(value=1.56, min=1.01, max=2.0, step=0.01, description='Exponent p'),\n    n_shapes=IntSlider(value=20000, min=50, max=1000000, step=50, description='Number of Shapes'),\n    max_particle_size=FloatSlider(value=5.0, min=0.5, max=20.0, step=0.5, description='Max Particle Size'),\n    random_orientation=Checkbox(value=True, description='Random Orientation')\n)\n</pre>  # Function to generate the tiling def generate_tiling(     shape_type='Circle',     A_plane=100.0,     A0=1.0,     p=2.0,     n_shapes=200,     max_particle_size=5.0,     random_orientation=True ):     # Calculate c using the Riemann zeta function     zeta_p = zeta(p)     c = A0 * zeta_p / (A_plane - A0)          # Generate areas for each shape     areas = [A0]     i = 1     while len(areas) &lt; n_shapes:         area = A0 / ((i**p) * c)         if area &lt;= 0 or np.sqrt(area) &gt; max_particle_size:             i += 1             continue         areas.append(area)         i += 1      # Compute dimensions of the shapes     if shape_type == 'Circle':         sizes = [np.sqrt(area / np.pi) for area in areas]  # Radii     else:         sizes = [np.sqrt(area) for area in areas]  # Side lengths for squares and triangles      # Define the plane dimensions (square)     L = np.sqrt(A_plane)  # Length of the side of the square plane      # Initialize list to store positions and sizes of the shapes     positions = []      # Function to check if a new shape overlaps with existing ones     def is_overlapping(x_new, y_new, size_new, positions):         for x, y, size, angle in positions:             if shape_type == 'Circle':                 distance = np.hypot(x_new - x, y_new - y)                 if distance &lt; (size_new + size):                     return True             else:                 # Approximate the shapes with circles for overlap checking                 distance = np.hypot(x_new - x, y_new - y)                 radius_new = size_new * np.sqrt(2) / 2                 radius = size * np.sqrt(2) / 2                 if distance &lt; (radius_new + radius):                     return True         return False      # Place the shapes randomly without overlapping     for size in sizes:         max_attempts = 1000         for attempt in range(max_attempts):             # Generate random position within the plane, ensuring the shape stays within bounds             x = random.uniform(size, L - size)             y = random.uniform(size, L - size)             angle = random.uniform(0, 360) if random_orientation else 0             # Check for overlap             if not is_overlapping(x, y, size, positions):                 positions.append((x, y, size, angle))                 break         else:             print(f\"Could not place a shape of size {size} without overlap after {max_attempts} attempts.\")             break      # Plot the shapes     fig, ax = plt.subplots(figsize=(8, 8))     for x, y, size, angle in positions:         if shape_type == 'Circle':             shape = plt.Circle((x, y), size, edgecolor='blue', facecolor='lightblue', alpha=0.6)         elif shape_type == 'Square':             shape = patches.Rectangle(                 (x - size / 2, y - size / 2),                 size,                 size,                 angle=angle,                 edgecolor='green',                 facecolor='lightgreen',                 alpha=0.6             )         elif shape_type == 'Triangle':             # Equilateral triangle             h = size * np.sqrt(3) / 2             points = np.array([                 [x, y + 2 * h / 3],                 [x - size / 2, y - h / 3],                 [x + size / 2, y - h / 3]             ])             t = patches.Polygon(                 points,                 closed=True,                 edgecolor='red',                 facecolor='salmon',                 alpha=0.6             )             shape = t             shape.set_transform(                 plt.matplotlib.transforms.Affine2D().rotate_deg_around(x, y, angle) + ax.transData             )         else:             continue          if shape_type in ['Circle', 'Square']:             shape.set_transform(                 plt.matplotlib.transforms.Affine2D().rotate_deg_around(x, y, angle) + ax.transData             )             ax.add_patch(shape)         elif shape_type == 'Triangle':             ax.add_patch(shape)      # Set plot parameters     ax.set_xlim(0, L)     ax.set_ylim(0, L)     ax.set_aspect('equal', 'box')     ax.set_title(f'Iterative Tiling Using Riemann Zeta Function - {shape_type}s')     ax.set_xlabel('X-axis')     ax.set_ylabel('Y-axis')     plt.grid(True)     plt.show()  # Interactive widget function def interactive_tiling(     shape_type,     A_plane,     A0,     p,     n_shapes,     max_particle_size,     random_orientation ):     generate_tiling(         shape_type=shape_type,         A_plane=A_plane,         A0=A0,         p=p,         n_shapes=n_shapes,         max_particle_size=max_particle_size,         random_orientation=random_orientation     )  # Create interactive sliders and dropdowns interact(     interactive_tiling,     shape_type=Dropdown(options=['Circle', 'Square', 'Triangle'], value='Circle', description='Shape Type'),     A_plane=FloatSlider(value=100.0, min=50.0, max=50000.0, step=100.0, description='Plane Area'),     A0=FloatSlider(value=1.0, min=0.1, max=100.0, step=0.01, description='Initial Area A0'),     p=FloatSlider(value=1.56, min=1.01, max=2.0, step=0.01, description='Exponent p'),     n_shapes=IntSlider(value=20000, min=50, max=1000000, step=50, description='Number of Shapes'),     max_particle_size=FloatSlider(value=5.0, min=0.5, max=20.0, step=0.5, description='Max Particle Size'),     random_orientation=Checkbox(value=True, description='Random Orientation') )  <pre>interactive(children=(Dropdown(description='Shape Type', options=('Circle', 'Square', 'Triangle'), value='Circ\u2026</pre> Out[2]: <pre>&lt;function __main__.interactive_tiling(shape_type, A_plane, A0, p, n_shapes, max_particle_size, random_orientation)&gt;</pre>"},{"location":"notebooks/zeta_space/#explanation-of-the-new-features","title":"Explanation of the New Features\u00b6","text":""},{"location":"notebooks/zeta_space/#1-multiple-shape-types","title":"1. Multiple Shape Types\u00b6","text":"<ul> <li><p>Implementation:</p> <ul> <li>Changed <code>shape_type</code> to <code>shape_types</code>, which is a list of selected shape types.</li> <li>Used a <code>SelectMultiple</code> widget to allow multiple selections.</li> <li>When assigning areas to shapes, the code randomly selects a shape type from the chosen list for each shape.</li> </ul> </li> <li><p>Purpose:</p> <ul> <li>Allows you to include a mix of shapes in the tiling.</li> <li>Adds diversity and complexity to the patterns generated.</li> </ul> </li> </ul>"},{"location":"notebooks/zeta_space/#2-random-shape-selection","title":"2. Random Shape Selection\u00b6","text":"<ul> <li><p>Assignment of Areas:</p> <ul> <li>The areas calculated are shuffled to distribute different sizes among the shapes.</li> <li>For each area, a shape type is randomly selected from the chosen list.</li> </ul> </li> <li><p>Placement and Drawing:</p> <ul> <li>The code handles the drawing of each shape according to its type.</li> <li>Overlap checking is adjusted to account for different shape types.</li> </ul> </li> </ul>"},{"location":"notebooks/zeta_space/#3-overlap-checking-adjustments","title":"3. Overlap Checking Adjustments\u00b6","text":"<ul> <li><p>Mixed Shapes:</p> <ul> <li>The <code>is_overlapping</code> function is updated to handle different shape types.</li> <li>Shapes are approximated as circles for overlap checking to simplify collision detection.</li> </ul> </li> <li><p>Radius Calculation:</p> <ul> <li>For circles, the radius is straightforward.</li> <li>For squares and triangles, the code calculates an equivalent radius by approximating the shape's bounding circle.</li> </ul> </li> </ul>"},{"location":"notebooks/zeta_space/#additional-notes","title":"Additional Notes\u00b6","text":"<ul> <li><p>Shuffle Areas:</p> <ul> <li>Shuffling the list of areas ensures that sizes are randomly distributed among the shapes, preventing patterns where certain shapes only have large or small sizes.</li> </ul> </li> <li><p>Shape-Specific Parameters:</p> <ul> <li>You can further customize the properties of each shape type if needed.</li> </ul> </li> <li><p>Performance Considerations:</p> <ul> <li>As the complexity increases with multiple shapes, the computation time may also increase.</li> <li>The code includes a maximum number of attempts to place each shape to prevent infinite loops.</li> </ul> </li> <li><p>Visualization:</p> <ul> <li>The plot title dynamically updates to reflect the selected shape types.</li> <li>Colors and styles are set differently for each shape type to distinguish them visually.</li> </ul> </li> </ul>"},{"location":"notebooks/zeta_space/#example-usage","title":"Example Usage\u00b6","text":"<ul> <li><p>Selecting All Shapes:</p> <ul> <li>By default, all shapes are selected, resulting in a tiling that includes circles, squares, and triangles.</li> </ul> </li> <li><p>Selecting Specific Shapes:</p> <ul> <li>You can select only 'Circle' and 'Square' to exclude triangles.</li> <li>Alternatively, select a single shape type to focus on that shape.</li> </ul> </li> <li><p>Adjusting Parameters:</p> <ul> <li>Modify the exponent <code>p</code> to see how it affects the size distribution.</li> <li>Change the maximum particle size to limit the size of the largest shapes.</li> <li>Toggle random orientation to see the difference between aligned and randomly rotated shapes.</li> </ul> </li> </ul> <p>Note: Ensure you have the necessary libraries installed (<code>numpy</code>, <code>matplotlib</code>, <code>scipy</code>, <code>ipywidgets</code>) and that you are running the code in an environment that supports interactive widgets.</p>"}]}