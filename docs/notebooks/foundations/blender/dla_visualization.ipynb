{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DLA Point Cloud Visualization\n",
    "\n",
    "This notebook provides tools for visualizing and analyzing 3D Diffusion-Limited Aggregation (DLA) point clouds exported from Blender.\n",
    "\n",
    "## Features\n",
    "- Interactive 3D visualization with Plotly\n",
    "- Fractal dimension analysis using box-counting method\n",
    "- Growth pattern analysis\n",
    "- Animation support for time-series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load DLA Data\n",
    "\n",
    "Load the exported DLA point cloud from Blender. Supports `.npz` format with positions, timepoints, and other attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dla_data(filepath):\n",
    "    \"\"\"\n",
    "    Load DLA point cloud from NumPy .npz file.\n",
    "    \n",
    "    Returns:\n",
    "        dict with positions, timepoints, colors, active, bounds, metadata\n",
    "    \"\"\"\n",
    "    data = np.load(filepath, allow_pickle=True)\n",
    "    \n",
    "    result = {\n",
    "        'positions': data['positions'],\n",
    "        'timepoints': data.get('timepoints', np.zeros(len(data['positions']))),\n",
    "        'colors': data.get('colors', np.zeros(len(data['positions']))),\n",
    "        'active': data.get('active', np.zeros(len(data['positions']), dtype=bool)),\n",
    "        'bounds': data.get('bounds', None),\n",
    "    }\n",
    "    \n",
    "    # Get metadata\n",
    "    for key in ['frame', 'total_frames', 'object_name', 'export_time']:\n",
    "        if key in data:\n",
    "            result[key] = data[key]\n",
    "    \n",
    "    return result\n",
    "\n",
    "def load_ply_data(filepath):\n",
    "    \"\"\"\n",
    "    Load DLA point cloud from PLY file.\n",
    "    \n",
    "    Returns:\n",
    "        dict with positions and timepoints\n",
    "    \"\"\"\n",
    "    positions = []\n",
    "    timepoints = []\n",
    "    colors = []\n",
    "    \n",
    "    with open(filepath, 'rb') as f:\n",
    "        # Read header\n",
    "        header_ended = False\n",
    "        is_binary = False\n",
    "        num_vertices = 0\n",
    "        \n",
    "        while not header_ended:\n",
    "            line = f.readline().decode('ascii').strip()\n",
    "            if line.startswith('format binary'):\n",
    "                is_binary = True\n",
    "            elif line.startswith('element vertex'):\n",
    "                num_vertices = int(line.split()[-1])\n",
    "            elif line == 'end_header':\n",
    "                header_ended = True\n",
    "        \n",
    "        # Read data\n",
    "        if is_binary:\n",
    "            import struct\n",
    "            for _ in range(num_vertices):\n",
    "                data = struct.unpack('<fffff', f.read(20))\n",
    "                positions.append(data[:3])\n",
    "                timepoints.append(data[3])\n",
    "                colors.append(data[4])\n",
    "        else:\n",
    "            for line in f:\n",
    "                parts = line.decode('ascii').strip().split()\n",
    "                if len(parts) >= 5:\n",
    "                    positions.append([float(parts[0]), float(parts[1]), float(parts[2])])\n",
    "                    timepoints.append(float(parts[3]))\n",
    "                    colors.append(float(parts[4]))\n",
    "    \n",
    "    return {\n",
    "        'positions': np.array(positions),\n",
    "        'timepoints': np.array(timepoints),\n",
    "        'colors': np.array(colors),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your exported DLA data\n",
    "# Update this path to point to your exported file\n",
    "DATA_PATH = \"/tmp/dla_export.npz\"  # or your custom path\n",
    "\n",
    "# Check if file exists, otherwise create sample data\n",
    "if os.path.exists(DATA_PATH):\n",
    "    dla_data = load_dla_data(DATA_PATH)\n",
    "    print(f\"Loaded {len(dla_data['positions'])} points from {DATA_PATH}\")\n",
    "else:\n",
    "    print(f\"File not found: {DATA_PATH}\")\n",
    "    print(\"Creating sample DLA data for demonstration...\")\n",
    "    \n",
    "    # Generate sample DLA-like data\n",
    "    np.random.seed(42)\n",
    "    n_points = 10000\n",
    "    \n",
    "    # Create branching structure\n",
    "    positions = []\n",
    "    timepoints = []\n",
    "    \n",
    "    # Seed point\n",
    "    positions.append([0, 0, 0])\n",
    "    timepoints.append(0)\n",
    "    \n",
    "    for i in range(1, n_points):\n",
    "        # Random walk from a random existing point\n",
    "        parent_idx = np.random.randint(0, len(positions))\n",
    "        parent = np.array(positions[parent_idx])\n",
    "        \n",
    "        # Add small random displacement\n",
    "        direction = np.random.randn(3)\n",
    "        direction = direction / np.linalg.norm(direction) * 0.05\n",
    "        \n",
    "        new_pos = parent + direction\n",
    "        positions.append(new_pos.tolist())\n",
    "        timepoints.append(i / n_points * 250)  # Normalize to frame range\n",
    "    \n",
    "    dla_data = {\n",
    "        'positions': np.array(positions),\n",
    "        'timepoints': np.array(timepoints),\n",
    "        'colors': np.random.rand(n_points),\n",
    "        'active': np.zeros(n_points, dtype=bool),\n",
    "    }\n",
    "    \n",
    "    print(f\"Generated {n_points} sample points\")\n",
    "\n",
    "# Display info\n",
    "positions = dla_data['positions']\n",
    "timepoints = dla_data['timepoints']\n",
    "\n",
    "print(f\"\\nData Summary:\")\n",
    "print(f\"  Points: {len(positions)}\")\n",
    "print(f\"  Position range:\")\n",
    "print(f\"    X: [{positions[:,0].min():.3f}, {positions[:,0].max():.3f}]\")\n",
    "print(f\"    Y: [{positions[:,1].min():.3f}, {positions[:,1].max():.3f}]\")\n",
    "print(f\"    Z: [{positions[:,2].min():.3f}, {positions[:,2].max():.3f}]\")\n",
    "print(f\"  Timepoint range: [{timepoints.min():.1f}, {timepoints.max():.1f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Interactive 3D Visualization\n",
    "\n",
    "Create an interactive 3D scatter plot with timepoint-based coloring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_dla_3d(positions, timepoints, title=\"DLA Point Cloud\", \n",
    "                     colorscale='Viridis', point_size=1, opacity=0.8,\n",
    "                     max_points=50000):\n",
    "    \"\"\"\n",
    "    Create interactive 3D visualization of DLA point cloud.\n",
    "    \n",
    "    Args:\n",
    "        positions: (N, 3) array of point coordinates\n",
    "        timepoints: (N,) array of timepoint values for coloring\n",
    "        title: Plot title\n",
    "        colorscale: Plotly colorscale name\n",
    "        point_size: Marker size\n",
    "        opacity: Marker opacity\n",
    "        max_points: Maximum points to display (for performance)\n",
    "    \n",
    "    Returns:\n",
    "        Plotly figure\n",
    "    \"\"\"\n",
    "    # Subsample if needed\n",
    "    if len(positions) > max_points:\n",
    "        indices = np.random.choice(len(positions), max_points, replace=False)\n",
    "        positions = positions[indices]\n",
    "        timepoints = timepoints[indices]\n",
    "        print(f\"Subsampled to {max_points} points for visualization\")\n",
    "    \n",
    "    fig = go.Figure(data=[go.Scatter3d(\n",
    "        x=positions[:, 0],\n",
    "        y=positions[:, 1],\n",
    "        z=positions[:, 2],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=point_size,\n",
    "            color=timepoints,\n",
    "            colorscale=colorscale,\n",
    "            opacity=opacity,\n",
    "            colorbar=dict(\n",
    "                title=\"Frame\",\n",
    "                thickness=20,\n",
    "            )\n",
    "        ),\n",
    "        hovertemplate=(\n",
    "            \"<b>Position</b><br>\"\n",
    "            \"X: %{x:.3f}<br>\"\n",
    "            \"Y: %{y:.3f}<br>\"\n",
    "            \"Z: %{z:.3f}<br>\"\n",
    "            \"Frame: %{marker.color:.0f}<br>\"\n",
    "            \"<extra></extra>\"\n",
    "        )\n",
    "    )])\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=dict(\n",
    "            text=title,\n",
    "            x=0.5,\n",
    "            font=dict(size=20)\n",
    "        ),\n",
    "        scene=dict(\n",
    "            xaxis_title=\"X\",\n",
    "            yaxis_title=\"Y\",\n",
    "            zaxis_title=\"Z\",\n",
    "            aspectmode='data',\n",
    "            bgcolor='rgb(20, 20, 30)',\n",
    "            xaxis=dict(gridcolor='gray', zerolinecolor='gray'),\n",
    "            yaxis=dict(gridcolor='gray', zerolinecolor='gray'),\n",
    "            zaxis=dict(gridcolor='gray', zerolinecolor='gray'),\n",
    "        ),\n",
    "        paper_bgcolor='rgb(30, 30, 40)',\n",
    "        font=dict(color='white'),\n",
    "        margin=dict(l=0, r=0, t=50, b=0),\n",
    "        width=900,\n",
    "        height=700,\n",
    "    )\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization\n",
    "fig = visualize_dla_3d(\n",
    "    dla_data['positions'],\n",
    "    dla_data['timepoints'],\n",
    "    title=\"3D DLA Point Cloud\",\n",
    "    colorscale='Viridis',\n",
    "    point_size=2\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fractal Dimension Analysis\n",
    "\n",
    "Estimate the fractal dimension using the box-counting method. For 3D DLA, the expected dimension is approximately D ≈ 2.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_counting_dimension(points, min_box=None, max_box=None, num_scales=20):\n",
    "    \"\"\"\n",
    "    Estimate fractal dimension using box-counting method.\n",
    "    \n",
    "    Args:\n",
    "        points: (N, 3) array of point coordinates\n",
    "        min_box: Minimum box size (default: auto from point density)\n",
    "        max_box: Maximum box size (default: bounding box diagonal)\n",
    "        num_scales: Number of scales to sample\n",
    "    \n",
    "    Returns:\n",
    "        dimension: Estimated fractal dimension\n",
    "        scales: Array of box sizes used\n",
    "        counts: Array of box counts at each scale\n",
    "        r_squared: R² value of the linear fit\n",
    "    \"\"\"\n",
    "    # Normalize points to [0, 1] range\n",
    "    points_min = points.min(axis=0)\n",
    "    points_max = points.max(axis=0)\n",
    "    extent = (points_max - points_min).max()\n",
    "    \n",
    "    if extent == 0:\n",
    "        return 0, [], [], 0\n",
    "    \n",
    "    normalized = (points - points_min) / extent\n",
    "    \n",
    "    # Set scale range\n",
    "    if min_box is None:\n",
    "        min_box = 0.01  # 1% of extent\n",
    "    if max_box is None:\n",
    "        max_box = 0.5  # 50% of extent\n",
    "    \n",
    "    scales = np.logspace(np.log10(min_box), np.log10(max_box), num_scales)\n",
    "    counts = []\n",
    "    \n",
    "    for scale in scales:\n",
    "        # Discretize points to grid\n",
    "        grid_points = np.floor(normalized / scale).astype(np.int32)\n",
    "        \n",
    "        # Count unique boxes\n",
    "        unique_boxes = len(set(map(tuple, grid_points)))\n",
    "        counts.append(unique_boxes)\n",
    "    \n",
    "    counts = np.array(counts)\n",
    "    \n",
    "    # Linear regression on log-log plot\n",
    "    log_scales = np.log(1 / scales)  # Use 1/scale for traditional box-counting\n",
    "    log_counts = np.log(counts)\n",
    "    \n",
    "    # Remove invalid entries\n",
    "    valid = np.isfinite(log_scales) & np.isfinite(log_counts)\n",
    "    log_scales = log_scales[valid]\n",
    "    log_counts = log_counts[valid]\n",
    "    scales = scales[valid]\n",
    "    counts = counts[valid]\n",
    "    \n",
    "    if len(log_scales) < 3:\n",
    "        return 0, scales, counts, 0\n",
    "    \n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(log_scales, log_counts)\n",
    "    \n",
    "    return slope, scales, counts, r_value ** 2\n",
    "\n",
    "\n",
    "def plot_box_counting_analysis(positions, title=\"Box-Counting Dimension Analysis\"):\n",
    "    \"\"\"\n",
    "    Create visualization of box-counting analysis.\n",
    "    \"\"\"\n",
    "    dimension, scales, counts, r_squared = box_counting_dimension(positions)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Log-log plot\n",
    "    ax1 = axes[0]\n",
    "    ax1.loglog(1/scales, counts, 'bo-', markersize=8, label='Data')\n",
    "    \n",
    "    # Fit line\n",
    "    log_x = np.log(1/scales)\n",
    "    log_y = np.log(counts)\n",
    "    slope, intercept = np.polyfit(log_x, log_y, 1)\n",
    "    fit_y = np.exp(slope * log_x + intercept)\n",
    "    ax1.loglog(1/scales, fit_y, 'r--', linewidth=2, \n",
    "               label=f'Fit: D = {dimension:.3f}')\n",
    "    \n",
    "    ax1.set_xlabel('1 / Box Size', fontsize=12)\n",
    "    ax1.set_ylabel('Number of Boxes', fontsize=12)\n",
    "    ax1.set_title('Box-Counting Analysis (Log-Log)', fontsize=14)\n",
    "    ax1.legend(fontsize=11)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Residuals\n",
    "    ax2 = axes[1]\n",
    "    residuals = log_y - (slope * log_x + intercept)\n",
    "    ax2.scatter(log_x, residuals, c='blue', alpha=0.7)\n",
    "    ax2.axhline(y=0, color='r', linestyle='--')\n",
    "    ax2.set_xlabel('log(1 / Box Size)', fontsize=12)\n",
    "    ax2.set_ylabel('Residuals', fontsize=12)\n",
    "    ax2.set_title(f'Residuals (R² = {r_squared:.4f})', fontsize=14)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle(title, fontsize=16, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig, dimension, r_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate fractal dimension\n",
    "fig, dimension, r_squared = plot_box_counting_analysis(\n",
    "    dla_data['positions'],\n",
    "    title=\"DLA Fractal Dimension Analysis\"\n",
    ")\n",
    "\n",
    "print(f\"\\nFractal Dimension Results:\")\n",
    "print(f\"  Estimated D = {dimension:.4f}\")\n",
    "print(f\"  R² = {r_squared:.4f}\")\n",
    "print(f\"\\n  Expected for 3D DLA: D ≈ 2.5\")\n",
    "print(f\"  Difference from expected: {abs(dimension - 2.5):.4f}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Growth Pattern Analysis\n",
    "\n",
    "Analyze how the DLA structure grows over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_growth_pattern(positions, timepoints, num_bins=50):\n",
    "    \"\"\"\n",
    "    Analyze DLA growth pattern over time.\n",
    "    \n",
    "    Returns metrics about growth rate, radius expansion, and density.\n",
    "    \"\"\"\n",
    "    # Sort by timepoint\n",
    "    order = np.argsort(timepoints)\n",
    "    sorted_positions = positions[order]\n",
    "    sorted_times = timepoints[order]\n",
    "    \n",
    "    # Calculate cumulative metrics\n",
    "    results = {\n",
    "        'time_bins': [],\n",
    "        'particle_count': [],\n",
    "        'max_radius': [],\n",
    "        'mean_radius': [],\n",
    "        'center_of_mass': [],\n",
    "    }\n",
    "    \n",
    "    time_bins = np.linspace(sorted_times.min(), sorted_times.max(), num_bins + 1)\n",
    "    \n",
    "    for i in range(num_bins):\n",
    "        t_start, t_end = time_bins[i], time_bins[i + 1]\n",
    "        mask = sorted_times <= t_end\n",
    "        \n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "        \n",
    "        subset = sorted_positions[mask]\n",
    "        \n",
    "        # Calculate metrics\n",
    "        radii = np.linalg.norm(subset, axis=1)\n",
    "        center = subset.mean(axis=0)\n",
    "        \n",
    "        results['time_bins'].append((t_start + t_end) / 2)\n",
    "        results['particle_count'].append(len(subset))\n",
    "        results['max_radius'].append(radii.max())\n",
    "        results['mean_radius'].append(radii.mean())\n",
    "        results['center_of_mass'].append(center)\n",
    "    \n",
    "    # Convert to arrays\n",
    "    for key in results:\n",
    "        results[key] = np.array(results[key])\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def plot_growth_analysis(growth_data):\n",
    "    \"\"\"\n",
    "    Create multi-panel plot of growth analysis.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    time = growth_data['time_bins']\n",
    "    \n",
    "    # Particle count\n",
    "    ax1 = axes[0, 0]\n",
    "    ax1.plot(time, growth_data['particle_count'], 'b-', linewidth=2)\n",
    "    ax1.fill_between(time, 0, growth_data['particle_count'], alpha=0.3)\n",
    "    ax1.set_xlabel('Frame', fontsize=12)\n",
    "    ax1.set_ylabel('Particle Count', fontsize=12)\n",
    "    ax1.set_title('Cumulative Particle Count', fontsize=14)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Radius expansion\n",
    "    ax2 = axes[0, 1]\n",
    "    ax2.plot(time, growth_data['max_radius'], 'r-', linewidth=2, label='Max Radius')\n",
    "    ax2.plot(time, growth_data['mean_radius'], 'g--', linewidth=2, label='Mean Radius')\n",
    "    ax2.set_xlabel('Frame', fontsize=12)\n",
    "    ax2.set_ylabel('Radius', fontsize=12)\n",
    "    ax2.set_title('Radius Expansion', fontsize=14)\n",
    "    ax2.legend(fontsize=11)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Growth rate (derivative of particle count)\n",
    "    ax3 = axes[1, 0]\n",
    "    growth_rate = np.gradient(growth_data['particle_count'], time)\n",
    "    ax3.plot(time, growth_rate, 'm-', linewidth=2)\n",
    "    ax3.set_xlabel('Frame', fontsize=12)\n",
    "    ax3.set_ylabel('Growth Rate (particles/frame)', fontsize=12)\n",
    "    ax3.set_title('Instantaneous Growth Rate', fontsize=14)\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Log-log plot of radius vs particles (for checking power law)\n",
    "    ax4 = axes[1, 1]\n",
    "    valid = (growth_data['max_radius'] > 0) & (growth_data['particle_count'] > 0)\n",
    "    if valid.sum() > 2:\n",
    "        log_r = np.log10(growth_data['max_radius'][valid])\n",
    "        log_n = np.log10(growth_data['particle_count'][valid])\n",
    "        \n",
    "        ax4.scatter(log_n, log_r, c='blue', alpha=0.7)\n",
    "        \n",
    "        # Fit line\n",
    "        slope, intercept = np.polyfit(log_n, log_r, 1)\n",
    "        fit_x = np.array([log_n.min(), log_n.max()])\n",
    "        fit_y = slope * fit_x + intercept\n",
    "        ax4.plot(fit_x, fit_y, 'r--', linewidth=2, \n",
    "                label=f'Slope = {slope:.3f} (1/D ≈ {1/slope:.3f})')\n",
    "        ax4.legend(fontsize=11)\n",
    "    \n",
    "    ax4.set_xlabel('log₁₀(Particle Count)', fontsize=12)\n",
    "    ax4.set_ylabel('log₁₀(Max Radius)', fontsize=12)\n",
    "    ax4.set_title('Power Law: R ~ N^(1/D)', fontsize=14)\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle('DLA Growth Pattern Analysis', fontsize=16, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze growth pattern\n",
    "growth_data = analyze_growth_pattern(\n",
    "    dla_data['positions'],\n",
    "    dla_data['timepoints']\n",
    ")\n",
    "\n",
    "fig = plot_growth_analysis(growth_data)\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nGrowth Summary:\")\n",
    "print(f\"  Final particle count: {growth_data['particle_count'][-1]:.0f}\")\n",
    "print(f\"  Final max radius: {growth_data['max_radius'][-1]:.4f}\")\n",
    "print(f\"  Final mean radius: {growth_data['mean_radius'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Cross-Section Views\n",
    "\n",
    "View 2D slices through the 3D structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cross_sections(positions, timepoints, slice_thickness=0.1):\n",
    "    \"\"\"\n",
    "    Plot XY, XZ, and YZ cross-sections through the center of the structure.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "    \n",
    "    center = positions.mean(axis=0)\n",
    "    \n",
    "    # XY plane (Z ≈ center)\n",
    "    mask_xy = np.abs(positions[:, 2] - center[2]) < slice_thickness\n",
    "    axes[0].scatter(\n",
    "        positions[mask_xy, 0], positions[mask_xy, 1],\n",
    "        c=timepoints[mask_xy], cmap='viridis', s=1, alpha=0.8\n",
    "    )\n",
    "    axes[0].set_xlabel('X')\n",
    "    axes[0].set_ylabel('Y')\n",
    "    axes[0].set_title(f'XY Plane (Z ≈ {center[2]:.2f})')\n",
    "    axes[0].set_aspect('equal')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # XZ plane (Y ≈ center)\n",
    "    mask_xz = np.abs(positions[:, 1] - center[1]) < slice_thickness\n",
    "    axes[1].scatter(\n",
    "        positions[mask_xz, 0], positions[mask_xz, 2],\n",
    "        c=timepoints[mask_xz], cmap='viridis', s=1, alpha=0.8\n",
    "    )\n",
    "    axes[1].set_xlabel('X')\n",
    "    axes[1].set_ylabel('Z')\n",
    "    axes[1].set_title(f'XZ Plane (Y ≈ {center[1]:.2f})')\n",
    "    axes[1].set_aspect('equal')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # YZ plane (X ≈ center)\n",
    "    mask_yz = np.abs(positions[:, 0] - center[0]) < slice_thickness\n",
    "    sc = axes[2].scatter(\n",
    "        positions[mask_yz, 1], positions[mask_yz, 2],\n",
    "        c=timepoints[mask_yz], cmap='viridis', s=1, alpha=0.8\n",
    "    )\n",
    "    axes[2].set_xlabel('Y')\n",
    "    axes[2].set_ylabel('Z')\n",
    "    axes[2].set_title(f'YZ Plane (X ≈ {center[0]:.2f})')\n",
    "    axes[2].set_aspect('equal')\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Colorbar\n",
    "    plt.colorbar(sc, ax=axes, label='Frame', shrink=0.8)\n",
    "    \n",
    "    plt.suptitle('Cross-Section Views (2D Slices)', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cross-sections\n",
    "fig = plot_cross_sections(\n",
    "    dla_data['positions'],\n",
    "    dla_data['timepoints'],\n",
    "    slice_thickness=0.1\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Alternative Colorscales\n",
    "\n",
    "Visualize with different color mappings to highlight different features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots with different colorscales\n",
    "colorscales = ['Viridis', 'Plasma', 'Turbo', 'Hot']\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=[f'{cs} Colorscale' for cs in colorscales],\n",
    "    specs=[[{'type': 'scatter3d'}, {'type': 'scatter3d'}],\n",
    "           [{'type': 'scatter3d'}, {'type': 'scatter3d'}]]\n",
    ")\n",
    "\n",
    "# Subsample for performance\n",
    "max_points = 10000\n",
    "if len(dla_data['positions']) > max_points:\n",
    "    indices = np.random.choice(len(dla_data['positions']), max_points, replace=False)\n",
    "    pos = dla_data['positions'][indices]\n",
    "    times = dla_data['timepoints'][indices]\n",
    "else:\n",
    "    pos = dla_data['positions']\n",
    "    times = dla_data['timepoints']\n",
    "\n",
    "for i, cs in enumerate(colorscales):\n",
    "    row = i // 2 + 1\n",
    "    col = i % 2 + 1\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter3d(\n",
    "            x=pos[:, 0],\n",
    "            y=pos[:, 1],\n",
    "            z=pos[:, 2],\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size=2,\n",
    "                color=times,\n",
    "                colorscale=cs,\n",
    "                opacity=0.8,\n",
    "            ),\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=row, col=col\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    height=800,\n",
    "    width=1000,\n",
    "    title_text=\"DLA Visualization with Different Colorscales\",\n",
    "    paper_bgcolor='rgb(30, 30, 40)',\n",
    "    font=dict(color='white'),\n",
    ")\n",
    "\n",
    "# Update all scenes\n",
    "for i in range(1, 5):\n",
    "    scene_name = f'scene{i}' if i > 1 else 'scene'\n",
    "    fig.update_layout(**{\n",
    "        scene_name: dict(\n",
    "            bgcolor='rgb(20, 20, 30)',\n",
    "            aspectmode='data'\n",
    "        )\n",
    "    })\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Export Analysis Results\n",
    "\n",
    "Save analysis results for documentation or further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_analysis_report(dla_data, output_path=None):\n",
    "    \"\"\"\n",
    "    Generate a comprehensive analysis report.\n",
    "    \"\"\"\n",
    "    positions = dla_data['positions']\n",
    "    timepoints = dla_data['timepoints']\n",
    "    \n",
    "    # Calculate all metrics\n",
    "    dimension, scales, counts, r_squared = box_counting_dimension(positions)\n",
    "    growth_data = analyze_growth_pattern(positions, timepoints)\n",
    "    \n",
    "    # Radial analysis\n",
    "    radii = np.linalg.norm(positions, axis=1)\n",
    "    \n",
    "    report = {\n",
    "        'basic_stats': {\n",
    "            'total_points': len(positions),\n",
    "            'bounds_min': positions.min(axis=0).tolist(),\n",
    "            'bounds_max': positions.max(axis=0).tolist(),\n",
    "            'center_of_mass': positions.mean(axis=0).tolist(),\n",
    "        },\n",
    "        'radial_stats': {\n",
    "            'min_radius': float(radii.min()),\n",
    "            'max_radius': float(radii.max()),\n",
    "            'mean_radius': float(radii.mean()),\n",
    "            'std_radius': float(radii.std()),\n",
    "        },\n",
    "        'fractal_analysis': {\n",
    "            'box_counting_dimension': float(dimension),\n",
    "            'r_squared': float(r_squared),\n",
    "            'expected_dla_dimension': 2.5,\n",
    "            'deviation_from_expected': float(abs(dimension - 2.5)),\n",
    "        },\n",
    "        'growth_metrics': {\n",
    "            'final_particle_count': int(growth_data['particle_count'][-1]),\n",
    "            'final_max_radius': float(growth_data['max_radius'][-1]),\n",
    "            'final_mean_radius': float(growth_data['mean_radius'][-1]),\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Print report\n",
    "    print(\"=\" * 60)\n",
    "    print(\"DLA ANALYSIS REPORT\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for section, data in report.items():\n",
    "        print(f\"\\n{section.upper().replace('_', ' ')}:\")\n",
    "        for key, value in data.items():\n",
    "            if isinstance(value, float):\n",
    "                print(f\"  {key}: {value:.6f}\")\n",
    "            elif isinstance(value, list):\n",
    "                print(f\"  {key}: [{', '.join(f'{v:.4f}' for v in value)}]\")\n",
    "            else:\n",
    "                print(f\"  {key}: {value}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    \n",
    "    # Save to file if requested\n",
    "    if output_path:\n",
    "        import json\n",
    "        with open(output_path, 'w') as f:\n",
    "            json.dump(report, f, indent=2)\n",
    "        print(f\"Report saved to: {output_path}\")\n",
    "    \n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and display report\n",
    "report = generate_analysis_report(dla_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
