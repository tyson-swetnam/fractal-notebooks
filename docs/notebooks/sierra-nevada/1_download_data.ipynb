{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Download LAZ Data - Sierra Nevada Giant Forest\n",
    "\n",
    "This notebook downloads LiDAR point cloud data (LAZ format) from the USGS 3DEP program for the Giant Forest area in Sequoia National Park.\n",
    "\n",
    "**Data Source:** [USGS 3DEP - CA Sierra Nevada 2022](https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/CA_SierraNevada_B22/CA_SierraNevada_9_2022/)\n",
    "\n",
    "**Target Area:** Giant Forest, Sequoia National Park\n",
    "- Center: 36.56°N, -118.75°W\n",
    "- Contains General Sherman Tree (world's largest tree by volume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import requests\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from pyproj import Transformer\n",
    "\n",
    "# Data directories\n",
    "DATA_ROOT = Path.home() / \"data-store\" / \"data\" / \"output\" / \"sierra-nevada\"\n",
    "RAW_DIR = DATA_ROOT / \"raw\"\n",
    "LAZ_DIR = RAW_DIR / \"laz\"\n",
    "\n",
    "# Ensure directories exist\n",
    "LAZ_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# USGS source\n",
    "BASE_URL = \"https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/CA_SierraNevada_B22/CA_SierraNevada_9_2022\"\n",
    "\n",
    "print(f\"Data root: {DATA_ROOT}\")\n",
    "print(f\"LAZ directory: {LAZ_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Target Area: Giant Forest\n",
    "\n",
    "The Giant Forest area in Sequoia National Park. We'll define a bounding box that captures:\n",
    "- General Sherman Tree\n",
    "- Congress Trail area\n",
    "- Crescent Meadow\n",
    "- Giant Forest Museum area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Giant Forest bounding box in WGS84 (lat/lon)\n",
    "BBOX_WGS84 = {\n",
    "    \"north\": 36.60,   # North boundary\n",
    "    \"south\": 36.52,   # South boundary\n",
    "    \"east\": -118.70,  # East boundary\n",
    "    \"west\": -118.80   # West boundary\n",
    "}\n",
    "\n",
    "# Key landmarks (for reference)\n",
    "LANDMARKS = {\n",
    "    \"General Sherman Tree\": (36.5819, -118.7514),\n",
    "    \"Giant Forest Museum\": (36.5642, -118.7511),\n",
    "    \"Moro Rock\": (36.5458, -118.7647),\n",
    "    \"Crescent Meadow\": (36.5536, -118.7450),\n",
    "    \"Congress Trail\": (36.5800, -118.7550)\n",
    "}\n",
    "\n",
    "print(f\"Bounding box (WGS84):\")\n",
    "print(f\"  North: {BBOX_WGS84['north']}°N\")\n",
    "print(f\"  South: {BBOX_WGS84['south']}°N\")\n",
    "print(f\"  East: {BBOX_WGS84['east']}°W\")\n",
    "print(f\"  West: {BBOX_WGS84['west']}°W\")\n",
    "print(f\"\\nArea: ~{abs(BBOX_WGS84['north']-BBOX_WGS84['south'])*111:.1f}km x ~{abs(BBOX_WGS84['east']-BBOX_WGS84['west'])*111*np.cos(np.radians(36.56)):.1f}km\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to UTM Zone 11N (EPSG:32611) for tile matching\n",
    "transformer = Transformer.from_crs(\"EPSG:4326\", \"EPSG:32611\", always_xy=True)\n",
    "\n",
    "# Convert corners to UTM\n",
    "west_utm, south_utm = transformer.transform(BBOX_WGS84[\"west\"], BBOX_WGS84[\"south\"])\n",
    "east_utm, north_utm = transformer.transform(BBOX_WGS84[\"east\"], BBOX_WGS84[\"north\"])\n",
    "\n",
    "BBOX_UTM = {\n",
    "    \"min_easting\": west_utm,\n",
    "    \"max_easting\": east_utm,\n",
    "    \"min_northing\": south_utm,\n",
    "    \"max_northing\": north_utm\n",
    "}\n",
    "\n",
    "print(f\"Bounding box (UTM Zone 11N / EPSG:32611):\")\n",
    "print(f\"  Easting: {BBOX_UTM['min_easting']:.0f} to {BBOX_UTM['max_easting']:.0f}\")\n",
    "print(f\"  Northing: {BBOX_UTM['min_northing']:.0f} to {BBOX_UTM['max_northing']:.0f}\")\n",
    "\n",
    "# Convert landmarks to UTM\n",
    "print(\"\\nLandmarks in UTM:\")\n",
    "for name, (lat, lon) in LANDMARKS.items():\n",
    "    e, n = transformer.transform(lon, lat)\n",
    "    print(f\"  {name}: E={e:.0f}, N={n:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and Parse File List\n",
    "\n",
    "Download the master file list to identify available tiles and their naming convention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download file list\n",
    "file_list_path = RAW_DIR / \"0_file_download_links.txt\"\n",
    "\n",
    "if not file_list_path.exists():\n",
    "    print(\"Downloading file list...\")\n",
    "    url = f\"{BASE_URL}/0_file_download_links.txt\"\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    file_list_path.write_text(response.text)\n",
    "    print(f\"Downloaded to {file_list_path}\")\n",
    "else:\n",
    "    print(f\"File list already exists: {file_list_path}\")\n",
    "\n",
    "# Read file list\n",
    "with open(file_list_path, 'r') as f:\n",
    "    all_links = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "print(f\"Total links in file: {len(all_links)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for LAZ files only\n",
    "laz_links = [link for link in all_links if link.endswith('.laz')]\n",
    "print(f\"Total LAZ files available: {len(laz_links)}\")\n",
    "\n",
    "# Show sample filenames to understand naming convention\n",
    "print(\"\\nSample LAZ filenames:\")\n",
    "for link in laz_links[:10]:\n",
    "    print(f\"  {os.path.basename(link)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze tile naming convention\n",
    "# Common patterns:\n",
    "# - USGS_LPC_<project>_<tileid>.laz\n",
    "# - Tile ID might be USNG grid (e.g., 11SKA1234) or UTM coordinates\n",
    "\n",
    "sample_names = [os.path.basename(link) for link in laz_links[:50]]\n",
    "\n",
    "# Try to extract coordinate patterns\n",
    "coord_pattern = re.compile(r'(\\d{6,7})_(\\d{7})')\n",
    "usng_pattern = re.compile(r'(\\d{2}[A-Z]{3})(\\d{4,5})(\\d{4,5})')\n",
    "\n",
    "print(\"Analyzing tile naming patterns...\\n\")\n",
    "\n",
    "for name in sample_names[:20]:\n",
    "    coord_match = coord_pattern.search(name)\n",
    "    usng_match = usng_pattern.search(name)\n",
    "    \n",
    "    if coord_match:\n",
    "        easting, northing = coord_match.groups()\n",
    "        print(f\"  {name}\")\n",
    "        print(f\"    -> UTM coords: E={easting}, N={northing}\")\n",
    "    elif usng_match:\n",
    "        zone, e, n = usng_match.groups()\n",
    "        print(f\"  {name}\")\n",
    "        print(f\"    -> USNG: {zone} {e} {n}\")\n",
    "    else:\n",
    "        print(f\"  {name} (pattern not matched)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Tiles for Giant Forest Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tile_coords(filename):\n",
    "    \"\"\"\n",
    "    Extract UTM coordinates from tile filename.\n",
    "    Handles multiple naming conventions.\n",
    "    Returns (easting, northing) or None if not parseable.\n",
    "    \"\"\"\n",
    "    # Pattern 1: UTM coordinates embedded in filename\n",
    "    # e.g., USGS_LPC_CA_SierraNevada_9_2022_333000_4045000.laz\n",
    "    coord_pattern = re.compile(r'(\\d{6})_(\\d{7})')\n",
    "    match = coord_pattern.search(filename)\n",
    "    if match:\n",
    "        return (int(match.group(1)), int(match.group(2)))\n",
    "    \n",
    "    # Pattern 2: USNG grid reference\n",
    "    # e.g., 11SKA3350045000.laz\n",
    "    usng_pattern = re.compile(r'11S[A-Z]{2}(\\d{5})(\\d{5})')\n",
    "    match = usng_pattern.search(filename)\n",
    "    if match:\n",
    "        # Convert USNG to UTM (approximate - USNG uses 100km grid)\n",
    "        e = int(match.group(1))\n",
    "        n = int(match.group(2))\n",
    "        # Need to add USNG grid zone offset (varies by grid square)\n",
    "        return (e, n)  # May need adjustment based on actual naming\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Build list of tiles with coordinates\n",
    "tiles_with_coords = []\n",
    "unmatched_tiles = []\n",
    "\n",
    "for link in laz_links:\n",
    "    filename = os.path.basename(link)\n",
    "    coords = extract_tile_coords(filename)\n",
    "    if coords:\n",
    "        tiles_with_coords.append({\n",
    "            'url': link,\n",
    "            'filename': filename,\n",
    "            'easting': coords[0],\n",
    "            'northing': coords[1]\n",
    "        })\n",
    "    else:\n",
    "        unmatched_tiles.append(filename)\n",
    "\n",
    "print(f\"Tiles with parsed coordinates: {len(tiles_with_coords)}\")\n",
    "print(f\"Tiles with unmatched patterns: {len(unmatched_tiles)}\")\n",
    "\n",
    "if unmatched_tiles:\n",
    "    print(f\"\\nSample unmatched tiles:\")\n",
    "    for t in unmatched_tiles[:5]:\n",
    "        print(f\"  {t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze coordinate ranges to understand tile coverage\n",
    "if tiles_with_coords:\n",
    "    eastings = [t['easting'] for t in tiles_with_coords]\n",
    "    northings = [t['northing'] for t in tiles_with_coords]\n",
    "    \n",
    "    print(f\"Dataset coordinate ranges:\")\n",
    "    print(f\"  Easting: {min(eastings):,} to {max(eastings):,}\")\n",
    "    print(f\"  Northing: {min(northings):,} to {max(northings):,}\")\n",
    "    \n",
    "    print(f\"\\nTarget area (Giant Forest):\")\n",
    "    print(f\"  Easting: {BBOX_UTM['min_easting']:,.0f} to {BBOX_UTM['max_easting']:,.0f}\")\n",
    "    print(f\"  Northing: {BBOX_UTM['min_northing']:,.0f} to {BBOX_UTM['max_northing']:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter tiles that intersect our bounding box\n",
    "# Add buffer for tile size (typically 1000m x 1000m)\n",
    "TILE_SIZE = 1000  # meters\n",
    "BUFFER = TILE_SIZE  # Include adjacent tiles\n",
    "\n",
    "def tile_intersects_bbox(tile, bbox, tile_size=1000):\n",
    "    \"\"\"Check if a tile intersects the bounding box.\"\"\"\n",
    "    # Tile covers from (easting, northing) to (easting+tile_size, northing+tile_size)\n",
    "    tile_min_e = tile['easting']\n",
    "    tile_max_e = tile['easting'] + tile_size\n",
    "    tile_min_n = tile['northing']\n",
    "    tile_max_n = tile['northing'] + tile_size\n",
    "    \n",
    "    # Check intersection\n",
    "    return (tile_min_e <= bbox['max_easting'] and \n",
    "            tile_max_e >= bbox['min_easting'] and\n",
    "            tile_min_n <= bbox['max_northing'] and \n",
    "            tile_max_n >= bbox['min_northing'])\n",
    "\n",
    "# Apply buffer to bbox\n",
    "bbox_buffered = {\n",
    "    'min_easting': BBOX_UTM['min_easting'] - BUFFER,\n",
    "    'max_easting': BBOX_UTM['max_easting'] + BUFFER,\n",
    "    'min_northing': BBOX_UTM['min_northing'] - BUFFER,\n",
    "    'max_northing': BBOX_UTM['max_northing'] + BUFFER\n",
    "}\n",
    "\n",
    "# Filter tiles\n",
    "giant_forest_tiles = [\n",
    "    t for t in tiles_with_coords \n",
    "    if tile_intersects_bbox(t, bbox_buffered, TILE_SIZE)\n",
    "]\n",
    "\n",
    "print(f\"Tiles intersecting Giant Forest area: {len(giant_forest_tiles)}\")\n",
    "\n",
    "if giant_forest_tiles:\n",
    "    print(f\"\\nTile coordinate range:\")\n",
    "    eastings = [t['easting'] for t in giant_forest_tiles]\n",
    "    northings = [t['northing'] for t in giant_forest_tiles]\n",
    "    print(f\"  Easting: {min(eastings):,} to {max(eastings):,}\")\n",
    "    print(f\"  Northing: {min(northings):,} to {max(northings):,}\")\n",
    "    \n",
    "    print(f\"\\nSample tiles:\")\n",
    "    for t in giant_forest_tiles[:10]:\n",
    "        print(f\"  {t['filename']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If no tiles matched, let's do a broader search\n",
    "# and examine the actual coordinate patterns more carefully\n",
    "\n",
    "if len(giant_forest_tiles) == 0:\n",
    "    print(\"No tiles matched. Examining all tile coordinates...\")\n",
    "    \n",
    "    # Find tiles closest to our target area\n",
    "    target_e = (BBOX_UTM['min_easting'] + BBOX_UTM['max_easting']) / 2\n",
    "    target_n = (BBOX_UTM['min_northing'] + BBOX_UTM['max_northing']) / 2\n",
    "    \n",
    "    print(f\"\\nTarget center: E={target_e:.0f}, N={target_n:.0f}\")\n",
    "    \n",
    "    if tiles_with_coords:\n",
    "        # Sort by distance to target\n",
    "        for t in tiles_with_coords:\n",
    "            t['distance'] = np.sqrt((t['easting'] - target_e)**2 + (t['northing'] - target_n)**2)\n",
    "        \n",
    "        sorted_tiles = sorted(tiles_with_coords, key=lambda x: x['distance'])\n",
    "        \n",
    "        print(f\"\\n10 Closest tiles to target:\")\n",
    "        for t in sorted_tiles[:10]:\n",
    "            print(f\"  {t['filename']}\")\n",
    "            print(f\"    E={t['easting']:,}, N={t['northing']:,}, dist={t['distance']/1000:.1f}km\")\n",
    "else:\n",
    "    print(f\"\\n✓ Found {len(giant_forest_tiles)} tiles for Giant Forest area\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Tile List for Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save filtered tile list\n",
    "tiles_to_download = giant_forest_tiles if giant_forest_tiles else []\n",
    "\n",
    "if tiles_to_download:\n",
    "    # Save URLs to file for wget\n",
    "    download_list_path = RAW_DIR / \"giant_forest_tiles.txt\"\n",
    "    with open(download_list_path, 'w') as f:\n",
    "        for tile in tiles_to_download:\n",
    "            f.write(tile['url'] + '\\n')\n",
    "    print(f\"Saved {len(tiles_to_download)} tile URLs to {download_list_path}\")\n",
    "    \n",
    "    # Save metadata\n",
    "    metadata = {\n",
    "        'project': 'Sierra Nevada Giant Forest LiDAR',\n",
    "        'source': BASE_URL,\n",
    "        'bbox_wgs84': BBOX_WGS84,\n",
    "        'bbox_utm': {k: float(v) for k, v in BBOX_UTM.items()},\n",
    "        'crs': 'EPSG:32611',\n",
    "        'tile_count': len(tiles_to_download),\n",
    "        'tiles': [{'filename': t['filename'], 'easting': t['easting'], 'northing': t['northing']} \n",
    "                  for t in tiles_to_download],\n",
    "        'created': datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    metadata_path = RAW_DIR / \"giant_forest_metadata.json\"\n",
    "    with open(metadata_path, 'w') as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "    print(f\"Saved metadata to {metadata_path}\")\n",
    "else:\n",
    "    print(\"No tiles to save. Please check coordinate matching above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download LAZ Tiles\n",
    "\n",
    "Download the identified tiles. This may take a while depending on network speed and number of tiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which tiles are already downloaded\n",
    "def get_downloaded_tiles():\n",
    "    \"\"\"Get list of already downloaded LAZ files.\"\"\"\n",
    "    downloaded = []\n",
    "    for f in LAZ_DIR.glob('*.laz'):\n",
    "        downloaded.append(f.name)\n",
    "    return set(downloaded)\n",
    "\n",
    "downloaded = get_downloaded_tiles()\n",
    "print(f\"Already downloaded: {len(downloaded)} tiles\")\n",
    "\n",
    "# Filter tiles that need downloading\n",
    "tiles_needed = [t for t in tiles_to_download if t['filename'] not in downloaded]\n",
    "print(f\"Tiles to download: {len(tiles_needed)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_tile(url, output_dir, max_retries=3):\n",
    "    \"\"\"\n",
    "    Download a single LAZ tile using wget.\n",
    "    Returns True if successful, False otherwise.\n",
    "    \"\"\"\n",
    "    filename = os.path.basename(url)\n",
    "    output_path = output_dir / filename\n",
    "    \n",
    "    if output_path.exists():\n",
    "        print(f\"  Already exists: {filename}\")\n",
    "        return True\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            result = subprocess.run(\n",
    "                ['wget', '-q', '--show-progress', '-O', str(output_path), url],\n",
    "                capture_output=False,\n",
    "                timeout=600  # 10 minute timeout per file\n",
    "            )\n",
    "            if result.returncode == 0 and output_path.exists():\n",
    "                return True\n",
    "        except subprocess.TimeoutExpired:\n",
    "            print(f\"  Timeout on attempt {attempt + 1}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Error on attempt {attempt + 1}: {e}\")\n",
    "    \n",
    "    return False\n",
    "\n",
    "# Alternative: Download all at once using wget -i\n",
    "def download_all_tiles(tile_list_path, output_dir):\n",
    "    \"\"\"\n",
    "    Download all tiles from a URL list file using wget.\n",
    "    \"\"\"\n",
    "    cmd = [\n",
    "        'wget',\n",
    "        '-i', str(tile_list_path),\n",
    "        '-P', str(output_dir),\n",
    "        '--continue',\n",
    "        '--progress=dot:giga',\n",
    "        '--no-clobber'\n",
    "    ]\n",
    "    \n",
    "    print(f\"Running: {' '.join(cmd)}\")\n",
    "    result = subprocess.run(cmd)\n",
    "    return result.returncode == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download tiles (uncomment to run)\n",
    "# This may take significant time depending on the number and size of tiles\n",
    "\n",
    "if tiles_needed:\n",
    "    print(f\"Starting download of {len(tiles_needed)} tiles...\")\n",
    "    print(f\"Output directory: {LAZ_DIR}\")\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    \n",
    "    # Option 1: Download using list file (recommended for many files)\n",
    "    download_list_path = RAW_DIR / \"giant_forest_tiles.txt\"\n",
    "    if download_list_path.exists():\n",
    "        success = download_all_tiles(download_list_path, LAZ_DIR)\n",
    "        if success:\n",
    "            print(\"\\n✓ Download complete!\")\n",
    "        else:\n",
    "            print(\"\\n⚠ Download may have issues. Check logs above.\")\n",
    "    \n",
    "    # Option 2: Download one by one (use if Option 1 fails)\n",
    "    # for i, tile in enumerate(tiles_needed):\n",
    "    #     print(f\"[{i+1}/{len(tiles_needed)}] Downloading {tile['filename']}...\")\n",
    "    #     success = download_tile(tile['url'], LAZ_DIR)\n",
    "    #     if not success:\n",
    "    #         print(f\"  ✗ Failed to download {tile['filename']}\")\n",
    "else:\n",
    "    print(\"No tiles need downloading. All tiles already present or no tiles identified.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check final download status\n",
    "downloaded_files = list(LAZ_DIR.glob('*.laz'))\n",
    "total_size = sum(f.stat().st_size for f in downloaded_files)\n",
    "\n",
    "print(f\"Download Summary:\")\n",
    "print(f\"  Total LAZ files: {len(downloaded_files)}\")\n",
    "print(f\"  Total size: {total_size / (1024**3):.2f} GB\")\n",
    "\n",
    "if tiles_to_download:\n",
    "    expected = len(tiles_to_download)\n",
    "    actual = len(downloaded_files)\n",
    "    if actual >= expected:\n",
    "        print(f\"\\n✓ All expected tiles downloaded ({actual}/{expected})\")\n",
    "    else:\n",
    "        print(f\"\\n⚠ Missing tiles: {expected - actual} of {expected}\")\n",
    "        \n",
    "        # Find missing tiles\n",
    "        downloaded_names = {f.name for f in downloaded_files}\n",
    "        missing = [t for t in tiles_to_download if t['filename'] not in downloaded_names]\n",
    "        print(f\"Missing tiles:\")\n",
    "        for t in missing[:10]:\n",
    "            print(f\"  - {t['filename']}\")\n",
    "        if len(missing) > 10:\n",
    "            print(f\"  ... and {len(missing) - 10} more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List downloaded files with sizes\n",
    "print(\"Downloaded LAZ files:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for f in sorted(downloaded_files)[:20]:\n",
    "    size_mb = f.stat().st_size / (1024**2)\n",
    "    print(f\"  {f.name}: {size_mb:.1f} MB\")\n",
    "\n",
    "if len(downloaded_files) > 20:\n",
    "    print(f\"  ... and {len(downloaded_files) - 20} more files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Download Status\n",
    "\n",
    "Update the metadata with download status for tracking across sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update metadata with download status\n",
    "metadata_path = RAW_DIR / \"giant_forest_metadata.json\"\n",
    "\n",
    "if metadata_path.exists():\n",
    "    with open(metadata_path, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "else:\n",
    "    metadata = {'project': 'Sierra Nevada Giant Forest LiDAR'}\n",
    "\n",
    "# Update download status\n",
    "metadata['download_status'] = {\n",
    "    'total_files': len(downloaded_files),\n",
    "    'total_size_gb': total_size / (1024**3),\n",
    "    'last_updated': datetime.now().isoformat(),\n",
    "    'downloaded_files': [f.name for f in downloaded_files]\n",
    "}\n",
    "\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f\"Updated metadata at {metadata_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "After downloading the LAZ files:\n",
    "\n",
    "1. **Run `2_laz_to_raster.ipynb`** to process LAZ → DEM/DSM/CHM\n",
    "2. **Run `3_chm_exploration.ipynb`** to analyze the generated CHM\n",
    "3. **Run `4_fractal_analysis.ipynb`** to compute fractal dimensions\n",
    "\n",
    "See `PLAN.md` for the complete project workflow."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
