{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# CHM Fractal Analysis: Differential Box Counting & Hypothesis Testing\n",
    "\n",
    "This notebook performs fractal dimension analysis on Canopy Height Models (CHM) using:\n",
    "\n",
    "1. **Differential Box Counting (DBC)** - For self-affine fractal dimension of height surfaces\n",
    "2. **Standard Box Counting** - For self-similar fractal dimension comparison\n",
    "3. **Lacunarity Analysis** - Scale invariance and gap texture\n",
    "4. **Zeta Function Analysis** - Gap size distribution for hypothesis testing\n",
    "\n",
    "## Key Features\n",
    "\n",
    "- **Interactive AOI Selection** via Leaflet map\n",
    "- **Proper NoData Handling** - Distinguishes NoData pixels from zero-height (lacunarity=0) pixels\n",
    "- **Research Hypotheses Testing** - Implements methods from Part V\n",
    "\n",
    "## Requirements\n",
    "\n",
    "```bash\n",
    "conda activate 3dep\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import rioxarray as rio\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import json\n",
    "from scipy import ndimage\n",
    "from scipy.stats import ks_2samp, chisquare\n",
    "from scipy.optimize import curve_fit\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Interactive mapping\n",
    "import ipyleaflet\n",
    "from ipyleaflet import Map, DrawControl, TileLayer, GeoJSON, basemaps\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Geospatial\n",
    "from shapely.geometry import shape, box, Polygon\n",
    "from shapely.ops import transform\n",
    "import pyproj\n",
    "from rasterio.windows import from_bounds\n",
    "from rasterio.enums import Resampling\n",
    "\n",
    "print(f\"Environment ready at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to CHM raster (update this to your CHM file)\n",
    "CHM_PATH = Path(\"/data-store/iplant/home/tswetnam/fractal-notebooks/docs/notebooks/3dep/outputs/chm/monument_canyon_rna_chm.tif\")\n",
    "\n",
    "# Alternative: use a relative path\n",
    "# CHM_PATH = Path(\"./outputs/chm/monument_canyon_rna_chm.tif\")\n",
    "\n",
    "# Output directory for results\n",
    "OUTPUT_DIR = Path(\"./outputs/fractal_analysis\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# NoData value (will be read from raster if available)\n",
    "NODATA_VALUE = -9999\n",
    "\n",
    "# Gap threshold (meters) - pixels below this are considered \"gaps\"\n",
    "GAP_THRESHOLD = 2.0\n",
    "\n",
    "print(f\"CHM Path: {CHM_PATH}\")\n",
    "print(f\"Output Directory: {OUTPUT_DIR.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-header",
   "metadata": {},
   "source": [
    "## 3. Load CHM Raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-chm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CHM\n",
    "print(f\"Loading CHM from: {CHM_PATH}\")\n",
    "\n",
    "if not CHM_PATH.exists():\n",
    "    raise FileNotFoundError(f\"CHM file not found: {CHM_PATH}\")\n",
    "\n",
    "chm = rio.open_rasterio(CHM_PATH, masked=True)\n",
    "\n",
    "# Get NoData value from raster\n",
    "if chm.rio.nodata is not None:\n",
    "    NODATA_VALUE = chm.rio.nodata\n",
    "\n",
    "# Get CRS and bounds\n",
    "chm_crs = chm.rio.crs\n",
    "chm_bounds = chm.rio.bounds()\n",
    "\n",
    "print(f\"CHM Shape: {chm.shape}\")\n",
    "print(f\"CHM CRS: {chm_crs}\")\n",
    "print(f\"CHM Bounds: {chm_bounds}\")\n",
    "print(f\"NoData Value: {NODATA_VALUE}\")\n",
    "print(f\"Resolution: {chm.rio.resolution()}\")\n",
    "\n",
    "# Basic statistics\n",
    "chm_data = chm.values.squeeze()\n",
    "valid_mask = ~np.isnan(chm_data) & (chm_data != NODATA_VALUE)\n",
    "valid_data = chm_data[valid_mask]\n",
    "\n",
    "print(f\"\\nValid pixels: {valid_mask.sum():,} / {chm_data.size:,}\")\n",
    "print(f\"Height range: {valid_data.min():.2f} - {valid_data.max():.2f} m\")\n",
    "print(f\"Mean height: {valid_data.mean():.2f} m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "map-header",
   "metadata": {},
   "source": [
    "## 4. Interactive AOI Selection\n",
    "\n",
    "Draw a rectangle on the map to select an Area of Interest (AOI) for analysis.\n",
    "The AOI will be used to subset the CHM for fractal analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leaflet-map",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform bounds to WGS84 for Leaflet\n",
    "def transform_bounds_to_wgs84(bounds, src_crs):\n",
    "    \"\"\"Transform bounds from source CRS to WGS84.\"\"\"\n",
    "    transformer = pyproj.Transformer.from_crs(src_crs, \"EPSG:4326\", always_xy=True)\n",
    "    west, south, east, north = bounds\n",
    "    west_wgs, south_wgs = transformer.transform(west, south)\n",
    "    east_wgs, north_wgs = transformer.transform(east, north)\n",
    "    return (west_wgs, south_wgs, east_wgs, north_wgs)\n",
    "\n",
    "# Get WGS84 bounds\n",
    "bounds_wgs84 = transform_bounds_to_wgs84(chm_bounds, chm_crs)\n",
    "center_lat = (bounds_wgs84[1] + bounds_wgs84[3]) / 2\n",
    "center_lon = (bounds_wgs84[0] + bounds_wgs84[2]) / 2\n",
    "\n",
    "print(f\"CHM bounds (WGS84): {bounds_wgs84}\")\n",
    "print(f\"Map center: ({center_lat:.4f}, {center_lon:.4f})\")\n",
    "\n",
    "# Store selected AOI\n",
    "selected_aoi = {'geometry': None, 'bounds_native': None}\n",
    "\n",
    "def handle_draw(target, action, geo_json):\n",
    "    \"\"\"Handle drawing events from the map.\"\"\"\n",
    "    if action == 'created':\n",
    "        geom = shape(geo_json['geometry'])\n",
    "        selected_aoi['geometry'] = geom\n",
    "        \n",
    "        # Transform to native CRS\n",
    "        transformer = pyproj.Transformer.from_crs(\"EPSG:4326\", chm_crs, always_xy=True)\n",
    "        geom_native = transform(transformer.transform, geom)\n",
    "        selected_aoi['bounds_native'] = geom_native.bounds\n",
    "        \n",
    "        print(f\"AOI selected!\")\n",
    "        print(f\"  WGS84 bounds: {geom.bounds}\")\n",
    "        print(f\"  Native CRS bounds: {geom_native.bounds}\")\n",
    "\n",
    "# Create map\n",
    "m = Map(\n",
    "    basemap=basemaps.Esri.WorldImagery,\n",
    "    center=(center_lat, center_lon),\n",
    "    zoom=14\n",
    ")\n",
    "\n",
    "# Add CHM boundary\n",
    "chm_boundary = {\n",
    "    \"type\": \"Feature\",\n",
    "    \"geometry\": {\n",
    "        \"type\": \"Polygon\",\n",
    "        \"coordinates\": [[\n",
    "            [bounds_wgs84[0], bounds_wgs84[1]],\n",
    "            [bounds_wgs84[2], bounds_wgs84[1]],\n",
    "            [bounds_wgs84[2], bounds_wgs84[3]],\n",
    "            [bounds_wgs84[0], bounds_wgs84[3]],\n",
    "            [bounds_wgs84[0], bounds_wgs84[1]]\n",
    "        ]]\n",
    "    },\n",
    "    \"properties\": {\"name\": \"CHM Extent\"}\n",
    "}\n",
    "\n",
    "boundary_layer = GeoJSON(\n",
    "    data=chm_boundary,\n",
    "    style={'color': 'yellow', 'weight': 2, 'fillOpacity': 0.1}\n",
    ")\n",
    "m.add_layer(boundary_layer)\n",
    "\n",
    "# Add draw control\n",
    "draw_control = DrawControl(\n",
    "    polygon={},\n",
    "    rectangle={'shapeOptions': {'color': '#00ff00', 'weight': 2}},\n",
    "    polyline={},\n",
    "    circle={},\n",
    "    circlemarker={}\n",
    ")\n",
    "draw_control.on_draw(handle_draw)\n",
    "m.add_control(draw_control)\n",
    "\n",
    "# Instructions widget\n",
    "instructions = widgets.HTML(\n",
    "    value=\"<b>Instructions:</b> Draw a rectangle on the map to select your AOI. \"\n",
    "          \"The yellow boundary shows the CHM extent.\"\n",
    ")\n",
    "\n",
    "display(instructions)\n",
    "display(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extract-aoi",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract CHM subset for selected AOI\n",
    "# If no AOI selected, use the entire CHM\n",
    "\n",
    "if selected_aoi['bounds_native'] is not None:\n",
    "    # Clip to AOI\n",
    "    west, south, east, north = selected_aoi['bounds_native']\n",
    "    chm_subset = chm.rio.clip_box(minx=west, miny=south, maxx=east, maxy=north)\n",
    "    print(f\"Using selected AOI\")\n",
    "else:\n",
    "    # Use entire CHM\n",
    "    chm_subset = chm\n",
    "    print(f\"No AOI selected - using entire CHM\")\n",
    "\n",
    "# Get the data array\n",
    "chm_array = chm_subset.values.squeeze().astype(np.float64)\n",
    "\n",
    "# Create masks\n",
    "nodata_mask = np.isnan(chm_array) | (chm_array == NODATA_VALUE)\n",
    "valid_mask = ~nodata_mask\n",
    "\n",
    "print(f\"\\nSubset shape: {chm_array.shape}\")\n",
    "print(f\"Valid pixels: {valid_mask.sum():,} ({100*valid_mask.sum()/chm_array.size:.1f}%)\")\n",
    "print(f\"NoData pixels: {nodata_mask.sum():,} ({100*nodata_mask.sum()/chm_array.size:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc-header",
   "metadata": {},
   "source": [
    "## 5. Differential Box Counting (DBC)\n",
    "\n",
    "The Sarkar & Chaudhuri method for self-affine surfaces (height fields).\n",
    "\n",
    "**Key difference from standard box counting:**\n",
    "- Standard box counting: counts occupied boxes in binary image\n",
    "- DBC: counts boxes needed to cover the height variation within each grid cell\n",
    "\n",
    "**NoData Handling:**\n",
    "- Boxes containing ANY NoData pixels are excluded from counting\n",
    "- This prevents NoData from being confused with zero height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc-functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def differential_box_counting(img, valid_mask, scales=None, normalize=True):\n",
    "    \"\"\"\n",
    "    Compute fractal dimension using Differential Box Counting (Sarkar & Chaudhuri method).\n",
    "    \n",
    "    For self-affine surfaces (height fields), this method:\n",
    "    1. Divides the (x,y) plane into grid cells of size s\n",
    "    2. For each cell, counts the number of boxes (height s) needed to cover z-range\n",
    "    3. N(s) = sum of boxes across all cells\n",
    "    4. D = slope of log(N(s)) vs log(1/s)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    img : 2D numpy array\n",
    "        Height field (CHM)\n",
    "    valid_mask : 2D numpy array (bool)\n",
    "        True for valid pixels, False for NoData\n",
    "    scales : list or None\n",
    "        Box sizes to use. If None, uses powers of 2.\n",
    "    normalize : bool\n",
    "        Whether to normalize heights to [0, 1]\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    D : float\n",
    "        Fractal dimension\n",
    "    r2 : float\n",
    "        R-squared of linear fit\n",
    "    scales : array\n",
    "        Box sizes used\n",
    "    Ns : array\n",
    "        Box counts at each scale\n",
    "    \"\"\"\n",
    "    rows, cols = img.shape\n",
    "    \n",
    "    # Normalize heights if requested\n",
    "    if normalize:\n",
    "        valid_values = img[valid_mask]\n",
    "        z_min, z_max = valid_values.min(), valid_values.max()\n",
    "        if z_max > z_min:\n",
    "            img_norm = (img - z_min) / (z_max - z_min)\n",
    "        else:\n",
    "            img_norm = np.zeros_like(img)\n",
    "    else:\n",
    "        img_norm = img.copy()\n",
    "    \n",
    "    # Default scales: powers of 2\n",
    "    if scales is None:\n",
    "        max_scale = min(rows, cols) // 4\n",
    "        scales = [2**i for i in range(1, 10) if 2**i <= max_scale]\n",
    "    \n",
    "    Ns_list = []\n",
    "    valid_scales = []\n",
    "    \n",
    "    for s in scales:\n",
    "        nx = cols // s\n",
    "        ny = rows // s\n",
    "        \n",
    "        if nx < 1 or ny < 1:\n",
    "            continue\n",
    "            \n",
    "        N_total = 0\n",
    "        valid_boxes = 0\n",
    "        \n",
    "        for i in range(ny):\n",
    "            for j in range(nx):\n",
    "                # Extract box\n",
    "                y_start, y_end = i * s, (i + 1) * s\n",
    "                x_start, x_end = j * s, (j + 1) * s\n",
    "                \n",
    "                box_data = img_norm[y_start:y_end, x_start:x_end]\n",
    "                box_valid = valid_mask[y_start:y_end, x_start:x_end]\n",
    "                \n",
    "                # Skip boxes with ANY NoData\n",
    "                if not box_valid.all():\n",
    "                    continue\n",
    "                \n",
    "                valid_boxes += 1\n",
    "                \n",
    "                # Calculate height range within box\n",
    "                z_min_box = box_data.min()\n",
    "                z_max_box = box_data.max()\n",
    "                \n",
    "                # Number of boxes of height s needed to cover range\n",
    "                # Add 1 to ensure at least one box\n",
    "                n = int(np.ceil((z_max_box - z_min_box) * (max(rows, cols) / s))) + 1\n",
    "                N_total += n\n",
    "        \n",
    "        if valid_boxes > 0:\n",
    "            Ns_list.append(N_total)\n",
    "            valid_scales.append(s)\n",
    "            print(f\"  Scale {s:4d}: N(s) = {N_total:10,}, valid boxes = {valid_boxes:,}\")\n",
    "    \n",
    "    if len(valid_scales) < 2:\n",
    "        return np.nan, 0.0, np.array([]), np.array([])\n",
    "    \n",
    "    # Linear regression on log-log plot\n",
    "    log_inv_s = np.log(1.0 / np.array(valid_scales))\n",
    "    log_Ns = np.log(np.array(Ns_list))\n",
    "    \n",
    "    coeffs = np.polyfit(log_inv_s, log_Ns, 1)\n",
    "    D = coeffs[0]  # Slope is the fractal dimension\n",
    "    \n",
    "    # Calculate R-squared\n",
    "    predicted = np.polyval(coeffs, log_inv_s)\n",
    "    ss_res = np.sum((log_Ns - predicted) ** 2)\n",
    "    ss_tot = np.sum((log_Ns - np.mean(log_Ns)) ** 2)\n",
    "    r2 = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0\n",
    "    \n",
    "    return D, r2, np.array(valid_scales), np.array(Ns_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running Differential Box Counting (DBC)...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "D_dbc, r2_dbc, scales_dbc, Ns_dbc = differential_box_counting(\n",
    "    chm_array, valid_mask, normalize=True\n",
    ")\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nDBC Fractal Dimension: D = {D_dbc:.4f}\")\n",
    "print(f\"R-squared: {r2_dbc:.4f}\")\n",
    "\n",
    "# Interpretation based on hypotheses\n",
    "print(\"\\nInterpretation (Hypothesis 1 - Optimal Filling):\")\n",
    "if D_dbc >= 2.6:\n",
    "    print(f\"  D = {D_dbc:.2f} -> Suggests OLD GROWTH (High complexity, D = 2.6-2.8)\")\n",
    "elif D_dbc >= 2.3:\n",
    "    print(f\"  D = {D_dbc:.2f} -> Suggests DISTURBED forest (D = 2.3-2.5)\")\n",
    "else:\n",
    "    print(f\"  D = {D_dbc:.2f} -> Suggests PLANTATION/Managed (Low complexity, D = 2.1-2.3)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "box-counting-header",
   "metadata": {},
   "source": [
    "## 6. Standard Box Counting (for comparison)\n",
    "\n",
    "Standard box counting treats the CHM as a binary image (canopy vs gap).\n",
    "This measures the **self-similar** fractal dimension of the canopy boundary.\n",
    "\n",
    "**Difference from DBC:**\n",
    "- DBC: Self-affine (considers height variation) -> D ∈ [2, 3]\n",
    "- Box Counting: Self-similar (binary presence) -> D ∈ [1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "box-counting-functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_box_counting(binary_img, valid_mask=None, scales=None):\n",
    "    \"\"\"\n",
    "    Standard box counting for binary images (self-similar fractals).\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    binary_img : 2D numpy array (bool)\n",
    "        Binary image (True = occupied, False = empty)\n",
    "    valid_mask : 2D numpy array (bool) or None\n",
    "        True for valid pixels. If None, all pixels are valid.\n",
    "    scales : list or None\n",
    "        Box sizes to use\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    D : float\n",
    "        Fractal dimension\n",
    "    r2 : float\n",
    "        R-squared of linear fit\n",
    "    scales : array\n",
    "        Box sizes used\n",
    "    Ns : array\n",
    "        Box counts at each scale\n",
    "    \"\"\"\n",
    "    rows, cols = binary_img.shape\n",
    "    \n",
    "    if valid_mask is None:\n",
    "        valid_mask = np.ones_like(binary_img, dtype=bool)\n",
    "    \n",
    "    # Default scales\n",
    "    if scales is None:\n",
    "        max_scale = min(rows, cols) // 4\n",
    "        scales = [2**i for i in range(1, 10) if 2**i <= max_scale]\n",
    "    \n",
    "    Ns_list = []\n",
    "    valid_scales = []\n",
    "    \n",
    "    for s in scales:\n",
    "        nx = cols // s\n",
    "        ny = rows // s\n",
    "        \n",
    "        if nx < 1 or ny < 1:\n",
    "            continue\n",
    "        \n",
    "        N_occupied = 0\n",
    "        \n",
    "        for i in range(ny):\n",
    "            for j in range(nx):\n",
    "                y_start, y_end = i * s, (i + 1) * s\n",
    "                x_start, x_end = j * s, (j + 1) * s\n",
    "                \n",
    "                box_data = binary_img[y_start:y_end, x_start:x_end]\n",
    "                box_valid = valid_mask[y_start:y_end, x_start:x_end]\n",
    "                \n",
    "                # Only count if at least one valid occupied pixel\n",
    "                if np.any(box_data & box_valid):\n",
    "                    N_occupied += 1\n",
    "        \n",
    "        if N_occupied > 0:\n",
    "            Ns_list.append(N_occupied)\n",
    "            valid_scales.append(s)\n",
    "            print(f\"  Scale {s:4d}: N(s) = {N_occupied:10,}\")\n",
    "    \n",
    "    if len(valid_scales) < 2:\n",
    "        return np.nan, 0.0, np.array([]), np.array([])\n",
    "    \n",
    "    # Linear regression\n",
    "    log_inv_s = np.log(1.0 / np.array(valid_scales))\n",
    "    log_Ns = np.log(np.array(Ns_list))\n",
    "    \n",
    "    coeffs = np.polyfit(log_inv_s, log_Ns, 1)\n",
    "    D = coeffs[0]\n",
    "    \n",
    "    # R-squared\n",
    "    predicted = np.polyval(coeffs, log_inv_s)\n",
    "    ss_res = np.sum((log_Ns - predicted) ** 2)\n",
    "    ss_tot = np.sum((log_Ns - np.mean(log_Ns)) ** 2)\n",
    "    r2 = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0\n",
    "    \n",
    "    return D, r2, np.array(valid_scales), np.array(Ns_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-box-counting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary canopy image (canopy = height > GAP_THRESHOLD)\n",
    "canopy_binary = (chm_array > GAP_THRESHOLD) & valid_mask\n",
    "\n",
    "print(f\"Binary canopy image created (threshold = {GAP_THRESHOLD}m)\")\n",
    "print(f\"Canopy pixels: {canopy_binary.sum():,} ({100*canopy_binary.sum()/valid_mask.sum():.1f}% of valid)\")\n",
    "print(f\"Gap pixels: {(valid_mask & ~canopy_binary).sum():,}\")\n",
    "\n",
    "print(\"\\nRunning Standard Box Counting...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "D_bc, r2_bc, scales_bc, Ns_bc = standard_box_counting(canopy_binary, valid_mask)\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nBox Counting Fractal Dimension: D = {D_bc:.4f}\")\n",
    "print(f\"R-squared: {r2_bc:.4f}\")\n",
    "\n",
    "print(\"\\nComparison:\")\n",
    "print(f\"  DBC (self-affine):        D = {D_dbc:.4f}\")\n",
    "print(f\"  Box Counting (self-similar): D = {D_bc:.4f}\")\n",
    "print(f\"  Difference: {D_dbc - D_bc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lacunarity-header",
   "metadata": {},
   "source": [
    "## 7. Lacunarity Analysis\n",
    "\n",
    "Lacunarity measures the \"gappiness\" or texture heterogeneity of the canopy.\n",
    "\n",
    "**Formula (Gliding Box Algorithm):**\n",
    "$$\\Lambda(r) = \\frac{\\sigma^2(r)}{\\mu^2(r)} + 1$$\n",
    "\n",
    "where $\\sigma$ and $\\mu$ are the variance and mean of \"canopy mass\" per box size $r$.\n",
    "\n",
    "**NoData Handling:**\n",
    "- NoData pixels are EXCLUDED from calculations\n",
    "- Zero-height pixels (gaps) are INCLUDED as zeros\n",
    "- This is crucial: NoData ≠ Gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lacunarity-functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gliding_box_lacunarity(img, valid_mask, box_sizes=None, min_valid_fraction=0.5):\n",
    "    \"\"\"\n",
    "    Calculate lacunarity using the Gliding Box Algorithm.\n",
    "    \n",
    "    IMPORTANT: This properly distinguishes NoData from zero-height pixels.\n",
    "    - NoData pixels are excluded from all calculations\n",
    "    - Zero-height pixels (gaps) contribute to lacunarity as zeros\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    img : 2D numpy array\n",
    "        Height values (or canopy mass)\n",
    "    valid_mask : 2D numpy array (bool)\n",
    "        True for valid pixels, False for NoData\n",
    "    box_sizes : list or None\n",
    "        Box sizes to analyze\n",
    "    min_valid_fraction : float\n",
    "        Minimum fraction of valid pixels required in a box\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    lacunarity : array\n",
    "        Lacunarity values for each box size\n",
    "    box_sizes : array\n",
    "        Box sizes used\n",
    "    r2 : float\n",
    "        R-squared of log-log linear fit\n",
    "    \"\"\"\n",
    "    rows, cols = img.shape\n",
    "    \n",
    "    # Replace invalid pixels with NaN for calculations\n",
    "    img_clean = img.copy()\n",
    "    img_clean[~valid_mask] = np.nan\n",
    "    \n",
    "    if box_sizes is None:\n",
    "        max_size = min(rows, cols) // 4\n",
    "        box_sizes = [2**i for i in range(1, 10) if 2**i <= max_size]\n",
    "    \n",
    "    lacunarity_values = []\n",
    "    valid_sizes = []\n",
    "    \n",
    "    for r in box_sizes:\n",
    "        box_sums = []\n",
    "        \n",
    "        # Gliding box\n",
    "        for i in range(0, rows - r + 1, max(1, r // 2)):  # 50% overlap\n",
    "            for j in range(0, cols - r + 1, max(1, r // 2)):\n",
    "                box = img_clean[i:i+r, j:j+r]\n",
    "                box_valid = valid_mask[i:i+r, j:j+r]\n",
    "                \n",
    "                # Skip if too few valid pixels\n",
    "                valid_fraction = box_valid.sum() / (r * r)\n",
    "                if valid_fraction < min_valid_fraction:\n",
    "                    continue\n",
    "                \n",
    "                # Sum only valid pixels\n",
    "                box_sum = np.nansum(box)\n",
    "                box_sums.append(box_sum)\n",
    "        \n",
    "        if len(box_sums) < 10:  # Need minimum samples\n",
    "            continue\n",
    "        \n",
    "        box_sums = np.array(box_sums)\n",
    "        mu = np.mean(box_sums)\n",
    "        sigma2 = np.var(box_sums)\n",
    "        \n",
    "        if mu > 0:\n",
    "            L = (sigma2 / (mu ** 2)) + 1\n",
    "        else:\n",
    "            L = 1.0  # No variation\n",
    "        \n",
    "        lacunarity_values.append(L)\n",
    "        valid_sizes.append(r)\n",
    "        print(f\"  r = {r:4d}: Λ = {L:.4f}, μ = {mu:.2f}, σ² = {sigma2:.2f}, n = {len(box_sums)}\")\n",
    "    \n",
    "    if len(valid_sizes) < 2:\n",
    "        return np.array([]), np.array([]), 0.0\n",
    "    \n",
    "    # Calculate R² of log-log fit (test for scale invariance)\n",
    "    log_r = np.log(np.array(valid_sizes))\n",
    "    log_L = np.log(np.array(lacunarity_values))\n",
    "    \n",
    "    coeffs = np.polyfit(log_r, log_L, 1)\n",
    "    predicted = np.polyval(coeffs, log_r)\n",
    "    ss_res = np.sum((log_L - predicted) ** 2)\n",
    "    ss_tot = np.sum((log_L - np.mean(log_L)) ** 2)\n",
    "    r2 = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0\n",
    "    \n",
    "    return np.array(lacunarity_values), np.array(valid_sizes), r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-lacunarity",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running Lacunarity Analysis (Gliding Box Algorithm)...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "lacunarity, lac_sizes, r2_lac = gliding_box_lacunarity(chm_array, valid_mask)\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nLacunarity R² (log-log linearity): {r2_lac:.4f}\")\n",
    "\n",
    "# Interpretation based on Hypothesis 2\n",
    "print(\"\\nInterpretation (Hypothesis 2 - Scale Invariance):\")\n",
    "if r2_lac > 0.95:\n",
    "    print(f\"  R² = {r2_lac:.2f} -> Strong scale invariance (OLD GROWTH signature)\")\n",
    "elif r2_lac > 0.70:\n",
    "    print(f\"  R² = {r2_lac:.2f} -> Moderate scale invariance (possible DISTURBANCE)\")\n",
    "else:\n",
    "    print(f\"  R² = {r2_lac:.2f} -> Weak scale invariance (PLANTATION or young forest)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zeta-header",
   "metadata": {},
   "source": [
    "## 8. Zeta Function Analysis (Gap Size Distribution)\n",
    "\n",
    "The Riemann Zeta function appears in the power-law distribution of gap sizes.\n",
    "\n",
    "**Hypothesis 3 (Zeta Distribution):**\n",
    "- Old-growth: Gap sizes follow power law $P(A) \\sim A^{-\\alpha}$ where $\\alpha \\approx 2.0$\n",
    "- Disturbed/Plantation: Exponential or lognormal distribution\n",
    "\n",
    "The exponent $\\alpha \\approx 2$ relates to $\\zeta(2) = \\pi^2/6 \\approx 1.645$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gap-analysis-functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_gaps(chm, valid_mask, gap_threshold=2.0, min_gap_size=1):\n",
    "    \"\"\"\n",
    "    Identify contiguous gap regions in the CHM.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    chm : 2D numpy array\n",
    "        Canopy height model\n",
    "    valid_mask : 2D numpy array (bool)\n",
    "        Valid pixel mask\n",
    "    gap_threshold : float\n",
    "        Height below which pixels are considered gaps\n",
    "    min_gap_size : int\n",
    "        Minimum gap size in pixels\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    gap_areas : array\n",
    "        Areas of each gap (in pixels)\n",
    "    labeled_gaps : 2D array\n",
    "        Labeled gap regions\n",
    "    \"\"\"\n",
    "    # Create gap mask (low height AND valid)\n",
    "    gap_mask = (chm < gap_threshold) & valid_mask\n",
    "    \n",
    "    # Label connected components\n",
    "    labeled, num_features = ndimage.label(gap_mask)\n",
    "    \n",
    "    # Get sizes of each gap\n",
    "    gap_areas = ndimage.sum(gap_mask, labeled, range(1, num_features + 1))\n",
    "    \n",
    "    # Filter by minimum size\n",
    "    gap_areas = gap_areas[gap_areas >= min_gap_size]\n",
    "    \n",
    "    return gap_areas, labeled\n",
    "\n",
    "\n",
    "def power_law(x, alpha, c):\n",
    "    \"\"\"Power law function: y = c * x^(-alpha)\"\"\"\n",
    "    return c * np.power(x, -alpha)\n",
    "\n",
    "\n",
    "def exponential(x, beta, c):\n",
    "    \"\"\"Exponential function: y = c * exp(-beta * x)\"\"\"\n",
    "    return c * np.exp(-beta * x)\n",
    "\n",
    "\n",
    "def fit_gap_distribution(gap_areas, resolution=1.0):\n",
    "    \"\"\"\n",
    "    Fit power law and exponential distributions to gap sizes.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    gap_areas : array\n",
    "        Gap areas in pixels\n",
    "    resolution : float\n",
    "        Pixel resolution in meters\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    results : dict\n",
    "        Fit parameters and statistics\n",
    "    \"\"\"\n",
    "    # Convert to actual area (m²)\n",
    "    areas = gap_areas * (resolution ** 2)\n",
    "    areas = areas[areas > 0]  # Remove zeros\n",
    "    \n",
    "    if len(areas) < 10:\n",
    "        return {'error': 'Insufficient gaps for analysis'}\n",
    "    \n",
    "    # Create empirical CDF\n",
    "    sorted_areas = np.sort(areas)\n",
    "    ecdf = np.arange(1, len(sorted_areas) + 1) / len(sorted_areas)\n",
    "    ccdf = 1 - ecdf  # Complementary CDF (P(X > x))\n",
    "    \n",
    "    # Fit power law using log-log regression\n",
    "    # P(X > x) ~ x^(-alpha+1) for power law\n",
    "    log_x = np.log(sorted_areas[ccdf > 0.01])  # Avoid tail\n",
    "    log_ccdf = np.log(ccdf[ccdf > 0.01])\n",
    "    \n",
    "    try:\n",
    "        pl_coeffs = np.polyfit(log_x, log_ccdf, 1)\n",
    "        alpha_pl = -pl_coeffs[0] + 1  # Convert from CDF slope to PDF exponent\n",
    "        \n",
    "        # R² for power law\n",
    "        predicted_pl = np.polyval(pl_coeffs, log_x)\n",
    "        ss_res_pl = np.sum((log_ccdf - predicted_pl) ** 2)\n",
    "        ss_tot = np.sum((log_ccdf - np.mean(log_ccdf)) ** 2)\n",
    "        r2_pl = 1 - (ss_res_pl / ss_tot) if ss_tot > 0 else 0\n",
    "    except:\n",
    "        alpha_pl = np.nan\n",
    "        r2_pl = 0\n",
    "    \n",
    "    # Fit exponential using linear regression on log(ccdf) vs x\n",
    "    try:\n",
    "        # For exponential: log(ccdf) = -beta * x + c\n",
    "        x_vals = sorted_areas[ccdf > 0.01]\n",
    "        log_ccdf_exp = np.log(ccdf[ccdf > 0.01])\n",
    "        \n",
    "        exp_coeffs = np.polyfit(x_vals, log_ccdf_exp, 1)\n",
    "        beta_exp = -exp_coeffs[0]\n",
    "        \n",
    "        # R² for exponential\n",
    "        predicted_exp = np.polyval(exp_coeffs, x_vals)\n",
    "        ss_res_exp = np.sum((log_ccdf_exp - predicted_exp) ** 2)\n",
    "        r2_exp = 1 - (ss_res_exp / ss_tot) if ss_tot > 0 else 0\n",
    "    except:\n",
    "        beta_exp = np.nan\n",
    "        r2_exp = 0\n",
    "    \n",
    "    # Zeta function connection\n",
    "    # For α ≈ 2, relates to ζ(2) = π²/6\n",
    "    zeta_2 = np.pi**2 / 6\n",
    "    \n",
    "    return {\n",
    "        'n_gaps': len(areas),\n",
    "        'min_area': areas.min(),\n",
    "        'max_area': areas.max(),\n",
    "        'median_area': np.median(areas),\n",
    "        'power_law': {\n",
    "            'alpha': alpha_pl,\n",
    "            'r2': r2_pl\n",
    "        },\n",
    "        'exponential': {\n",
    "            'beta': beta_exp,\n",
    "            'r2': r2_exp\n",
    "        },\n",
    "        'zeta_connection': {\n",
    "            'zeta_2': zeta_2,\n",
    "            'alpha_vs_zeta2': abs(alpha_pl - 2.0) if not np.isnan(alpha_pl) else np.nan\n",
    "        },\n",
    "        'sorted_areas': sorted_areas,\n",
    "        'ccdf': ccdf\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-gap-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running Gap Size Distribution Analysis...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Get pixel resolution\n",
    "res_x, res_y = abs(chm_subset.rio.resolution()[0]), abs(chm_subset.rio.resolution()[1])\n",
    "pixel_resolution = (res_x + res_y) / 2  # Average resolution\n",
    "\n",
    "# Identify gaps\n",
    "gap_areas, labeled_gaps = identify_gaps(chm_array, valid_mask, GAP_THRESHOLD)\n",
    "\n",
    "print(f\"Gap threshold: {GAP_THRESHOLD}m\")\n",
    "print(f\"Pixel resolution: {pixel_resolution:.3f}m\")\n",
    "print(f\"Number of gaps found: {len(gap_areas)}\")\n",
    "\n",
    "# Fit distributions\n",
    "gap_results = fit_gap_distribution(gap_areas, pixel_resolution)\n",
    "\n",
    "if 'error' in gap_results:\n",
    "    print(f\"\\nError: {gap_results['error']}\")\n",
    "else:\n",
    "    print(f\"\\nGap Statistics:\")\n",
    "    print(f\"  Count: {gap_results['n_gaps']}\")\n",
    "    print(f\"  Area range: {gap_results['min_area']:.2f} - {gap_results['max_area']:.2f} m²\")\n",
    "    print(f\"  Median area: {gap_results['median_area']:.2f} m²\")\n",
    "    \n",
    "    print(f\"\\nPower Law Fit:\")\n",
    "    print(f\"  α (exponent): {gap_results['power_law']['alpha']:.4f}\")\n",
    "    print(f\"  R²: {gap_results['power_law']['r2']:.4f}\")\n",
    "    \n",
    "    print(f\"\\nExponential Fit:\")\n",
    "    print(f\"  β: {gap_results['exponential']['beta']:.6f}\")\n",
    "    print(f\"  R²: {gap_results['exponential']['r2']:.4f}\")\n",
    "    \n",
    "    print(f\"\\nZeta Function Connection:\")\n",
    "    print(f\"  ζ(2) = π²/6 ≈ {gap_results['zeta_connection']['zeta_2']:.4f}\")\n",
    "    print(f\"  |α - 2| = {gap_results['zeta_connection']['alpha_vs_zeta2']:.4f}\")\n",
    "    \n",
    "    # Interpretation\n",
    "    print(\"\\nInterpretation (Hypothesis 3 - Zeta Distribution):\")\n",
    "    pl_r2 = gap_results['power_law']['r2']\n",
    "    exp_r2 = gap_results['exponential']['r2']\n",
    "    alpha = gap_results['power_law']['alpha']\n",
    "    \n",
    "    if pl_r2 > exp_r2 and pl_r2 > 0.8:\n",
    "        print(f\"  Power law fits better (R²={pl_r2:.2f} vs {exp_r2:.2f})\")\n",
    "        if 1.8 <= alpha <= 2.2:\n",
    "            print(f\"  α ≈ {alpha:.2f} is close to 2.0 -> OLD GROWTH signature\")\n",
    "        else:\n",
    "            print(f\"  α = {alpha:.2f} deviates from 2.0 -> Possible disturbance\")\n",
    "    else:\n",
    "        print(f\"  Exponential fits better (R²={exp_r2:.2f} vs {pl_r2:.2f})\")\n",
    "        print(f\"  -> DISTURBED or PLANTATION signature\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualization-header",
   "metadata": {},
   "source": [
    "## 9. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "\n",
    "# 1. CHM with gaps highlighted\n",
    "ax1 = axes[0, 0]\n",
    "chm_display = np.ma.masked_where(~valid_mask, chm_array)\n",
    "im1 = ax1.imshow(chm_display, cmap='Greens', vmin=0)\n",
    "ax1.set_title(f'CHM (Gap threshold = {GAP_THRESHOLD}m)')\n",
    "plt.colorbar(im1, ax=ax1, label='Height (m)')\n",
    "\n",
    "# Overlay gaps\n",
    "gap_overlay = np.ma.masked_where(chm_array >= GAP_THRESHOLD, np.ones_like(chm_array))\n",
    "ax1.imshow(gap_overlay, cmap='Reds', alpha=0.5)\n",
    "\n",
    "# 2. DBC log-log plot\n",
    "ax2 = axes[0, 1]\n",
    "if len(scales_dbc) > 0:\n",
    "    ax2.plot(np.log(1/scales_dbc), np.log(Ns_dbc), 'bo-', markersize=8, label='DBC Data')\n",
    "    coeffs = np.polyfit(np.log(1/scales_dbc), np.log(Ns_dbc), 1)\n",
    "    x_fit = np.log(1/scales_dbc)\n",
    "    ax2.plot(x_fit, np.polyval(coeffs, x_fit), 'r--', \n",
    "             label=f'Fit: D = {D_dbc:.3f}')\n",
    "ax2.set_xlabel('log(1/s)')\n",
    "ax2.set_ylabel('log(N(s))')\n",
    "ax2.set_title(f'Differential Box Counting\\nD = {D_dbc:.3f}, R² = {r2_dbc:.3f}')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Standard box counting comparison\n",
    "ax3 = axes[0, 2]\n",
    "if len(scales_bc) > 0:\n",
    "    ax3.plot(np.log(1/scales_bc), np.log(Ns_bc), 'go-', markersize=8, label='Box Counting')\n",
    "    coeffs_bc = np.polyfit(np.log(1/scales_bc), np.log(Ns_bc), 1)\n",
    "    x_fit_bc = np.log(1/scales_bc)\n",
    "    ax3.plot(x_fit_bc, np.polyval(coeffs_bc, x_fit_bc), 'r--',\n",
    "             label=f'Fit: D = {D_bc:.3f}')\n",
    "ax3.set_xlabel('log(1/s)')\n",
    "ax3.set_ylabel('log(N(s))')\n",
    "ax3.set_title(f'Standard Box Counting\\nD = {D_bc:.3f}, R² = {r2_bc:.3f}')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Lacunarity curve\n",
    "ax4 = axes[1, 0]\n",
    "if len(lac_sizes) > 0:\n",
    "    ax4.loglog(lac_sizes, lacunarity, 'mo-', markersize=8, label='Lacunarity')\n",
    "    ax4.set_xlabel('Box size r (pixels)')\n",
    "    ax4.set_ylabel('Lacunarity Λ(r)')\n",
    "    ax4.set_title(f'Lacunarity (Scale Invariance)\\nR² = {r2_lac:.3f}')\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Gap size distribution\n",
    "ax5 = axes[1, 1]\n",
    "if 'sorted_areas' in gap_results:\n",
    "    ax5.loglog(gap_results['sorted_areas'], gap_results['ccdf'], 'k.', \n",
    "               alpha=0.5, markersize=3, label='Data')\n",
    "    \n",
    "    # Plot power law fit\n",
    "    x_range = np.logspace(np.log10(gap_results['min_area']), \n",
    "                          np.log10(gap_results['max_area']), 100)\n",
    "    alpha = gap_results['power_law']['alpha']\n",
    "    y_pl = (x_range / gap_results['min_area']) ** (-(alpha - 1))\n",
    "    ax5.loglog(x_range, y_pl, 'r-', linewidth=2, \n",
    "               label=f'Power Law (α={alpha:.2f})')\n",
    "    \n",
    "ax5.set_xlabel('Gap Area (m²)')\n",
    "ax5.set_ylabel('P(X > x)')\n",
    "ax5.set_title('Gap Size Distribution (CCDF)')\n",
    "ax5.legend()\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Summary statistics\n",
    "ax6 = axes[1, 2]\n",
    "ax6.axis('off')\n",
    "\n",
    "summary_text = f\"\"\"\n",
    "FRACTAL ANALYSIS SUMMARY\n",
    "{'='*40}\n",
    "\n",
    "Differential Box Counting (Self-Affine):\n",
    "  D = {D_dbc:.4f}  (R² = {r2_dbc:.4f})\n",
    "  \n",
    "Standard Box Counting (Self-Similar):\n",
    "  D = {D_bc:.4f}  (R² = {r2_bc:.4f})\n",
    "  \n",
    "Lacunarity (Scale Invariance):\n",
    "  R² = {r2_lac:.4f}\n",
    "  \n",
    "Gap Distribution:\n",
    "  Power Law α = {gap_results.get('power_law', {}).get('alpha', np.nan):.4f}\n",
    "  Power Law R² = {gap_results.get('power_law', {}).get('r2', 0):.4f}\n",
    "  \n",
    "Zeta Connection:\n",
    "  |α - 2| = {gap_results.get('zeta_connection', {}).get('alpha_vs_zeta2', np.nan):.4f}\n",
    "  ζ(2) = π²/6 ≈ 1.645\n",
    "\"\"\"\n",
    "\n",
    "ax6.text(0.05, 0.95, summary_text, transform=ax6.transAxes,\n",
    "         fontsize=10, verticalalignment='top', fontfamily='monospace',\n",
    "         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save figure\n",
    "fig_path = OUTPUT_DIR / 'fractal_analysis_results.png'\n",
    "plt.savefig(fig_path, dpi=150, bbox_inches='tight')\n",
    "print(f\"Figure saved to: {fig_path}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "export-header",
   "metadata": {},
   "source": [
    "## 10. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "export-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile all results\n",
    "results = {\n",
    "    'metadata': {\n",
    "        'chm_path': str(CHM_PATH),\n",
    "        'analysis_date': datetime.now().isoformat(),\n",
    "        'gap_threshold_m': GAP_THRESHOLD,\n",
    "        'nodata_value': float(NODATA_VALUE),\n",
    "        'aoi_selected': selected_aoi['bounds_native'] is not None\n",
    "    },\n",
    "    'differential_box_counting': {\n",
    "        'fractal_dimension': float(D_dbc),\n",
    "        'r_squared': float(r2_dbc),\n",
    "        'scales': scales_dbc.tolist() if len(scales_dbc) > 0 else [],\n",
    "        'counts': Ns_dbc.tolist() if len(Ns_dbc) > 0 else [],\n",
    "        'interpretation': 'self-affine surface dimension'\n",
    "    },\n",
    "    'standard_box_counting': {\n",
    "        'fractal_dimension': float(D_bc),\n",
    "        'r_squared': float(r2_bc),\n",
    "        'scales': scales_bc.tolist() if len(scales_bc) > 0 else [],\n",
    "        'counts': Ns_bc.tolist() if len(Ns_bc) > 0 else [],\n",
    "        'interpretation': 'self-similar boundary dimension'\n",
    "    },\n",
    "    'lacunarity': {\n",
    "        'r_squared': float(r2_lac),\n",
    "        'box_sizes': lac_sizes.tolist() if len(lac_sizes) > 0 else [],\n",
    "        'values': lacunarity.tolist() if len(lacunarity) > 0 else [],\n",
    "        'interpretation': 'scale invariance measure'\n",
    "    },\n",
    "    'gap_distribution': {\n",
    "        'n_gaps': gap_results.get('n_gaps', 0),\n",
    "        'power_law_alpha': float(gap_results.get('power_law', {}).get('alpha', np.nan)),\n",
    "        'power_law_r2': float(gap_results.get('power_law', {}).get('r2', 0)),\n",
    "        'exponential_r2': float(gap_results.get('exponential', {}).get('r2', 0)),\n",
    "        'zeta_2': float(np.pi**2 / 6),\n",
    "        'alpha_vs_zeta2': float(gap_results.get('zeta_connection', {}).get('alpha_vs_zeta2', np.nan))\n",
    "    },\n",
    "    'hypothesis_tests': {\n",
    "        'H1_optimal_filling': {\n",
    "            'D_dbc': float(D_dbc),\n",
    "            'prediction': 'old_growth' if D_dbc >= 2.6 else ('disturbed' if D_dbc >= 2.3 else 'plantation')\n",
    "        },\n",
    "        'H2_scale_invariance': {\n",
    "            'lacunarity_r2': float(r2_lac),\n",
    "            'prediction': 'old_growth' if r2_lac > 0.95 else ('disturbed' if r2_lac > 0.7 else 'plantation')\n",
    "        },\n",
    "        'H3_zeta_distribution': {\n",
    "            'power_law_alpha': float(gap_results.get('power_law', {}).get('alpha', np.nan)),\n",
    "            'power_law_better': gap_results.get('power_law', {}).get('r2', 0) > gap_results.get('exponential', {}).get('r2', 0),\n",
    "            'prediction': 'old_growth' if (gap_results.get('power_law', {}).get('r2', 0) > 0.8 and \n",
    "                                           1.8 <= gap_results.get('power_law', {}).get('alpha', 0) <= 2.2) else 'disturbed_or_plantation'\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save to JSON\n",
    "results_path = OUTPUT_DIR / 'fractal_analysis_results.json'\n",
    "with open(results_path, 'w') as f:\n",
    "    json.dump(results, f, indent=2, default=str)\n",
    "\n",
    "print(f\"Results saved to: {results_path}\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "references",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## References\n",
    "\n",
    "### Methods\n",
    "- Sarkar, N., & Chaudhuri, B.B. (1994). An efficient differential box-counting approach to compute fractal dimension of image. *IEEE Transactions on Systems, Man, and Cybernetics*.\n",
    "- Allain, C., & Cloitre, M. (1991). Characterizing the lacunarity of random and deterministic fractal sets. *Physical Review A*.\n",
    "\n",
    "### Ecological Applications\n",
    "- West, G.B., Brown, J.H., & Enquist, B.J. (1997). A general model for the origin of allometric scaling laws in biology. *Science*.\n",
    "- Mandelbrot, B.B. (1983). *The Fractal Geometry of Nature*. W.H. Freeman.\n",
    "\n",
    "### Zeta Function in Physics\n",
    "- Montgomery, H.L. (1973). The pair correlation of zeros of the zeta function. *Analytic Number Theory*.\n",
    "- Lapidus, M.L., & van Frankenhuijsen, M. (2006). *Fractal Geometry, Complex Dimensions and Zeta Functions*. Springer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (3dep)",
   "language": "python",
   "name": "3dep"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
