{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# CHM Generation: Ocala Longleaf Pine\n",
    "\n",
    "**Site:** Ocala Longleaf Pine, FL\n",
    "**Forest Type:** Longleaf Pine\n",
    "**Expected Max Height:** 35m\n",
    "\n",
    "**Description:** Florida sandhill longleaf pine ecosystem\n",
    "\n",
    "Generate Canopy Height Models from USGS 3D Elevation Program (3DEP) lidar data.\n",
    "\n",
    "**Modified from:** [OpenTopography OT_3DEP_Workflows](https://github.com/OpenTopography/OT_3DEP_Workflows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment validated successfully!\n"
     ]
    }
   ],
   "source": [
    "# Environment validation\n",
    "import sys\n",
    "\n",
    "REQUIRED_PACKAGES = ['pdal', 'geopandas', 'rioxarray', 'pyproj', 'shapely', 'numpy']\n",
    "missing = []\n",
    "\n",
    "for pkg in REQUIRED_PACKAGES:\n",
    "    try:\n",
    "        __import__(pkg)\n",
    "    except ImportError:\n",
    "        missing.append(pkg)\n",
    "\n",
    "if missing:\n",
    "    raise ImportError(\n",
    "        f\"Missing packages: {missing}\\n\"\n",
    "        f\"Please activate the 3dep conda environment:\\n\"\n",
    "        f\"  conda activate 3dep\"\n",
    "    )\n",
    "\n",
    "print(\"Environment validated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cell-3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded at 2025-12-19 18:19:00\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pdal\n",
    "import pyproj\n",
    "import requests\n",
    "import rioxarray as rio\n",
    "import xarray as xr\n",
    "from rasterio.enums import Resampling\n",
    "from shapely.geometry import shape, box\n",
    "from shapely.ops import transform\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"Libraries loaded at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "\n",
    "**Important:** We write outputs to local storage (`/home/jovyan/outputs/`) first for better I/O performance, then copy to the CyVerse Data Store in a separate step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cell-5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directories created under: /home/jovyan/data-store/data/output/3dep\n"
     ]
    }
   ],
   "source": [
    "# Output configuration\n",
    "# Local storage for processing outputs\n",
    "LOCAL_OUTPUT_BASE = Path(\"/home/jovyan/data-store/data/output/3dep\")\n",
    "LOCAL_OUTPUT_CHM = LOCAL_OUTPUT_BASE / \"chm\"\n",
    "LOCAL_OUTPUT_DTM = LOCAL_OUTPUT_BASE / \"dtm\"\n",
    "LOCAL_OUTPUT_DSM = LOCAL_OUTPUT_BASE / \"dsm\"\n",
    "\n",
    "# CyVerse Data Store for final storage (optional - if using CyVerse)\n",
    "DATASTORE_OUTPUT_BASE = Path(\"/home/jovyan/data-store/data/output/3dep\")\n",
    "\n",
    "# Create local output directories\n",
    "for d in [LOCAL_OUTPUT_CHM, LOCAL_OUTPUT_DTM, LOCAL_OUTPUT_DSM]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Output directories created under: {LOCAL_OUTPUT_BASE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolution rules:\n",
      "  >= 12 pts/m\u00b2 -> 0.333m\n",
      "  <  12 pts/m\u00b2 -> 0.5m\n"
     ]
    }
   ],
   "source": [
    "# Resolution configuration\n",
    "# Resolution is determined by point density:\n",
    "#   - >= 12 points/m\u00b2 -> 0.333m resolution\n",
    "#   - <  12 points/m\u00b2 -> 0.5m resolution\n",
    "\n",
    "DENSITY_THRESHOLD = 12  # points per square meter\n",
    "RESOLUTION_HIGH = 0.333  # for high density (>= threshold)\n",
    "RESOLUTION_STANDARD = 0.5  # for standard density (< threshold)\n",
    "\n",
    "# Output CRS\n",
    "OUTPUT_CRS = 3857  # Web Mercator\n",
    "\n",
    "def get_resolution(point_density_per_m2):\n",
    "    \"\"\"Select output resolution based on point density.\n",
    "    \n",
    "    Args:\n",
    "        point_density_per_m2: Estimated point density in points/m\u00b2\n",
    "        \n",
    "    Returns:\n",
    "        Resolution in meters (0.333 or 0.5)\n",
    "    \"\"\"\n",
    "    if point_density_per_m2 >= DENSITY_THRESHOLD:\n",
    "        return RESOLUTION_HIGH\n",
    "    return RESOLUTION_STANDARD\n",
    "\n",
    "print(f\"Resolution rules:\")\n",
    "print(f\"  >= {DENSITY_THRESHOLD} pts/m\u00b2 -> {RESOLUTION_HIGH}m\")\n",
    "print(f\"  <  {DENSITY_THRESHOLD} pts/m\u00b2 -> {RESOLUTION_STANDARD}m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 3. Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gcs_to_proj(poly):\n",
    "    \"\"\"Reproject from EPSG:4326 to EPSG:3857.\"\"\"\n",
    "    wgs84 = pyproj.CRS(\"EPSG:4326\")\n",
    "    web_mercator = pyproj.CRS(\"EPSG:3857\")\n",
    "    project = pyproj.Transformer.from_crs(wgs84, web_mercator, always_xy=True).transform\n",
    "    return transform(project, poly)\n",
    "\n",
    "\n",
    "def proj_to_gcs(poly):\n",
    "    \"\"\"Reproject from EPSG:3857 to EPSG:4326.\"\"\"\n",
    "    wgs84 = pyproj.CRS(\"EPSG:4326\")\n",
    "    web_mercator = pyproj.CRS(\"EPSG:3857\")\n",
    "    project = pyproj.Transformer.from_crs(web_mercator, wgs84, always_xy=True).transform\n",
    "    return transform(project, poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dem_pipeline(\n",
    "    extent_epsg3857,\n",
    "    usgs_3dep_dataset_names,\n",
    "    pc_resolution,\n",
    "    dem_resolution,\n",
    "    dem_type,  # 'dsm' or 'dtm'\n",
    "    dem_out_path,\n",
    "    filter_noise=True,\n",
    "    out_crs=3857\n",
    "):\n",
    "    \"\"\"Build PDAL pipeline for DEM generation.\n",
    "    \n",
    "    Uses 'max' for DSM and 'min' for DTM - NO IDW smoothing.\n",
    "    \n",
    "    Args:\n",
    "        extent_epsg3857: AOI polygon in EPSG:3857 (WKT string)\n",
    "        usgs_3dep_dataset_names: List of 3DEP dataset names\n",
    "        pc_resolution: Point cloud resolution parameter\n",
    "        dem_resolution: Output DEM resolution in meters\n",
    "        dem_type: 'dsm' (all points) or 'dtm' (ground only)\n",
    "        dem_out_path: Output file path\n",
    "        filter_noise: Remove noise classes\n",
    "        out_crs: Output CRS EPSG code\n",
    "        \n",
    "    Returns:\n",
    "        PDAL pipeline dictionary\n",
    "    \"\"\"\n",
    "    # Build readers for each dataset\n",
    "    readers = []\n",
    "    for name in usgs_3dep_dataset_names:\n",
    "        url = f\"https://s3-us-west-2.amazonaws.com/usgs-lidar-public/{name}/ept.json\"\n",
    "        reader = {\n",
    "            \"type\": \"readers.ept\",\n",
    "            \"filename\": url,\n",
    "            \"polygon\": str(extent_epsg3857),\n",
    "            \"requests\": 3,\n",
    "            \"resolution\": pc_resolution\n",
    "        }\n",
    "        readers.append(reader)\n",
    "    \n",
    "    pipeline = {\"pipeline\": readers}\n",
    "    \n",
    "    if filter_noise:\n",
    "        # Remove Class 7 (low noise) and Class 18 (high noise)\n",
    "        pipeline['pipeline'].append({\n",
    "            \"type\": \"filters.range\",\n",
    "            \"limits\": \"Classification![7:7]\"\n",
    "        })\n",
    "        pipeline['pipeline'].append({\n",
    "            \"type\": \"filters.range\",\n",
    "            \"limits\": \"Classification![18:18]\"\n",
    "        })\n",
    "    \n",
    "    # Reproject to output CRS\n",
    "    pipeline['pipeline'].append({\n",
    "        \"type\": \"filters.reprojection\",\n",
    "        \"out_srs\": f\"EPSG:{out_crs}\"\n",
    "    })\n",
    "    \n",
    "    if dem_type == 'dtm':\n",
    "        # Filter to ground points only (Class 2)\n",
    "        pipeline['pipeline'].append({\n",
    "            \"type\": \"filters.range\",\n",
    "            \"limits\": \"Classification[2:2]\"\n",
    "        })\n",
    "        # Use MIN for DTM (lowest point = ground)\n",
    "        grid_method = \"min\"\n",
    "    else:\n",
    "        # Use MAX for DSM (highest point = canopy/surface)\n",
    "        grid_method = \"max\"\n",
    "    \n",
    "    # Add GDAL writer with explicit CRS\n",
    "    pipeline['pipeline'].append({\n",
    "        \"type\": \"writers.gdal\",\n",
    "        \"filename\": str(dem_out_path),\n",
    "        \"gdaldriver\": \"GTiff\",\n",
    "        \"nodata\": -9999,\n",
    "        \"output_type\": grid_method,\n",
    "        \"resolution\": float(dem_resolution),\n",
    "        \"gdalopts\": f\"COMPRESS=LZW,TILED=YES,BLOCKXSIZE=256,BLOCKYSIZE=256\",\n",
    "        \"override_srs\": f\"EPSG:{out_crs}\"  # Explicitly set CRS in output\n",
    "    })\n",
    "    \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## 4. Load 3DEP Dataset Boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cell-11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 3DEP dataset boundaries...\n",
      "Loaded 2221 3DEP datasets\n",
      "Total points available: 73,773,529,099,863\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading 3DEP dataset boundaries...\")\n",
    "\n",
    "# Fetch 3DEP boundaries from Hobu Inc repository\n",
    "url = 'https://raw.githubusercontent.com/hobuinc/usgs-lidar/master/boundaries/resources.geojson'\n",
    "r = requests.get(url)\n",
    "\n",
    "# Save locally for reference (to local storage, not Data Store)\n",
    "boundaries_file = LOCAL_OUTPUT_BASE / 'resources.geojson'\n",
    "with open(boundaries_file, 'w') as f:\n",
    "    f.write(r.content.decode(\"utf-8\"))\n",
    "\n",
    "# Load as GeoDataFrame\n",
    "df_3dep = gpd.read_file(boundaries_file)\n",
    "\n",
    "# Project geometries to EPSG:3857\n",
    "df_3dep['geometry_3857'] = df_3dep['geometry'].apply(gcs_to_proj)\n",
    "\n",
    "print(f\"Loaded {len(df_3dep)} 3DEP datasets\")\n",
    "print(f\"Total points available: {df_3dep['count'].sum():,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## 5. Define Area of Interest (AOI)\n",
    "\n",
    "Current AOI: **Ocala Longleaf Pine, FL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cell-13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Site: monument_canyon_rna\n",
      "Bounding box (WGS84): [-106.64270398641813, 35.79252004986472, -106.6172480729282, 35.81386115600991]\n",
      "Area: 8.3006 km\u00b2\n"
     ]
    }
   ],
   "source": [
    "# Define AOI using GeoJSON",
    "# Ocala Longleaf Pine, FL",
    "",
    "AOI_GEOJSON = {",
    "  \"type\": \"FeatureCollection\",",
    "  \"features\": [",
    "    {",
    "      \"type\": \"Feature\",",
    "      \"properties\": {},",
    "      \"geometry\": {",
    "        \"coordinates\": [",
    "          [",
    "            [-81.85, 29.25],",
    "            [-81.85, 29.18],",
    "            [-81.78, 29.18],",
    "            [-81.78, 29.25],",
    "            [-81.85, 29.25]",
    "          ]",
    "        ],",
    "        \"type\": \"Polygon\"",
    "      }",
    "    }",
    "  ]",
    "}",
    "",
    "SITE_NAME = \"ocala_longleaf\"",
    "",
    "# Parse GeoJSON and create AOI",
    "feature = AOI_GEOJSON['features'][0]",
    "AOI_GCS = shape(feature['geometry'])",
    "AOI_EPSG3857 = gcs_to_proj(AOI_GCS)",
    "",
    "# Calculate bounding box for reference",
    "AOI_BBOX = list(AOI_GCS.bounds)  # [west, south, east, north]",
    "",
    "print(f\"Site: {SITE_NAME}\")",
    "print(f\"Bounding box (WGS84): {AOI_BBOX}\")",
    "print(f\"Area: {AOI_EPSG3857.area / 1e6:.4f} km\u00b2\")",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## 6. Find Intersecting 3DEP Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cell-15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 intersecting 3DEP dataset(s):\n",
      "  - NM_NorthCentral_B1_2016: 48,720,670,453 points\n",
      "  - NM_SouthCentral_B9_2018: 20,850,776,931 points\n"
     ]
    }
   ],
   "source": [
    "# Find 3DEP datasets that intersect with our AOI\n",
    "intersecting = []\n",
    "\n",
    "for idx, row in df_3dep.iterrows():\n",
    "    if row['geometry_3857'].intersects(AOI_EPSG3857):\n",
    "        intersecting.append({\n",
    "            'name': row['name'],\n",
    "            'url': row['url'],\n",
    "            'count': row['count'],\n",
    "            'geometry_gcs': row['geometry'],\n",
    "            'geometry_3857': row['geometry_3857']\n",
    "        })\n",
    "\n",
    "if not intersecting:\n",
    "    raise ValueError(\"No 3DEP datasets found for this AOI. Check coordinates.\")\n",
    "\n",
    "print(f\"Found {len(intersecting)} intersecting 3DEP dataset(s):\")\n",
    "for ds in intersecting:\n",
    "    print(f\"  - {ds['name']}: {ds['count']:,} points\")\n",
    "\n",
    "# Extract dataset names for PDAL\n",
    "dataset_names = [ds['name'] for ds in intersecting]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## 7. Estimate Point Density and Select Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cell-17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AOI Area: 8.3006 km\u00b2 (8,300,619 m\u00b2)\n",
      "Estimated points: 53,943,549\n",
      "Estimated density: 6.5 points/m\u00b2\n",
      "\n",
      "Selected resolution: 0.5m\n",
      "  (Threshold: 12 pts/m\u00b2 -> STANDARD resolution)\n"
     ]
    }
   ],
   "source": [
    "# Estimate point density for our AOI\n",
    "total_points_estimate = 0\n",
    "\n",
    "for ds in intersecting:\n",
    "    # Ratio of AOI area to dataset area\n",
    "    ratio = AOI_EPSG3857.area / ds['geometry_3857'].area\n",
    "    points_estimate = ratio * ds['count']\n",
    "    total_points_estimate += points_estimate\n",
    "\n",
    "# Calculate density\n",
    "aoi_area_m2 = AOI_EPSG3857.area\n",
    "estimated_density = total_points_estimate / aoi_area_m2\n",
    "\n",
    "# Select resolution based on density\n",
    "selected_resolution = get_resolution(estimated_density)\n",
    "\n",
    "print(f\"AOI Area: {aoi_area_m2 / 1e6:.4f} km\u00b2 ({aoi_area_m2:,.0f} m\u00b2)\")\n",
    "print(f\"Estimated points: {total_points_estimate:,.0f}\")\n",
    "print(f\"Estimated density: {estimated_density:.1f} points/m\u00b2\")\n",
    "print(f\"\")\n",
    "print(f\"Selected resolution: {selected_resolution}m\")\n",
    "print(f\"  (Threshold: {DENSITY_THRESHOLD} pts/m\u00b2 -> \"\n",
    "      f\"{'HIGH' if estimated_density >= DENSITY_THRESHOLD else 'STANDARD'} resolution)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## 8. Generate Digital Surface Model (DSM)\n",
    "\n",
    "Writing to **local storage** for fast I/O."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cell-19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating DSM at 0.5m resolution...\n",
      "Output (local): /home/jovyan/data-store/data/output/3dep/dsm/monument_canyon_rna_dsm.tif\n",
      "Method: MAX (highest point per cell - NO IDW)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4315/1317859243.py:24: RuntimeWarning: TIFFFetchNormalTag:IO error during reading of \"GeoPixelScale\"; tag ignored\n",
      "  dsm_pipeline.execute_streaming(chunk_size=1000000)\n",
      "/tmp/ipykernel_4315/1317859243.py:24: RuntimeWarning: TIFFFetchNormalTag:IO error during reading of \"GeoTiePoints\"; tag ignored\n",
      "  dsm_pipeline.execute_streaming(chunk_size=1000000)\n",
      "/tmp/ipykernel_4315/1317859243.py:24: RuntimeWarning: TIFFFetchNormalTag:IO error during reading of \"GeoKeyDirectory\"; tag ignored\n",
      "  dsm_pipeline.execute_streaming(chunk_size=1000000)\n",
      "/tmp/ipykernel_4315/1317859243.py:24: RuntimeWarning: TIFFFetchNormalTag:IO error during reading of \"GeoASCIIParams\"; tag ignored\n",
      "  dsm_pipeline.execute_streaming(chunk_size=1000000)\n",
      "/tmp/ipykernel_4315/1317859243.py:24: RuntimeWarning: TIFFFetchNormalTag:IO error during reading of \"GDALMetadata\"; tag ignored\n",
      "  dsm_pipeline.execute_streaming(chunk_size=1000000)\n",
      "/tmp/ipykernel_4315/1317859243.py:24: RuntimeWarning: TIFFFetchNormalTag:IO error during reading of \"GDALNoDataValue\"; tag ignored\n",
      "  dsm_pipeline.execute_streaming(chunk_size=1000000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DSM complete in 101.6 seconds\n",
      "File size: 97.6 MB\n"
     ]
    }
   ],
   "source": [
    "# DSM output path (LOCAL storage)\n",
    "dsm_path = LOCAL_OUTPUT_DSM / f\"{SITE_NAME}_dsm.tif\"\n",
    "\n",
    "print(f\"Generating DSM at {selected_resolution}m resolution...\")\n",
    "print(f\"Output (local): {dsm_path}\")\n",
    "print(f\"Method: MAX (highest point per cell - NO IDW)\")\n",
    "\n",
    "# Build pipeline\n",
    "dsm_pipeline_dict = make_dem_pipeline(\n",
    "    extent_epsg3857=AOI_EPSG3857.wkt,\n",
    "    usgs_3dep_dataset_names=dataset_names,\n",
    "    pc_resolution=1.0,  # Full resolution point cloud\n",
    "    dem_resolution=selected_resolution,\n",
    "    dem_type='dsm',\n",
    "    dem_out_path=dsm_path,\n",
    "    filter_noise=True,\n",
    "    out_crs=OUTPUT_CRS\n",
    ")\n",
    "\n",
    "# Execute\n",
    "dsm_pipeline = pdal.Pipeline(json.dumps(dsm_pipeline_dict))\n",
    "\n",
    "start_time = datetime.now()\n",
    "dsm_pipeline.execute_streaming(chunk_size=1000000)\n",
    "elapsed = (datetime.now() - start_time).total_seconds()\n",
    "\n",
    "print(f\"DSM complete in {elapsed:.1f} seconds\")\n",
    "print(f\"File size: {dsm_path.stat().st_size / 1e6:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "## 9. Generate Digital Terrain Model (DTM)\n",
    "\n",
    "Writing to **local storage** for fast I/O."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cell-21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating DTM at 0.5m resolution...\n",
      "Output (local): /home/jovyan/data-store/data/output/3dep/dtm/monument_canyon_rna_dtm.tif\n",
      "Method: MIN (lowest ground point per cell - NO IDW)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "writers.gdal: Unable to write block for for raster '/home/jovyan/data-store/data/output/3dep/dtm/monument_canyon_rna_dtm.tif'.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     21\u001b[39m dtm_pipeline = pdal.Pipeline(json.dumps(dtm_pipeline_dict))\n\u001b[32m     23\u001b[39m start_time = datetime.now()\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[43mdtm_pipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute_streaming\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1000000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m elapsed = (datetime.now() - start_time).total_seconds()\n\u001b[32m     27\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDTM complete in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00melapsed\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m seconds\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mRuntimeError\u001b[39m: writers.gdal: Unable to write block for for raster '/home/jovyan/data-store/data/output/3dep/dtm/monument_canyon_rna_dtm.tif'."
     ]
    }
   ],
   "source": [
    "# DTM output path (LOCAL storage)\n",
    "dtm_path = LOCAL_OUTPUT_DTM / f\"{SITE_NAME}_dtm.tif\"\n",
    "\n",
    "print(f\"Generating DTM at {selected_resolution}m resolution...\")\n",
    "print(f\"Output (local): {dtm_path}\")\n",
    "print(f\"Method: MIN (lowest ground point per cell - NO IDW)\")\n",
    "\n",
    "# Build pipeline\n",
    "dtm_pipeline_dict = make_dem_pipeline(\n",
    "    extent_epsg3857=AOI_EPSG3857.wkt,\n",
    "    usgs_3dep_dataset_names=dataset_names,\n",
    "    pc_resolution=1.0,  # Full resolution point cloud\n",
    "    dem_resolution=selected_resolution,\n",
    "    dem_type='dtm',\n",
    "    dem_out_path=dtm_path,\n",
    "    filter_noise=True,\n",
    "    out_crs=OUTPUT_CRS\n",
    ")\n",
    "\n",
    "# Execute\n",
    "dtm_pipeline = pdal.Pipeline(json.dumps(dtm_pipeline_dict))\n",
    "\n",
    "start_time = datetime.now()\n",
    "dtm_pipeline.execute_streaming(chunk_size=1000000)\n",
    "elapsed = (datetime.now() - start_time).total_seconds()\n",
    "\n",
    "print(f\"DTM complete in {elapsed:.1f} seconds\")\n",
    "print(f\"File size: {dtm_path.stat().st_size / 1e6:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "## 10. Calculate Canopy Height Model (CHM)\n",
    "\n",
    "**CHM = DSM - DTM**\n",
    "\n",
    "Simple direct subtraction with no smoothing or interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DSM and DTM from local storage\n",
    "print(\"Loading DSM and DTM from local storage...\")\n",
    "\n",
    "dsm = rio.open_rasterio(dsm_path, masked=True)\n",
    "dtm = rio.open_rasterio(dtm_path, masked=True)\n",
    "\n",
    "print(f\"DSM shape: {dsm.shape}, CRS: {dsm.rio.crs}\")\n",
    "print(f\"DTM shape: {dtm.shape}, CRS: {dtm.rio.crs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify CRS is set, fix if needed\n",
    "if dsm.rio.crs is None:\n",
    "    print(\"Warning: DSM missing CRS, setting to EPSG:3857\")\n",
    "    dsm = dsm.rio.write_crs(f\"EPSG:{OUTPUT_CRS}\")\n",
    "\n",
    "if dtm.rio.crs is None:\n",
    "    print(\"Warning: DTM missing CRS, setting to EPSG:3857\")\n",
    "    dtm = dtm.rio.write_crs(f\"EPSG:{OUTPUT_CRS}\")\n",
    "\n",
    "# Align rasters if shapes don't match\n",
    "if dsm.shape != dtm.shape:\n",
    "    print(f\"Raster shapes differ: DSM={dsm.shape}, DTM={dtm.shape}\")\n",
    "    print(\"Aligning rasters...\")\n",
    "    \n",
    "    # Use the smaller raster as reference\n",
    "    if dsm.shape[1] * dsm.shape[2] > dtm.shape[1] * dtm.shape[2]:\n",
    "        dsm = dsm.rio.reproject_match(dtm)\n",
    "        print(f\"DSM reprojected to match DTM: {dsm.shape}\")\n",
    "    else:\n",
    "        dtm = dtm.rio.reproject_match(dsm)\n",
    "        print(f\"DTM reprojected to match DSM: {dtm.shape}\")\n",
    "\n",
    "print(f\"\\nFinal shapes: DSM={dsm.shape}, DTM={dtm.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate CHM: Direct subtraction only\n",
    "print(\"Calculating CHM = DSM - DTM (direct subtraction, no smoothing)...\")\n",
    "\n",
    "# Ensure coordinates match exactly\n",
    "dsm = dsm.assign_coords({\"x\": dtm.x, \"y\": dtm.y})\n",
    "\n",
    "chm = dsm - dtm\n",
    "\n",
    "# Set NoData value\n",
    "nodata_val = -9999\n",
    "chm = chm.rio.write_nodata(nodata_val)\n",
    "chm = chm.rio.write_crs(f\"EPSG:{OUTPUT_CRS}\")\n",
    "\n",
    "# Save CHM to local storage\n",
    "chm_path = LOCAL_OUTPUT_CHM / f\"{SITE_NAME}_chm.tif\"\n",
    "chm.rio.to_raster(chm_path, driver=\"GTiff\", compress=\"LZW\", tiled=True)\n",
    "\n",
    "print(f\"CHM saved to: {chm_path}\")\n",
    "print(f\"File size: {chm_path.stat().st_size / 1e6:.1f} MB\")\n",
    "\n",
    "# Also save the DTM as DEM alongside the CHM for use in fractal analysis (Hypothesis 5)\n",
    "dem_path = LOCAL_OUTPUT_CHM / f\"{SITE_NAME}_dem.tif\"\n",
    "dtm.rio.to_raster(dem_path, driver=\"GTiff\", compress=\"LZW\", tiled=True)\n",
    "print(f\"DEM saved to: {dem_path} (for fractal analysis H5)\")\n",
    "print(f\"File size: {dem_path.stat().st_size / 1e6:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "## 11. Calculate Statistics and Generate Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate CHM statistics\n",
    "chm_data = chm.values.flatten()\n",
    "chm_valid = chm_data[~np.isnan(chm_data)]\n",
    "chm_valid = chm_valid[chm_valid != nodata_val]\n",
    "\n",
    "# Filter to reasonable height values (0-150m)\n",
    "chm_heights = chm_valid[(chm_valid >= 0) & (chm_valid <= 150)]\n",
    "\n",
    "stats = {\n",
    "    'site_name': SITE_NAME,\n",
    "    'bbox': AOI_BBOX,\n",
    "    'area_km2': aoi_area_m2 / 1e6,\n",
    "    'resolution_m': selected_resolution,\n",
    "    'point_density_est': estimated_density,\n",
    "    'datasets_used': dataset_names,\n",
    "    'crs': f'EPSG:{OUTPUT_CRS}',\n",
    "    'processing': {\n",
    "        'dsm_method': 'max',\n",
    "        'dtm_method': 'min',\n",
    "        'smoothing': 'none',\n",
    "        'interpolation': 'none'\n",
    "    },\n",
    "    'chm_statistics': {\n",
    "        'min_height_m': float(np.min(chm_heights)) if len(chm_heights) > 0 else None,\n",
    "        'max_height_m': float(np.max(chm_heights)) if len(chm_heights) > 0 else None,\n",
    "        'mean_height_m': float(np.mean(chm_heights)) if len(chm_heights) > 0 else None,\n",
    "        'median_height_m': float(np.median(chm_heights)) if len(chm_heights) > 0 else None,\n",
    "        'std_height_m': float(np.std(chm_heights)) if len(chm_heights) > 0 else None,\n",
    "        'valid_pixels': int(len(chm_heights)),\n",
    "        'total_pixels': int(len(chm_data))\n",
    "    },\n",
    "    'generated_at': datetime.now().isoformat(),\n",
    "    'source': 'USGS 3DEP via OpenTopography'\n",
    "}\n",
    "\n",
    "# Print summary\n",
    "print(\"CHM Statistics:\")\n",
    "if stats['chm_statistics']['min_height_m'] is not None:\n",
    "    print(f\"  Min height:    {stats['chm_statistics']['min_height_m']:.2f} m\")\n",
    "    print(f\"  Max height:    {stats['chm_statistics']['max_height_m']:.2f} m\")\n",
    "    print(f\"  Mean height:   {stats['chm_statistics']['mean_height_m']:.2f} m\")\n",
    "    print(f\"  Median height: {stats['chm_statistics']['median_height_m']:.2f} m\")\n",
    "    print(f\"  Std deviation: {stats['chm_statistics']['std_height_m']:.2f} m\")\n",
    "    print(f\"  Valid pixels:  {stats['chm_statistics']['valid_pixels']:,}\")\n",
    "else:\n",
    "    print(\"  No valid height data found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metadata to local storage\n",
    "metadata_path = LOCAL_OUTPUT_CHM / f\"{SITE_NAME}_metadata.json\"\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(stats, f, indent=2)\n",
    "\n",
    "print(f\"Metadata saved to: {metadata_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-29",
   "metadata": {},
   "source": [
    "## 12. Visualize CHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample for visualization if needed\n",
    "def downsample_for_plot(raster, max_dim=1000):\n",
    "    \"\"\"Downsample raster for efficient plotting.\"\"\"\n",
    "    # Handle both 2D (after squeeze) and 3D arrays\n",
    "    if len(raster.shape) == 2:\n",
    "        height, width = raster.shape\n",
    "    else:\n",
    "        height, width = raster.shape[1], raster.shape[2]\n",
    "    \n",
    "    if max(height, width) > max_dim:\n",
    "        scale = max_dim / max(height, width)\n",
    "        new_width = int(raster.rio.width * scale)\n",
    "        new_height = int(raster.rio.height * scale)\n",
    "        return raster.rio.reproject(\n",
    "            raster.rio.crs,\n",
    "            shape=(new_height, new_width),\n",
    "            resampling=Resampling.bilinear\n",
    "        )\n",
    "    return raster\n",
    "\n",
    "chm_plot = downsample_for_plot(chm.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# CHM map\n",
    "ax1 = axes[0]\n",
    "im = chm_plot.plot(ax=ax1, cmap='Greens', robust=True, add_colorbar=False)\n",
    "ax1.set_title(f\"Canopy Height Model: {SITE_NAME}\")\n",
    "ax1.set_xlabel(\"Easting (m)\")\n",
    "ax1.set_ylabel(\"Northing (m)\")\n",
    "ax1.ticklabel_format(style='plain')\n",
    "ax1.set_aspect('equal')\n",
    "plt.colorbar(im, ax=ax1, label='Height (m)')\n",
    "\n",
    "# Height histogram\n",
    "ax2 = axes[1]\n",
    "if len(chm_heights) > 0:\n",
    "    ax2.hist(chm_heights, bins=50, color='green', alpha=0.7, edgecolor='darkgreen')\n",
    "    ax2.axvline(stats['chm_statistics']['mean_height_m'], color='red', \n",
    "                linestyle='--', label=f\"Mean: {stats['chm_statistics']['mean_height_m']:.1f}m\")\n",
    "    ax2.axvline(stats['chm_statistics']['median_height_m'], color='orange', \n",
    "                linestyle='--', label=f\"Median: {stats['chm_statistics']['median_height_m']:.1f}m\")\n",
    "    ax2.legend()\n",
    "ax2.set_title(\"Height Distribution\")\n",
    "ax2.set_xlabel(\"Canopy Height (m)\")\n",
    "ax2.set_ylabel(\"Pixel Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save figure to local storage\n",
    "preview_path = LOCAL_OUTPUT_CHM / f\"{SITE_NAME}_preview.png\"\n",
    "plt.savefig(preview_path, dpi=150, bbox_inches='tight')\n",
    "print(f\"Preview saved to: {preview_path}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-32",
   "metadata": {},
   "source": [
    "## 13. Cleanup Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close raster handles and free memory\n",
    "dsm.close()\n",
    "dtm.close()\n",
    "chm.close()\n",
    "\n",
    "del dsm, dtm, chm, chm_plot\n",
    "\n",
    "print(\"Memory cleaned up.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-34",
   "metadata": {},
   "source": [
    "## 14. Copy Outputs to CyVerse Data Store\n",
    "\n",
    "Now that processing is complete, copy the outputs from local storage to the CyVerse Data Store for persistent storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Data Store output directories\n",
    "DATASTORE_CHM = DATASTORE_OUTPUT_BASE / \"chm\"\n",
    "DATASTORE_DTM = DATASTORE_OUTPUT_BASE / \"dtm\"\n",
    "DATASTORE_DSM = DATASTORE_OUTPUT_BASE / \"dsm\"\n",
    "\n",
    "for d in [DATASTORE_CHM, DATASTORE_DTM, DATASTORE_DSM]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Data Store directories created under: {DATASTORE_OUTPUT_BASE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy files to Data Store\n",
    "print(\"Copying outputs to CyVerse Data Store...\")\n",
    "print(\"(This may take a while due to CSI mount I/O)\")\n",
    "print()\n",
    "\n",
    "files_to_copy = [\n",
    "    (dsm_path, DATASTORE_DSM / dsm_path.name),\n",
    "    (dtm_path, DATASTORE_DTM / dtm_path.name),\n",
    "    (chm_path, DATASTORE_CHM / chm_path.name),\n",
    "    (metadata_path, DATASTORE_CHM / metadata_path.name),\n",
    "    (preview_path, DATASTORE_CHM / preview_path.name),\n",
    "]\n",
    "\n",
    "for src, dst in files_to_copy:\n",
    "    if src.exists():\n",
    "        start = datetime.now()\n",
    "        print(f\"  Copying {src.name}...\", end=\" \", flush=True)\n",
    "        shutil.copy2(src, dst)\n",
    "        elapsed = (datetime.now() - start).total_seconds()\n",
    "        print(f\"done ({elapsed:.1f}s)\")\n",
    "    else:\n",
    "        print(f\"  Skipping {src.name} (not found)\")\n",
    "\n",
    "print()\n",
    "print(\"Copy complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-37",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CHM GENERATION COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nLocal outputs: {LOCAL_OUTPUT_BASE}\")\n",
    "print(f\"Data Store outputs: {DATASTORE_OUTPUT_BASE}\")\n",
    "print(f\"\\nFiles generated:\")\n",
    "print(f\"  - CHM: {SITE_NAME}_chm.tif\")\n",
    "print(f\"  - DEM: {SITE_NAME}_dem.tif (for fractal analysis)\")\n",
    "print(f\"  - DSM: {SITE_NAME}_dsm.tif\")\n",
    "print(f\"  - DTM: {SITE_NAME}_dtm.tif\")\n",
    "print(f\"  - Metadata: {SITE_NAME}_metadata.json\")\n",
    "print(f\"  - Preview: {SITE_NAME}_preview.png\")\n",
    "print(f\"\\nFor fractal analysis, use:\")\n",
    "print(f\"  CHM_PATH = '{chm_path}'\")\n",
    "print(f\"  DEM_PATH = '{dem_path}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-38",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## References\n",
    "\n",
    "- Original notebook: [OpenTopography OT_3DEP_Workflows](https://github.com/OpenTopography/OT_3DEP_Workflows)\n",
    "- 3DEP Program: https://www.usgs.gov/3d-elevation-program\n",
    "- PDAL Documentation: https://pdal.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83465ce0-411a-4624-93f9-b2187262381b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (3DEP)",
   "language": "python",
   "name": "3dep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}